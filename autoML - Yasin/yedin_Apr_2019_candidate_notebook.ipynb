{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook\n",
    "\n",
    "This notebook was automatically generated by the AutoML job **niy-Apr-2019-20201202-1434**.\n",
    "This notebook allows you to customize the candidate definitions and execute the SageMaker Autopilot workflow.\n",
    "\n",
    "The dataset has **12** columns and the column named **ARR_DELAY_NEW** is used as\n",
    "the target column. This is being treated as a **Regression** problem. \n",
    "This notebook will build a **[Regression](https://en.wikipedia.org/wiki/Regression_analysis)** model that\n",
    "**minimizes** the \"**MSE**\" quality metric of the trained models.\n",
    "The \"**MSE**\" metric stands for mean square error. It minimizes the square distance between the model's prediction and the true answer.\n",
    "\n",
    "As part of the AutoML job, the input dataset has been randomly split into two pieces, one for **training** and one for\n",
    "**validation**. This notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively\n",
    "train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO)\n",
    "job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "Look for sections like this for recommended settings that you can change.\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Sagemaker Setup](#Sagemaker-Setup)\n",
    "    1. [Downloading Generated Candidates](#Downloading-Generated-Modules)\n",
    "    1. [SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration](#SageMaker-Autopilot-Job-and-Amazon-Simple-Storage-Service-(Amazon-S3)-Configuration)\n",
    "1. [Candidate Pipelines](#Candidate-Pipelines)\n",
    "    1. [Generated Candidates](#Generated-Candidates)\n",
    "    1. [Selected Candidates](#Selected-Candidates)\n",
    "1. [Executing the Candidate Pipelines](#Executing-the-Candidate-Pipelines)\n",
    "    1. [Run Data Transformation Steps](#Run-Data-Transformation-Steps)\n",
    "    1. [Multi Algorithm Hyperparameter Tuning](#Multi-Algorithm-Hyperparameter-Tuning)\n",
    "1. [Model Selection and Deployment](#Model-Selection-and-Deployment)\n",
    "    1. [Tuning Job Result Overview](#Tuning-Job-Result-Overview)\n",
    "    1. [Model Deployment](#Model-Deployment)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Setup\n",
    "\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "- Check environment & dependencies.\n",
    "- Create a few helper objects/function to organize input/output data and SageMaker sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimal Environment Requirements**\n",
    "\n",
    "- Jupyter: Tested on `JupyterLab 1.0.6`, `jupyter_core 4.5.0` and `IPython 6.4.0`\n",
    "- Kernel: `conda_python3`\n",
    "- Dependencies required\n",
    "  - `sagemaker-python-sdk>=1.72.1,<2.0.0`\n",
    "    - Use `!pip install sagemaker==1.72.1` to download this dependency.\n",
    "    - Kernel may need to be restarted after download.\n",
    "- Expected Execution Role/permission\n",
    "  - S3 access to the bucket that stores the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Generated Modules\n",
    "Download the generated data transformation modules and an SageMaker Autopilot helper module used by this notebook.\n",
    "Those artifacts will be downloaded to **niy-Apr-2019-20201202-1434-artifacts** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p niy-Apr-2019-20201202-1434-artifacts\n",
    "!aws s3 sync s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/sagemaker-automl-candidates/pr-1-bcecb56184f44b75be8236d67223d3a14325f9b64ffb4e2c8fa8a5cb91/generated_module niy-Apr-2019-20201202-1434-artifacts/generated_module --only-show-errors\n",
    "!aws s3 sync s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/sagemaker-automl-candidates/pr-1-bcecb56184f44b75be8236d67223d3a14325f9b64ffb4e2c8fa8a5cb91/notebooks/sagemaker_automl niy-Apr-2019-20201202-1434-artifacts/sagemaker_automl --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"niy-Apr-2019-20201202-1434-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will\n",
    "look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 10:54:38,069 INFO botocore.credentials: Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This notebook is initialized to use the following configuration: \n",
       "        <table>\n",
       "        <tr><th colspan=2>Name</th><th>Value</th></tr>\n",
       "        <tr><th>General</th><th>Role</th><td>arn:aws:iam::898627427171:role/service-role/AmazonSageMaker-ExecutionRole-20201106T104926</td></tr>\n",
       "        <tr><th rowspan=2>Base AutoML Job</th><th>Job Name</th><td>niy-Apr-2019-20201202-1434</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434</td></tr>\n",
       "        <tr><th rowspan=5>Interactive Job</th><th>Job Name</th><td>niy-Apr-20-notebook-run-03-09-54-38</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/niy-Apr-20-notebook-run-03-09-54-38</td></tr>\n",
       "        <tr><th>Data Processing Trained Model Directory</th><td>s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/niy-Apr-20-notebook-run-03-09-54-38/data-processor-models</td></tr>\n",
       "        <tr><th>Data Processing Transformed Output</th><td>s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/niy-Apr-20-notebook-run-03-09-54-38/transformed-data</td></tr>\n",
       "        <tr><th>Algo Tuning Model Output Directory</th><td>s3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/niy-Apr-20-notebook-run-03-09-54-38/multi-algo-tuning</td></tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_automl import uid, AutoMLLocalRunConfig\n",
    "\n",
    "# Where the preprocessed data from the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'niy-Apr-2019-20201202-1434'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://niy-certification/automl/output/niy-Apr-2019-20201202-1434',\n",
    "    'data_transformer_image_repo_version': '0.2-1-cpu-py3',\n",
    "    'algo_image_repo_versions': {'xgboost': '1.0-1-cpu-py3', 'linear-learner': 'latest', 'mlp': 'training-cpu'},\n",
    "    'algo_inference_image_repo_versions': {'xgboost': '1.0-1-cpu-py3', 'linear-learner': 'latest', 'mlp': 'inference-cpu'}\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'niy-Apr-20-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://niy-certification/automl/output/niy-Apr-2019-20201202-1434/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "    'data_processing_model_dir': 'data-processor-models',\n",
    "    'data_processing_transformed_output_dir': 'transformed-data',\n",
    "    'multi_algo_tuning_output_dir': 'multi-algo-tuning'\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG = AutoMLLocalRunConfig(\n",
    "    role='arn:aws:iam::898627427171:role/service-role/AmazonSageMaker-ExecutionRole-20201106T104926',\n",
    "    base_automl_job_config=BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config=LOCAL_AUTOML_JOB_CONFIG,\n",
    "    security_config={'EnableInterContainerTrafficEncryption': False, 'VpcConfig': {}})\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Pipelines\n",
    "\n",
    "The `AutoMLLocalRunner` keeps track of selected candidates and automates many of the steps needed to execute feature engineering and tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl import AutoMLInteractiveRunner, AutoMLLocalCandidate\n",
    "\n",
    "automl_interactive_runner = AutoMLInteractiveRunner(AUTOML_LOCAL_RUN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Candidates\n",
    "\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated **10** machine learning\n",
    "pipeline(s) that use **3** algorithm(s). Each pipeline contains a set of feature transformers and an\n",
    "algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. The resource configuration: instance type & count\n",
    "1. Select candidate pipeline definitions by cells\n",
    "1. The linked data transformation script can be reviewed and updated. Please refer to the [README.md](./niy-Apr-2019-20201202-1434-artifacts/generated_module/README.md) for detailed customization instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp0-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp0.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp0\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp1-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp1.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp1\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp2-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp2.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp2\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp3-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp3.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp3\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp4-linear-learner](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp4.py)**: This data transformation strategy first transforms 'numeric1' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 10:55:00,238 WARNING sagemaker.amazon.amazon_estimator: 'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:00,244 WARNING sagemaker.amazon.amazon_estimator: 'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp4\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp5-linear-learner](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp5.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 10:55:00,578 WARNING sagemaker.amazon.amazon_estimator: 'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:00,584 WARNING sagemaker.amazon.amazon_estimator: 'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp5\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp6-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp6.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp6\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp7-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp7.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp7\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp8-xgboost](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp8.py)**: This data transformation strategy first transforms 'numeric1' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical1' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp8\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp9-mlp](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp9.py)**: This data transformation strategy transforms 'categorical1' features using [ThresholdOrdinalEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py), 'numeric1' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *mlp* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp9\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": False,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"mlp\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"candidate_specific_static_hyperparameters\": {\n",
    "            \"num_categorical_features\": '5',\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Candidates\n",
    "\n",
    "You have selected the following candidates (please run the cell below and click on the feature transformer links for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <table>\n",
       "            <tr><th>Candidate Name</th><th>Algorithm</th><th>Feature Transformer</th></tr>\n",
       "            <tr><th>dpp0-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp0.py'>dpp0.py</a></td></tr>\n",
       "<tr><th>dpp1-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp1.py'>dpp1.py</a></td></tr>\n",
       "<tr><th>dpp2-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp2.py'>dpp2.py</a></td></tr>\n",
       "<tr><th>dpp3-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp3.py'>dpp3.py</a></td></tr>\n",
       "<tr><th>dpp4-linear-learner</th><td>linear-learner</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp4.py'>dpp4.py</a></td></tr>\n",
       "<tr><th>dpp5-linear-learner</th><td>linear-learner</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp5.py'>dpp5.py</a></td></tr>\n",
       "<tr><th>dpp6-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp6.py'>dpp6.py</a></td></tr>\n",
       "<tr><th>dpp7-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp7.py'>dpp7.py</a></td></tr>\n",
       "<tr><th>dpp8-xgboost</th><td>xgboost</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp8.py'>dpp8.py</a></td></tr>\n",
       "<tr><th>dpp9-mlp</th><td>mlp</td><td><a href='niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp9.py'>dpp9.py</a></td></tr>\n",
       "            </table>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_interactive_runner.display_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering pipeline consists of two SageMaker jobs:\n",
    "\n",
    "1. Generated trainable data transformer Python modules like [dpp0.py](niy-Apr-2019-20201202-1434-artifacts/generated_module/candidate_data_processors/dpp0.py), which has been downloaded to the local file system\n",
    "2. A **training** job to train the data transformers\n",
    "3. A **batch transform** job to apply the trained transformation to the dataset to generate the algorithm compatible data\n",
    "\n",
    "The transformers and its training pipeline are built using open sourced **[sagemaker-scikit-learn-container][]** and **[sagemaker-scikit-learn-extension][]**.\n",
    "\n",
    "[sagemaker-scikit-learn-container]: https://github.com/aws/sagemaker-scikit-learn-container\n",
    "[sagemaker-scikit-learn-extension]: https://github.com/aws/sagemaker-scikit-learn-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Candidate Pipelines\n",
    "\n",
    "Each candidate pipeline consists of two steps, feature transformation and algorithm training.\n",
    "For efficiency first execute the feature transformation step which will generate a featurized dataset on S3\n",
    "for each pipeline.\n",
    "\n",
    "After each featurized dataset is prepared, execute a multi-algorithm tuning job that will run tuning jobs\n",
    "in parallel for each pipeline. This tuning job will execute training jobs to find the best set of\n",
    "hyper-parameters for each pipeline, as well as finding the overall best performing pipeline.\n",
    "\n",
    "### Run Data Transformation Steps\n",
    "\n",
    "Now you are ready to start execution all data transformation steps.  The cell below may take some time to finish,\n",
    "feel free to go grab a cup of coffee. To expedite the process you can set the number of `parallel_jobs` to be up to 10.\n",
    "Please check the account limits to increase the limits before increasing the number of jobs to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 10:55:25,667 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,668 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,669 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,669 INFO root: [Worker_0:dpp0-xgboost]Executing step: train_data_transformer\n",
      "2020-12-03 10:55:25,670 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,672 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,672 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,673 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,673 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,674 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,675 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,675 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,676 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,677 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,677 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,678 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,678 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,679 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,680 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:25,680 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:25,681 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:55:28,936 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:28,937 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp0-train-03-09-55-25\n",
      "\n",
      "2020-12-03 09:55:29 Starting - Starting the training job\n",
      "2020-12-03 09:55:31 Starting - Launching requested ML instances2020-12-03 10:55:34,676 INFO root: [Worker_1:dpp1-xgboost]Executing step: train_data_transformer\n",
      "2020-12-03 10:55:34,902 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 10:55:34,903 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp1-train-03-09-55-25\n",
      "\n",
      "2020-12-03 09:55:35 Starting - Starting the training job.\n",
      "2020-12-03 09:55:36 Starting - Launching requested ML instances......................\n",
      "2020-12-03 09:56:36 Starting - Preparing the instances for training..\n",
      "2020-12-03 09:56:41 Starting - Preparing the instances for training.............\n",
      "2020-12-03 09:57:21 Downloading - Downloading input data\n",
      "2020-12-03 09:57:21 Downloading - Downloading input data.\n",
      "2020-12-03 09:57:29 Training - Downloading the training image....\n",
      "2020-12-03 09:57:37 Training - Downloading the training image..\n",
      "2020-12-03 09:57:49 Training - Training image download completed. Training in progress...\n",
      "2020-12-03 09:57:51 Training - Training image download completed. Training in progress...\n",
      "2020-12-03 09:58:04 Uploading - Uploading generated training model...\n",
      "2020-12-03 09:58:11 Completed - Training job completed\n",
      "2020-12-03 10:58:16,263 INFO root: [Worker_0:dpp0-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 10:58:16,312 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:58:16,668 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-09-58-16-668\n",
      "2020-12-03 10:58:17,003 INFO root: [Worker_0:dpp0-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 10:58:17,004 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp0-transform-03-09-55-25\n",
      "\n",
      "2020-12-03 09:58:12 Uploading - Uploading generated training model.\n",
      "2020-12-03 09:58:19 Completed - Training job completed\n",
      "..2020-12-03 10:58:31,268 INFO root: [Worker_1:dpp1-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 10:58:31,317 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 10:58:31,317 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-09-58-31-317\n",
      "..2020-12-03 10:58:40,710 INFO root: [Worker_1:dpp1-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 10:58:40,711 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp1-transform-03-09-55-25\n",
      "...........................................................................................................!\n",
      "2020-12-03 11:03:10,095 INFO root: Successfully fit data transformer for dpp0-xgboost\n",
      "2020-12-03 11:03:13,099 INFO root: [Worker_0:dpp2-xgboost]Executing step: train_data_transformer\n",
      ".2020-12-03 11:03:16,394 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:03:16,394 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp2-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:03:16 Starting - Starting the training job.\n",
      "2020-12-03 10:03:18 Starting - Launching requested ML instances....!\n",
      "2020-12-03 11:03:33,667 INFO root: Successfully fit data transformer for dpp1-xgboost\n",
      "2020-12-03 11:03:36,668 INFO root: [Worker_1:dpp3-xgboost]Executing step: train_data_transformer\n",
      ".2020-12-03 11:03:36,952 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:03:36,953 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp3-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:03:37 Starting - Starting the training job.\n",
      "2020-12-03 10:03:39 Starting - Launching requested ML instances................\n",
      "2020-12-03 10:04:23 Starting - Preparing the instances for training........\n",
      "2020-12-03 10:04:47 Starting - Preparing the instances for training....\n",
      "2020-12-03 10:05:01 Downloading - Downloading input data.........\n",
      "2020-12-03 10:05:26 Training - Downloading the training image\n",
      "2020-12-03 10:05:27 Downloading - Downloading input data.......\n",
      "2020-12-03 10:05:44 Training - Downloading the training image...\n",
      "2020-12-03 10:05:58 Training - Training image download completed. Training in progress.....\n",
      "2020-12-03 10:06:12 Uploading - Uploading generated training model..\n",
      "2020-12-03 10:06:14 Uploading - Uploading generated training model\n",
      "2020-12-03 10:06:19 Completed - Training job completed\n",
      "\n",
      "2020-12-03 10:06:20 Completed - Training job completed\n",
      "2020-12-03 11:06:26,514 INFO root: [Worker_0:dpp2-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 11:06:26,568 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:06:26,568 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-06-26-568\n",
      "2020-12-03 11:06:26,990 INFO root: [Worker_1:dpp3-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 11:06:27,037 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:06:27,038 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-06-27-038\n",
      "2020-12-03 11:06:29,975 INFO root: [Worker_0:dpp2-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 11:06:29,976 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp2-transform-03-09-55-25\n",
      ".2020-12-03 11:06:31,329 INFO root: [Worker_1:dpp3-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 11:06:31,330 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp3-transform-03-09-55-25\n",
      ".....................................................................................................................!.\n",
      "2020-12-03 11:11:31,417 INFO root: Successfully fit data transformer for dpp2-xgboost\n",
      ".2020-12-03 11:11:39,421 INFO root: [Worker_0:dpp4-linear-learner]Executing step: train_data_transformer\n",
      "2020-12-03 11:11:39,715 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:11:39,716 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp4-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:11:39 Starting - Starting the training job!\n",
      "2020-12-03 11:11:41,517 INFO root: Successfully fit data transformer for dpp3-xgboost\n",
      "2020-12-03 11:11:44,522 INFO root: [Worker_1:dpp5-linear-learner]Executing step: train_data_transformer\n",
      "2020-12-03 11:11:44,764 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:11:44,765 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp5-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:11:44 Starting - Starting the training job\n",
      "2020-12-03 10:11:41 Starting - Launching requested ML instances\n",
      "2020-12-03 10:11:46 Starting - Launching requested ML instances...............................\n",
      "2020-12-03 10:13:10 Starting - Preparing the instances for training\n",
      "2020-12-03 10:13:06 Starting - Preparing the instances for training.............\n",
      "2020-12-03 10:13:46 Downloading - Downloading input data..\n",
      "2020-12-03 10:13:52 Downloading - Downloading input data........\n",
      "2020-12-03 10:14:12 Training - Downloading the training image\n",
      "2020-12-03 10:14:19 Training - Downloading the training image....\n",
      "2020-12-03 10:14:27 Training - Training image download completed. Training in progress.\n",
      "2020-12-03 10:14:33 Training - Training image download completed. Training in progress........\n",
      "2020-12-03 10:14:54 Uploading - Uploading generated training model.\n",
      "2020-12-03 10:15:01 Completed - Training job completed\n",
      ".2020-12-03 11:15:05,181 INFO root: [Worker_1:dpp5-linear-learner]Executing step: create_transformer_model\n",
      "2020-12-03 11:15:05,230 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:15:05,231 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-15-05-231\n",
      ".2020-12-03 11:15:08,553 INFO root: [Worker_1:dpp5-linear-learner]Executing step: perform_data_transform\n",
      "2020-12-03 11:15:08,555 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp5-transform-03-09-55-25\n",
      "...\n",
      "2020-12-03 10:15:12 Uploading - Uploading generated training model.\n",
      "2020-12-03 10:15:19 Completed - Training job completed\n",
      "..2020-12-03 11:15:30,499 INFO root: [Worker_0:dpp4-linear-learner]Executing step: create_transformer_model\n",
      "2020-12-03 11:15:30,571 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:15:30,572 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-15-30-572\n",
      ".2020-12-03 11:15:38,926 INFO root: [Worker_0:dpp4-linear-learner]Executing step: perform_data_transform\n",
      "2020-12-03 11:15:38,927 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp4-transform-03-09-55-25\n",
      "........................................................................................................!.\n",
      "2020-12-03 11:20:05,102 INFO root: [Worker_1:dpp6-xgboost]Executing step: train_data_transformer\n",
      "2020-12-03 11:20:05,102 INFO root: Successfully fit data transformer for dpp5-linear-learner\n",
      "2020-12-03 11:20:05,421 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:20:05,422 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:20:05 Starting - Starting the training job.\n",
      "2020-12-03 10:20:07 Starting - Launching requested ML instances..!\n",
      "2020-12-03 11:20:20,245 INFO root: Successfully fit data transformer for dpp4-linear-learner\n",
      "..2020-12-03 11:20:28,250 INFO root: [Worker_0:dpp7-xgboost]Executing step: train_data_transformer\n",
      "2020-12-03 11:20:28,535 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:20:28,535 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp7-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:20:28 Starting - Starting the training job.\n",
      "2020-12-03 10:20:30 Starting - Launching requested ML instances................\n",
      "2020-12-03 10:21:15 Starting - Preparing the instances for training........\n",
      "2020-12-03 10:21:38 Starting - Preparing the instances for training............\n",
      "2020-12-03 10:22:07 Downloading - Downloading input data..\n",
      "2020-12-03 10:22:15 Downloading - Downloading input data.\n",
      "2020-12-03 10:22:22 Training - Downloading the training image\n",
      "2020-12-03 10:22:24 Training - Downloading the training image.....\n",
      "2020-12-03 10:22:38 Training - Training image download completed. Training in progress.\n",
      "2020-12-03 10:22:42 Training - Training image download completed. Training in progress........\n",
      "2020-12-03 10:23:03 Uploading - Uploading generated training model\n",
      "2020-12-03 10:23:03 Uploading - Uploading generated training model\n",
      "2020-12-03 10:23:10 Completed - Training job completed\n",
      "\n",
      "2020-12-03 10:23:10 Completed - Training job completed\n",
      "2020-12-03 11:23:12,573 INFO root: [Worker_1:dpp6-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 11:23:12,619 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:23:12,620 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-23-12-620\n",
      "2020-12-03 11:23:12,995 INFO root: [Worker_1:dpp6-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 11:23:12,996 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp6-transform-03-09-55-25\n",
      "..2020-12-03 11:23:18,514 INFO root: [Worker_0:dpp7-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 11:23:18,564 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:23:18,565 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-23-18-565\n",
      ".2020-12-03 11:23:26,903 INFO root: [Worker_0:dpp7-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 11:23:26,904 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp7-transform-03-09-55-25\n",
      "...............................................................................................................................!\n",
      "2020-12-03 11:28:46,654 INFO root: Successfully fit data transformer for dpp6-xgboost\n",
      "!\n",
      "2020-12-03 11:28:50,387 INFO root: Successfully fit data transformer for dpp7-xgboost\n",
      "2020-12-03 11:28:52,657 INFO root: [Worker_1:dpp8-xgboost]Executing step: train_data_transformer\n",
      "2020-12-03 11:28:55,942 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:28:55,943 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp8-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:28:56 Starting - Starting the training job2020-12-03 11:29:00,388 INFO root: [Worker_0:dpp9-mlp]Executing step: train_data_transformer\n",
      "2020-12-03 11:29:00,607 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:29:00,608 INFO sagemaker: Creating training-job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp9-train-03-09-55-25\n",
      "\n",
      "2020-12-03 10:29:00 Starting - Starting the training job\n",
      "2020-12-03 10:28:58 Starting - Launching requested ML instances\n",
      "2020-12-03 10:29:02 Starting - Launching requested ML instances.........................\n",
      "2020-12-03 10:30:08 Starting - Preparing the instances for training\n",
      "2020-12-03 10:30:07 Starting - Preparing the instances for training.............\n",
      "2020-12-03 10:30:44 Downloading - Downloading input data\n",
      "2020-12-03 10:30:49 Downloading - Downloading input data.\n",
      "2020-12-03 10:30:56 Training - Downloading the training image....\n",
      "2020-12-03 10:31:06 Training - Downloading the training image..\n",
      "2020-12-03 10:31:16 Training - Training image download completed. Training in progress...\n",
      "2020-12-03 10:31:19 Training - Training image download completed. Training in progress.....\n",
      "2020-12-03 10:31:32 Uploading - Uploading generated training model.\n",
      "2020-12-03 10:31:39 Completed - Training job completed\n",
      "\n",
      "2020-12-03 10:31:40 Uploading - Uploading generated training model\n",
      "2020-12-03 10:31:46 Completed - Training job completed\n",
      "2020-12-03 11:31:52,566 INFO root: [Worker_0:dpp9-mlp]Executing step: create_transformer_model\n",
      "2020-12-03 11:31:52,625 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:31:52,626 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-31-52-626\n",
      "2020-12-03 11:31:54,163 INFO root: [Worker_1:dpp8-xgboost]Executing step: create_transformer_model\n",
      "2020-12-03 11:31:54,216 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:31:54,217 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-12-03-10-31-54-217\n",
      "2020-12-03 11:32:00,600 INFO root: [Worker_1:dpp8-xgboost]Executing step: perform_data_transform\n",
      "2020-12-03 11:32:00,601 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp8-transform-03-09-55-25\n",
      ".2020-12-03 11:32:03,031 INFO root: [Worker_0:dpp9-mlp]Executing step: perform_data_transform\n",
      "2020-12-03 11:32:03,032 INFO sagemaker: Creating transform job with name: niy-Apr-20-notebook-run-03-09-54-38-dpp9-transform-03-09-55-25\n",
      "............................................................................................................!\n",
      "2020-12-03 11:36:35,949 INFO root: Successfully fit data transformer for dpp9-mlp\n",
      "...!\n",
      "2020-12-03 11:36:53,933 INFO root: Successfully fit data transformer for dpp8-xgboost\n",
      "2020-12-03 11:36:53,934 INFO root: Successfully fit 10 data transformers\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.fit_data_transformers(parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Algorithm Hyperparameter Tuning\n",
    "\n",
    "Now that the algorithm compatible transformed datasets are ready, you can start the multi-algorithm model tuning job\n",
    "to find the best predictive model. The following algorithm training job configuration for each\n",
    "algorithm is auto-generated by the AutoML Job as part of the recommendation.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Hyperparameter ranges\n",
    "2. Objective metrics\n",
    "3. Recommended static algorithm hyperparameters.\n",
    "\n",
    "Please refers to [Xgboost tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) and [Linear learner tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) for detailed explanations of the parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML recommendation job has recommended the following hyperparameters, objectives and accuracy metrics for\n",
    "the algorithm and problem type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_OBJECTIVE_METRICS = {\n",
    "    'xgboost': 'validation:mse',\n",
    "    'linear-learner': 'validation:objective_loss',\n",
    "    'mlp': 'validation:mse',\n",
    "}\n",
    "\n",
    "STATIC_HYPERPARAMETERS = {\n",
    "    'xgboost': {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'save_model_on_termination': 'true',\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'predictor_type': 'regressor',\n",
    "        'epochs': 50,\n",
    "        'loss': 'auto',\n",
    "        'mini_batch_size': 800,\n",
    "    },\n",
    "    'mlp': {\n",
    "        'problem_type': 'regression',\n",
    "        'ml_application': 'mlp',\n",
    "        'use_batchnorm': 'true',\n",
    "        'activation': 'relu',\n",
    "        'warmup_epochs': 10,\n",
    "        'eval_metric': 'mse',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tunable hyperparameters search ranges are recommended for the Multi-Algo tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "    'xgboost': {\n",
    "        'num_round': IntegerParameter(2, 1024, scaling_type='Logarithmic'),\n",
    "        'max_depth': IntegerParameter(2, 8, scaling_type='Logarithmic'),\n",
    "        'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "        'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "        'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "        'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "        'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "        'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "        'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'wd': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'l1': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'learning_rate': ContinuousParameter(1e-5, 1.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'mlp': {\n",
    "        'mini_batch_size': IntegerParameter(128, 512, scaling_type='Linear'),\n",
    "        'learning_rate': ContinuousParameter(1e-6, 1e-2, scaling_type='Logarithmic'),\n",
    "        'weight_decay': ContinuousParameter(1e-12, 1e-2, scaling_type='Logarithmic'),\n",
    "        'dropout_prob': ContinuousParameter(0.25, 0.5, scaling_type='Linear'),\n",
    "        'embedding_size_factor': ContinuousParameter(0.65, 0.95, scaling_type='Linear'),\n",
    "        'network_type': CategoricalParameter(['feedforward', 'widedeep']),\n",
    "        'layers': CategoricalParameter(['256', '50, 25', '100, 50', '200, 100', '256, 128', '300, 150', '200, 100, 50']),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi-Algorithm Tuner Input\n",
    "\n",
    "To use the multi-algorithm HPO tuner, prepare some inputs and parameters. Prepare a dictionary whose key is the name of the trained pipeline candidates and the values are respectively:\n",
    "\n",
    "1. Estimators for the recommended algorithm\n",
    "2. Hyperparameters search ranges\n",
    "3. Objective metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 11:37:35,225 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,226 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,226 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,227 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,227 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,228 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,228 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,229 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,230 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:35,230 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "multi_algo_tuning_parameters = automl_interactive_runner.prepare_multi_algo_parameters(\n",
    "    objective_metrics=ALGORITHM_OBJECTIVE_METRICS,\n",
    "    static_hyperparameters=STATIC_HYPERPARAMETERS,\n",
    "    hyperparameters_search_ranges=ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you prepare the inputs data to the multi-algo tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 11:37:40,350 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,351 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,352 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,352 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,353 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,353 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,354 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,354 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,355 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,355 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,356 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,356 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,356 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,357 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,357 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,358 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,358 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,359 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,359 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-12-03 11:37:40,360 WARNING sagemaker: 's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "multi_algo_tuning_inputs = automl_interactive_runner.prepare_multi_algo_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Multi-Algorithm Tuner\n",
    "\n",
    "With the recommended Hyperparameter ranges and the transformed dataset, create a multi-algorithm model tuning job\n",
    "that coordinates hyper parameter optimizations across the different possible algorithms and feature processing strategies.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Tuner strategy: [Bayesian](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization), [Random Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)\n",
    "2. Objective type: `Minimize`, `Maximize`, see [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "3. Max Job size: the max number of training jobs HPO would be launching to run experiments. Note the default value is **250**\n",
    "    which is the default of the managed flow.\n",
    "4. Parallelism. Number of jobs that will be executed in parallel. Higher value will expedite the tuning process.\n",
    "    Please check the account limits to increase the limits before increasing the number of jobs to run in parallel\n",
    "5. Please use a different tuning job name if you re-run this cell after applied customizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "base_tuning_job_name = \"{}-tuning\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name)\n",
    "\n",
    "tuner = HyperparameterTuner.create(\n",
    "    base_tuning_job_name=base_tuning_job_name,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Minimize',\n",
    "    max_parallel_jobs=2,\n",
    "    max_jobs=100,\n",
    "    **multi_algo_tuning_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Multi-Algorithm Tuning\n",
    "\n",
    "Now you are ready to start running the **Multi-Algo Tuning** job. After the job is finished, store the tuning job name which you use to select models in the next section.\n",
    "The tuning process will take some time, please track the progress in the Amazon SageMaker Hyperparameter tuning jobs console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 11:38:23,075 INFO sagemaker.tuner: _TuningJob.start_new!!!\n",
      "2020-12-03 11:38:23,078 INFO sagemaker: Creating hyperparameter tuning job with name: niy-Apr-20-notebook--201203-1138\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tuning Job niy-Apr-20-notebook--201203-1138 started, please track the progress from [here](https://eu-central-1.console.aws.amazon.com/sagemaker/home?region=eu-central-1#/hyper-tuning-jobs/niy-Apr-20-notebook--201203-1138)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Run tuning\n",
    "tuner.fit(inputs=multi_algo_tuning_inputs, include_cls_metadata=None)\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "display(\n",
    "    Markdown(f\"Tuning Job {tuning_job_name} started, please track the progress from [here](https://{AUTOML_LOCAL_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_RUN_CONFIG.region}#/hyper-tuning-jobs/{tuning_job_name})\"))\n",
    "\n",
    "# Wait for tuning job to finish\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Deployment\n",
    "\n",
    "This section guides you through the model selection process. Afterward, you construct an inference pipeline\n",
    "on Amazon SageMaker to host the best candidate.\n",
    "\n",
    "Because you executed the feature transformation and algorithm training in two separate steps, you now need to manually\n",
    "link each trained model with the feature transformer that it is associated with. When running a regular Amazon\n",
    "SageMaker Autopilot job, this will automatically be done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Job Result Overview\n",
    "\n",
    "The performance of each candidate pipeline can be viewed as a Pandas dataframe. For more interactive usage please\n",
    "refers to [model tuning monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingJobDefinitionName</th>\n",
       "      <th>...</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>num_round</th>\n",
       "      <th>subsample</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>embedding_size_factor</th>\n",
       "      <th>layers</th>\n",
       "      <th>mini_batch_size</th>\n",
       "      <th>network_type</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-077-ed92cba9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>112.364372</td>\n",
       "      <td>2020-12-03 14:41:35+01:00</td>\n",
       "      <td>2020-12-03 14:43:58+01:00</td>\n",
       "      <td>143.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.841792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-069-4a564742</td>\n",
       "      <td>Completed</td>\n",
       "      <td>115.137993</td>\n",
       "      <td>2020-12-03 14:18:07+01:00</td>\n",
       "      <td>2020-12-03 14:20:12+01:00</td>\n",
       "      <td>125.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.771873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-094-40cddec1</td>\n",
       "      <td>Completed</td>\n",
       "      <td>116.878860</td>\n",
       "      <td>2020-12-03 15:15:53+01:00</td>\n",
       "      <td>2020-12-03 15:16:58+01:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.515284</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.982084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-099-52485a29</td>\n",
       "      <td>Completed</td>\n",
       "      <td>118.013763</td>\n",
       "      <td>2020-12-03 15:27:50+01:00</td>\n",
       "      <td>2020-12-03 15:29:54+01:00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.959909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-098-4b1595c6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>119.172188</td>\n",
       "      <td>2020-12-03 15:23:30+01:00</td>\n",
       "      <td>2020-12-03 15:26:01+01:00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.785819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-091-fdcad7ba</td>\n",
       "      <td>Completed</td>\n",
       "      <td>121.680878</td>\n",
       "      <td>2020-12-03 15:11:29+01:00</td>\n",
       "      <td>2020-12-03 15:13:34+01:00</td>\n",
       "      <td>125.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.570702</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.878672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-093-622bb41a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>124.040466</td>\n",
       "      <td>2020-12-03 15:15:36+01:00</td>\n",
       "      <td>2020-12-03 15:17:27+01:00</td>\n",
       "      <td>111.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.687855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-082-fc5f9c06</td>\n",
       "      <td>Completed</td>\n",
       "      <td>124.662079</td>\n",
       "      <td>2020-12-03 14:51:22+01:00</td>\n",
       "      <td>2020-12-03 14:52:54+01:00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>605.0</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-066-474c7ea8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>127.815331</td>\n",
       "      <td>2020-12-03 14:13:32+01:00</td>\n",
       "      <td>2020-12-03 14:14:43+01:00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.125752</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.567103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-087-7d0c8742</td>\n",
       "      <td>Completed</td>\n",
       "      <td>128.604858</td>\n",
       "      <td>2020-12-03 15:03:09+01:00</td>\n",
       "      <td>2020-12-03 15:05:28+01:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>946.0</td>\n",
       "      <td>0.662445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-067-93bacab3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>129.130157</td>\n",
       "      <td>2020-12-03 14:14:00+01:00</td>\n",
       "      <td>2020-12-03 14:15:53+01:00</td>\n",
       "      <td>113.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.053415</td>\n",
       "      <td>727.0</td>\n",
       "      <td>0.872264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-044-d62d74c9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>130.724442</td>\n",
       "      <td>2020-12-03 13:07:19+01:00</td>\n",
       "      <td>2020-12-03 13:08:36+01:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>dpp1-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008359</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.952344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-075-e540b57a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>133.142303</td>\n",
       "      <td>2020-12-03 14:37:20+01:00</td>\n",
       "      <td>2020-12-03 14:39:18+01:00</td>\n",
       "      <td>118.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>947.0</td>\n",
       "      <td>0.972641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-080-84f08d5c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>133.795059</td>\n",
       "      <td>2020-12-03 14:47:11+01:00</td>\n",
       "      <td>2020-12-03 14:48:42+01:00</td>\n",
       "      <td>91.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-083-60d111f8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>134.346375</td>\n",
       "      <td>2020-12-03 14:55:10+01:00</td>\n",
       "      <td>2020-12-03 14:56:49+01:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0.532697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-060-78e57984</td>\n",
       "      <td>Completed</td>\n",
       "      <td>134.394287</td>\n",
       "      <td>2020-12-03 14:01:28+01:00</td>\n",
       "      <td>2020-12-03 14:03:21+01:00</td>\n",
       "      <td>113.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>687.0</td>\n",
       "      <td>0.864131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-079-c3a283ce</td>\n",
       "      <td>Completed</td>\n",
       "      <td>134.946976</td>\n",
       "      <td>2020-12-03 14:46:53+01:00</td>\n",
       "      <td>2020-12-03 14:48:35+01:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.243345</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-085-af8206e4</td>\n",
       "      <td>Completed</td>\n",
       "      <td>137.156082</td>\n",
       "      <td>2020-12-03 14:58:56+01:00</td>\n",
       "      <td>2020-12-03 15:01:20+01:00</td>\n",
       "      <td>144.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>752.0</td>\n",
       "      <td>0.594818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-089-4088e30d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>137.181808</td>\n",
       "      <td>2020-12-03 15:07:15+01:00</td>\n",
       "      <td>2020-12-03 15:09:10+01:00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.808820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>niy-Apr-20-notebook--201203-1138-090-19d8f065</td>\n",
       "      <td>Completed</td>\n",
       "      <td>143.068924</td>\n",
       "      <td>2020-12-03 15:07:55+01:00</td>\n",
       "      <td>2020-12-03 15:10:10+01:00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    l1  learning_rate  wd                                TrainingJobName  \\\n",
       "23 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-077-ed92cba9   \n",
       "31 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-069-4a564742   \n",
       "6  NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-094-40cddec1   \n",
       "1  NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-099-52485a29   \n",
       "2  NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-098-4b1595c6   \n",
       "9  NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-091-fdcad7ba   \n",
       "7  NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-093-622bb41a   \n",
       "18 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-082-fc5f9c06   \n",
       "34 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-066-474c7ea8   \n",
       "13 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-087-7d0c8742   \n",
       "33 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-067-93bacab3   \n",
       "56 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-044-d62d74c9   \n",
       "25 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-075-e540b57a   \n",
       "20 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-080-84f08d5c   \n",
       "17 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-083-60d111f8   \n",
       "40 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-060-78e57984   \n",
       "21 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-079-c3a283ce   \n",
       "15 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-085-af8206e4   \n",
       "11 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-089-4088e30d   \n",
       "10 NaN            NaN NaN  niy-Apr-20-notebook--201203-1138-090-19d8f065   \n",
       "\n",
       "   TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "23         Completed           112.364372 2020-12-03 14:41:35+01:00   \n",
       "31         Completed           115.137993 2020-12-03 14:18:07+01:00   \n",
       "6          Completed           116.878860 2020-12-03 15:15:53+01:00   \n",
       "1          Completed           118.013763 2020-12-03 15:27:50+01:00   \n",
       "2          Completed           119.172188 2020-12-03 15:23:30+01:00   \n",
       "9          Completed           121.680878 2020-12-03 15:11:29+01:00   \n",
       "7          Completed           124.040466 2020-12-03 15:15:36+01:00   \n",
       "18         Completed           124.662079 2020-12-03 14:51:22+01:00   \n",
       "34         Completed           127.815331 2020-12-03 14:13:32+01:00   \n",
       "13         Completed           128.604858 2020-12-03 15:03:09+01:00   \n",
       "33         Completed           129.130157 2020-12-03 14:14:00+01:00   \n",
       "56         Completed           130.724442 2020-12-03 13:07:19+01:00   \n",
       "25         Completed           133.142303 2020-12-03 14:37:20+01:00   \n",
       "20         Completed           133.795059 2020-12-03 14:47:11+01:00   \n",
       "17         Completed           134.346375 2020-12-03 14:55:10+01:00   \n",
       "40         Completed           134.394287 2020-12-03 14:01:28+01:00   \n",
       "21         Completed           134.946976 2020-12-03 14:46:53+01:00   \n",
       "15         Completed           137.156082 2020-12-03 14:58:56+01:00   \n",
       "11         Completed           137.181808 2020-12-03 15:07:15+01:00   \n",
       "10         Completed           143.068924 2020-12-03 15:07:55+01:00   \n",
       "\n",
       "             TrainingEndTime  TrainingElapsedTimeSeconds  \\\n",
       "23 2020-12-03 14:43:58+01:00                       143.0   \n",
       "31 2020-12-03 14:20:12+01:00                       125.0   \n",
       "6  2020-12-03 15:16:58+01:00                        65.0   \n",
       "1  2020-12-03 15:29:54+01:00                       124.0   \n",
       "2  2020-12-03 15:26:01+01:00                       151.0   \n",
       "9  2020-12-03 15:13:34+01:00                       125.0   \n",
       "7  2020-12-03 15:17:27+01:00                       111.0   \n",
       "18 2020-12-03 14:52:54+01:00                        92.0   \n",
       "34 2020-12-03 14:14:43+01:00                        71.0   \n",
       "13 2020-12-03 15:05:28+01:00                       139.0   \n",
       "33 2020-12-03 14:15:53+01:00                       113.0   \n",
       "56 2020-12-03 13:08:36+01:00                        77.0   \n",
       "25 2020-12-03 14:39:18+01:00                       118.0   \n",
       "20 2020-12-03 14:48:42+01:00                        91.0   \n",
       "17 2020-12-03 14:56:49+01:00                        99.0   \n",
       "40 2020-12-03 14:03:21+01:00                       113.0   \n",
       "21 2020-12-03 14:48:35+01:00                       102.0   \n",
       "15 2020-12-03 15:01:20+01:00                       144.0   \n",
       "11 2020-12-03 15:09:10+01:00                       115.0   \n",
       "10 2020-12-03 15:10:10+01:00                       135.0   \n",
       "\n",
       "   TrainingJobDefinitionName  ...  max_depth  min_child_weight  num_round  \\\n",
       "23              dpp6-xgboost  ...        6.0          0.000246     1019.0   \n",
       "31              dpp6-xgboost  ...        8.0          0.000002      681.0   \n",
       "6               dpp6-xgboost  ...        7.0          4.515284      222.0   \n",
       "1               dpp6-xgboost  ...        6.0          0.000001      916.0   \n",
       "2               dpp6-xgboost  ...        8.0          0.000025      919.0   \n",
       "9               dpp6-xgboost  ...        8.0          1.570702      753.0   \n",
       "7               dpp6-xgboost  ...        6.0          0.000004      758.0   \n",
       "18              dpp6-xgboost  ...        5.0          0.000410      605.0   \n",
       "34              dpp3-xgboost  ...        6.0          3.125752      255.0   \n",
       "13              dpp6-xgboost  ...        7.0          0.000001      946.0   \n",
       "33              dpp6-xgboost  ...        6.0          0.053415      727.0   \n",
       "56              dpp1-xgboost  ...        6.0          0.008359      407.0   \n",
       "25              dpp6-xgboost  ...        5.0          0.000032      947.0   \n",
       "20              dpp6-xgboost  ...        8.0          0.000001      452.0   \n",
       "17              dpp6-xgboost  ...        5.0          0.013156      660.0   \n",
       "40              dpp6-xgboost  ...        6.0          0.000001      687.0   \n",
       "21              dpp6-xgboost  ...        8.0          1.243345      570.0   \n",
       "15              dpp6-xgboost  ...        8.0          0.000035      752.0   \n",
       "11              dpp6-xgboost  ...        7.0          0.000030      566.0   \n",
       "10              dpp6-xgboost  ...        5.0          0.000007     1024.0   \n",
       "\n",
       "    subsample  dropout_prob  embedding_size_factor  layers  mini_batch_size  \\\n",
       "23   0.841792           NaN                    NaN     NaN              NaN   \n",
       "31   0.771873           NaN                    NaN     NaN              NaN   \n",
       "6    0.982084           NaN                    NaN     NaN              NaN   \n",
       "1    0.959909           NaN                    NaN     NaN              NaN   \n",
       "2    0.785819           NaN                    NaN     NaN              NaN   \n",
       "9    0.878672           NaN                    NaN     NaN              NaN   \n",
       "7    0.687855           NaN                    NaN     NaN              NaN   \n",
       "18   0.762083           NaN                    NaN     NaN              NaN   \n",
       "34   0.567103           NaN                    NaN     NaN              NaN   \n",
       "13   0.662445           NaN                    NaN     NaN              NaN   \n",
       "33   0.872264           NaN                    NaN     NaN              NaN   \n",
       "56   0.952344           NaN                    NaN     NaN              NaN   \n",
       "25   0.972641           NaN                    NaN     NaN              NaN   \n",
       "20   0.970455           NaN                    NaN     NaN              NaN   \n",
       "17   0.532697           NaN                    NaN     NaN              NaN   \n",
       "40   0.864131           NaN                    NaN     NaN              NaN   \n",
       "21   0.888925           NaN                    NaN     NaN              NaN   \n",
       "15   0.594818           NaN                    NaN     NaN              NaN   \n",
       "11   0.808820           NaN                    NaN     NaN              NaN   \n",
       "10   0.741689           NaN                    NaN     NaN              NaN   \n",
       "\n",
       "    network_type  weight_decay  \n",
       "23           NaN           NaN  \n",
       "31           NaN           NaN  \n",
       "6            NaN           NaN  \n",
       "1            NaN           NaN  \n",
       "2            NaN           NaN  \n",
       "9            NaN           NaN  \n",
       "7            NaN           NaN  \n",
       "18           NaN           NaN  \n",
       "34           NaN           NaN  \n",
       "13           NaN           NaN  \n",
       "33           NaN           NaN  \n",
       "56           NaN           NaN  \n",
       "25           NaN           NaN  \n",
       "20           NaN           NaN  \n",
       "17           NaN           NaN  \n",
       "40           NaN           NaN  \n",
       "21           NaN           NaN  \n",
       "15           NaN           NaN  \n",
       "11           NaN           NaN  \n",
       "10           NaN           NaN  \n",
       "\n",
       "[20 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "SAGEMAKER_SESSION = AUTOML_LOCAL_RUN_CONFIG.sagemaker_session\n",
    "SAGEMAKER_ROLE = AUTOML_LOCAL_RUN_CONFIG.role\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best training job can be selected as below:\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Tips: </strong>\n",
    "You could select alternative job by using the value from `TrainingJobName` column above and assign to `best_training_job` below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 15:32:21,495 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,545 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,546 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,548 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,567 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,568 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,569 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:32:21,572 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Best Multi Algorithm HPO training job name is niy-Apr-20-notebook--201203-1138-077-ed92cba9\n"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "best_training_job = attached_tuner.best_training_job()\n",
    "\n",
    "print(\"Best Multi Algorithm HPO training job name is {}\".format(best_training_job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Best Training Job with Feature Pipelines\n",
    "\n",
    "Finally, deploy the best training job to Amazon SageMaker along with its companion feature engineering models.\n",
    "At the end of the section, you get an endpoint that's ready to serve online inference or start batch transform jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/pipeline.html) that has multiple containers of the following:\n",
    "\n",
    "1. Data Transformation Container: a container built from the model we selected and trained during the data transformer sections\n",
    "2. Algorithm Container: a container built from the trained model we selected above from the best HPO training job.\n",
    "\n",
    "Get both best data transformation model and algorithm model from best training job and create an pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 15:33:20,952 INFO root: Chosen Data Processing pipeline candidate name is dpp6-xgboost\n",
      "2020-12-03 15:33:21,387 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:33:21,392 WARNING sagemaker: This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "2020-12-03 10:23:10 Starting - Preparing the instances for training\n",
      "2020-12-03 10:23:10 Downloading - Downloading input data\n",
      "2020-12-03 10:23:10 Training - Training image download completed. Training in progress.\n",
      "2020-12-03 10:23:10 Uploading - Uploading generated training model\n",
      "2020-12-03 10:23:10 Completed - Training job completed\u001b[34m2020-12-03 10:22:38,052 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:38,053 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:38,062 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:38,344 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:44,603 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:44,614 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:44,622 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"processor_module\": \"dpp6\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://niy-certification/niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"processor_module\":\"dpp6\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://niy-certification/niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"processor_module\":\"dpp6\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://niy-certification/niy-Apr-20-notebook-run-03-09-54-38-dpp6-train-03-09-55-25/source/sourcedir.tar.gz\",\"module_name\":\"trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--processor_module\",\"dpp6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSOR_MODULE=dpp6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python trainer.py --processor_module dpp6\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-03 10:22:59,305 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n",
      "2020-12-03 15:33:26,985 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 15:33:27,044 INFO botocore.credentials: Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2020-12-03 15:33:27,425 WARNING sagemaker.estimator: Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-12-03 13:43:58 Starting - Preparing the instances for training\n",
      "2020-12-03 13:43:58 Downloading - Downloading input data\n",
      "2020-12-03 13:43:58 Training - Training image download completed. Training in progress.\n",
      "2020-12-03 13:43:58 Uploading - Uploading generated training model\n",
      "2020-12-03 13:43:58 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:mse to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : mse\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 416607 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 104126 rows\u001b[0m\n",
      "\u001b[34m[13:42:20] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { _tuning_objective_metric, num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:45.77851#011validation-rmse:46.25512#011train-mse:2095.50488#011validation-mse:2139.60352\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:41.17813#011validation-rmse:41.45515#011train-mse:1695.67798#011validation-mse:1718.55102\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:38.62502#011validation-rmse:38.88685#011train-mse:1491.89514#011validation-mse:1512.20032\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:37.32994#011validation-rmse:37.67136#011train-mse:1393.54846#011validation-mse:1419.11853\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:36.93793#011validation-rmse:37.29937#011train-mse:1364.41419#011validation-mse:1391.24524\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:36.58553#011validation-rmse:36.98772#011train-mse:1338.49206#011validation-mse:1368.09021\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:33.55387#011validation-rmse:33.93628#011train-mse:1125.84045#011validation-mse:1151.67114\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:33.29797#011validation-rmse:33.71390#011train-mse:1108.74976#011validation-mse:1136.62439\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:33.12137#011validation-rmse:33.54437#011train-mse:1097.02173#011validation-mse:1125.22363\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:32.98365#011validation-rmse:33.40704#011train-mse:1087.91431#011validation-mse:1116.02991\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:31.63973#011validation-rmse:32.09453#011train-mse:1001.07745#011validation-mse:1030.06140\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:29.54910#011validation-rmse:29.86734#011train-mse:873.14728#011validation-mse:892.06079\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:28.52839#011validation-rmse:28.77277#011train-mse:813.87775#011validation-mse:827.87329\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:28.44596#011validation-rmse:28.71034#011train-mse:809.16534#011validation-mse:824.28375\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:28.23532#011validation-rmse:28.51533#011train-mse:797.24182#011validation-mse:813.12433\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:28.07573#011validation-rmse:28.37300#011train-mse:788.24445#011validation-mse:805.02808\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:27.29519#011validation-rmse:27.53046#011train-mse:745.02417#011validation-mse:757.92700\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:27.19545#011validation-rmse:27.47352#011train-mse:739.59265#011validation-mse:754.79468\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:27.11496#011validation-rmse:27.40568#011train-mse:735.22534#011validation-mse:751.06982\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:26.22452#011validation-rmse:26.48621#011train-mse:687.72760#011validation-mse:701.51910\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:25.63283#011validation-rmse:25.85630#011train-mse:657.04712#011validation-mse:668.54785\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:23.97258#011validation-rmse:24.24748#011train-mse:574.68250#011validation-mse:587.94049\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:23.91287#011validation-rmse:24.21658#011train-mse:571.82593#011validation-mse:586.44214\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:22.30534#011validation-rmse:22.67575#011train-mse:497.53070#011validation-mse:514.18921\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:22.25489#011validation-rmse:22.65052#011train-mse:495.28052#011validation-mse:513.04620\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:22.19896#011validation-rmse:22.61688#011train-mse:492.79492#011validation-mse:511.52347\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:22.07746#011validation-rmse:22.53175#011train-mse:487.41434#011validation-mse:507.67999\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:21.98428#011validation-rmse:22.45865#011train-mse:483.30981#011validation-mse:504.39072\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:21.93295#011validation-rmse:22.41718#011train-mse:481.05499#011validation-mse:502.52994\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:21.58315#011validation-rmse:22.07865#011train-mse:465.83276#011validation-mse:487.46692\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:21.48575#011validation-rmse:22.02295#011train-mse:461.63763#011validation-mse:485.01034\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:21.41864#011validation-rmse:21.97172#011train-mse:458.75873#011validation-mse:482.75650\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:20.74434#011validation-rmse:21.25037#011train-mse:430.32871#011validation-mse:451.57812\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:20.16773#011validation-rmse:20.60352#011train-mse:406.73773#011validation-mse:424.50500\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:20.07664#011validation-rmse:20.55300#011train-mse:403.07153#011validation-mse:422.42584\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:20.01028#011validation-rmse:20.51963#011train-mse:400.41223#011validation-mse:421.05502\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:18.64429#011validation-rmse:19.10641#011train-mse:347.60950#011validation-mse:365.05524\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:18.58911#011validation-rmse:19.09951#011train-mse:345.55597#011validation-mse:364.79147\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:18.31719#011validation-rmse:18.82669#011train-mse:335.52035#011validation-mse:354.44409\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:17.53983#011validation-rmse:18.02516#011train-mse:307.64630#011validation-mse:324.90656\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:16.87292#011validation-rmse:17.36429#011train-mse:284.69605#011validation-mse:301.51862\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:16.85656#011validation-rmse:17.35407#011train-mse:284.14450#011validation-mse:301.16394\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:16.82767#011validation-rmse:17.34000#011train-mse:283.17056#011validation-mse:300.67560\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:16.79217#011validation-rmse:17.30850#011train-mse:281.97775#011validation-mse:299.58402\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:16.77611#011validation-rmse:17.29783#011train-mse:281.43863#011validation-mse:299.21503\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:16.00099#011validation-rmse:16.62188#011train-mse:256.03213#011validation-mse:276.28680\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:15.98561#011validation-rmse:16.61662#011train-mse:255.53995#011validation-mse:276.11215\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:15.93369#011validation-rmse:16.59662#011train-mse:253.88301#011validation-mse:275.44791\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:15.90406#011validation-rmse:16.57377#011train-mse:252.93973#011validation-mse:274.68994\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:15.85795#011validation-rmse:16.52817#011train-mse:251.47485#011validation-mse:273.18051\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:15.30836#011validation-rmse:16.02719#011train-mse:234.34663#011validation-mse:256.87091\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:15.25419#011validation-rmse:15.97625#011train-mse:232.69090#011validation-mse:255.24056\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:15.05585#011validation-rmse:15.80989#011train-mse:226.67944#011validation-mse:249.95256\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:14.89135#011validation-rmse:15.69769#011train-mse:221.75285#011validation-mse:246.41753\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:14.79622#011validation-rmse:15.66656#011train-mse:218.92835#011validation-mse:245.44124\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:14.74166#011validation-rmse:15.64484#011train-mse:217.31712#011validation-mse:244.76128\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:14.71331#011validation-rmse:15.62966#011train-mse:216.48196#011validation-mse:244.28641\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:14.66158#011validation-rmse:15.61609#011train-mse:214.96242#011validation-mse:243.86240\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:14.64065#011validation-rmse:15.60675#011train-mse:214.34912#011validation-mse:243.57071\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:14.60961#011validation-rmse:15.59510#011train-mse:213.44113#011validation-mse:243.20735\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:14.34520#011validation-rmse:15.34818#011train-mse:205.78540#011validation-mse:235.56656\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:14.30801#011validation-rmse:15.28757#011train-mse:204.71956#011validation-mse:233.71004\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:13.86379#011validation-rmse:14.87261#011train-mse:192.20541#011validation-mse:221.19485\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:13.70151#011validation-rmse:14.69370#011train-mse:187.73193#011validation-mse:215.90500\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:13.67892#011validation-rmse:14.68249#011train-mse:187.11351#011validation-mse:215.57568\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:13.66699#011validation-rmse:14.67561#011train-mse:186.78737#011validation-mse:215.37354\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:13.62496#011validation-rmse:14.66386#011train-mse:185.63980#011validation-mse:215.02893\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:13.59997#011validation-rmse:14.65608#011train-mse:184.95958#011validation-mse:214.80069\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:13.58217#011validation-rmse:14.64315#011train-mse:184.47584#011validation-mse:214.42188\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:13.56824#011validation-rmse:14.64133#011train-mse:184.09772#011validation-mse:214.36842\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:13.55174#011validation-rmse:14.62433#011train-mse:183.65028#011validation-mse:213.87120\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:13.53381#011validation-rmse:14.62021#011train-mse:183.16449#011validation-mse:213.75049\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:13.51463#011validation-rmse:14.60794#011train-mse:182.64563#011validation-mse:213.39197\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:13.33232#011validation-rmse:14.44794#011train-mse:177.75125#011validation-mse:208.74283\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:13.17444#011validation-rmse:14.34402#011train-mse:173.56654#011validation-mse:205.75105\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:12.91611#011validation-rmse:14.12628#011train-mse:166.82654#011validation-mse:199.55193\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:12.61164#011validation-rmse:13.90317#011train-mse:159.05412#011validation-mse:193.29843\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:12.58573#011validation-rmse:13.88996#011train-mse:158.40111#011validation-mse:192.93112\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:12.57185#011validation-rmse:13.87839#011train-mse:158.05179#011validation-mse:192.60996\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:12.51952#011validation-rmse:13.85270#011train-mse:156.73906#011validation-mse:191.89740\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:12.49431#011validation-rmse:13.83311#011train-mse:156.10818#011validation-mse:191.35522\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:12.20724#011validation-rmse:13.60168#011train-mse:149.01717#011validation-mse:185.00581\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:12.18783#011validation-rmse:13.59282#011train-mse:148.54350#011validation-mse:184.76462\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:12.15746#011validation-rmse:13.57433#011train-mse:147.80440#011validation-mse:184.26268\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:12.11629#011validation-rmse:13.55002#011train-mse:146.80501#011validation-mse:183.60323\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:12.10820#011validation-rmse:13.54386#011train-mse:146.60902#011validation-mse:183.43626\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:12.06631#011validation-rmse:13.53153#011train-mse:145.59636#011validation-mse:183.10237\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:12.05081#011validation-rmse:13.52357#011train-mse:145.22252#011validation-mse:182.88687\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:12.00767#011validation-rmse:13.50700#011train-mse:144.18468#011validation-mse:182.43919\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:11.99477#011validation-rmse:13.50210#011train-mse:143.87506#011validation-mse:182.30675\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:11.98444#011validation-rmse:13.49545#011train-mse:143.62721#011validation-mse:182.12717\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:11.97467#011validation-rmse:13.48777#011train-mse:143.39325#011validation-mse:181.92006\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:11.73885#011validation-rmse:13.29151#011train-mse:137.80116#011validation-mse:176.66435\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:11.62996#011validation-rmse:13.19920#011train-mse:135.25659#011validation-mse:174.21905\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:11.46525#011validation-rmse:13.08051#011train-mse:131.45248#011validation-mse:171.09975\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:11.30942#011validation-rmse:12.97875#011train-mse:127.90331#011validation-mse:168.44815\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:11.28887#011validation-rmse:12.97213#011train-mse:127.43906#011validation-mse:168.27634\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:11.06756#011validation-rmse:12.80806#011train-mse:122.49146#011validation-mse:164.04652\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:11.04838#011validation-rmse:12.80292#011train-mse:122.06727#011validation-mse:163.91492\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:11.03532#011validation-rmse:12.79360#011train-mse:121.77895#011validation-mse:163.67641\u001b[0m\n",
      "\u001b[34m[100]#011train-rmse:11.01545#011validation-rmse:12.78060#011train-mse:121.34081#011validation-mse:163.34383\u001b[0m\n",
      "\u001b[34m[101]#011train-rmse:10.99563#011validation-rmse:12.77096#011train-mse:120.90440#011validation-mse:163.09747\u001b[0m\n",
      "\u001b[34m[102]#011train-rmse:10.98545#011validation-rmse:12.76472#011train-mse:120.68067#011validation-mse:162.93820\u001b[0m\n",
      "\u001b[34m[103]#011train-rmse:10.95756#011validation-rmse:12.74427#011train-mse:120.06862#011validation-mse:162.41641\u001b[0m\n",
      "\u001b[34m[104]#011train-rmse:10.91817#011validation-rmse:12.74094#011train-mse:119.20688#011validation-mse:162.33160\u001b[0m\n",
      "\u001b[34m[105]#011train-rmse:10.75065#011validation-rmse:12.59479#011train-mse:115.57694#011validation-mse:158.62869\u001b[0m\n",
      "\u001b[34m[106]#011train-rmse:10.74142#011validation-rmse:12.58763#011train-mse:115.37841#011validation-mse:158.44847\u001b[0m\n",
      "\u001b[34m[107]#011train-rmse:10.72245#011validation-rmse:12.57689#011train-mse:114.97138#011validation-mse:158.17844\u001b[0m\n",
      "\u001b[34m[108]#011train-rmse:10.58193#011validation-rmse:12.50458#011train-mse:111.97770#011validation-mse:156.36450\u001b[0m\n",
      "\u001b[34m[109]#011train-rmse:10.56735#011validation-rmse:12.49404#011train-mse:111.66940#011validation-mse:156.10121\u001b[0m\n",
      "\u001b[34m[110]#011train-rmse:10.54737#011validation-rmse:12.48264#011train-mse:111.24760#011validation-mse:155.81639\u001b[0m\n",
      "\u001b[34m[111]#011train-rmse:10.53913#011validation-rmse:12.47673#011train-mse:111.07367#011validation-mse:155.66898\u001b[0m\n",
      "\u001b[34m[112]#011train-rmse:10.53256#011validation-rmse:12.47247#011train-mse:110.93529#011validation-mse:155.56284\u001b[0m\n",
      "\u001b[34m[113]#011train-rmse:10.51916#011validation-rmse:12.46798#011train-mse:110.65318#011validation-mse:155.45070\u001b[0m\n",
      "\u001b[34m[114]#011train-rmse:10.51254#011validation-rmse:12.46384#011train-mse:110.51394#011validation-mse:155.34752\u001b[0m\n",
      "\u001b[34m[115]#011train-rmse:10.47798#011validation-rmse:12.43385#011train-mse:109.78858#011validation-mse:154.60066\u001b[0m\n",
      "\u001b[34m[116]#011train-rmse:10.47303#011validation-rmse:12.43086#011train-mse:109.68476#011validation-mse:154.52622\u001b[0m\n",
      "\u001b[34m[117]#011train-rmse:10.33697#011validation-rmse:12.33323#011train-mse:106.85349#011validation-mse:152.10875\u001b[0m\n",
      "\u001b[34m[118]#011train-rmse:10.31715#011validation-rmse:12.31745#011train-mse:106.44425#011validation-mse:151.71968\u001b[0m\n",
      "\u001b[34m[119]#011train-rmse:10.28682#011validation-rmse:12.28325#011train-mse:105.81915#011validation-mse:150.87840\u001b[0m\n",
      "\u001b[34m[120]#011train-rmse:10.27153#011validation-rmse:12.26729#011train-mse:105.50470#011validation-mse:150.48660\u001b[0m\n",
      "\u001b[34m[121]#011train-rmse:10.25374#011validation-rmse:12.26387#011train-mse:105.13963#011validation-mse:150.40263\u001b[0m\n",
      "\u001b[34m[122]#011train-rmse:10.24553#011validation-rmse:12.25591#011train-mse:104.97141#011validation-mse:150.20743\u001b[0m\n",
      "\u001b[34m[123]#011train-rmse:10.09089#011validation-rmse:12.18781#011train-mse:101.82661#011validation-mse:148.54279\u001b[0m\n",
      "\u001b[34m[124]#011train-rmse:10.04698#011validation-rmse:12.14849#011train-mse:100.94237#011validation-mse:147.58604\u001b[0m\n",
      "\u001b[34m[125]#011train-rmse:9.91013#011validation-rmse:12.05669#011train-mse:98.21124#011validation-mse:145.36404\u001b[0m\n",
      "\u001b[34m[126]#011train-rmse:9.82226#011validation-rmse:11.98722#011train-mse:96.47730#011validation-mse:143.69383\u001b[0m\n",
      "\u001b[34m[127]#011train-rmse:9.81131#011validation-rmse:11.98028#011train-mse:96.26219#011validation-mse:143.52718\u001b[0m\n",
      "\u001b[34m[128]#011train-rmse:9.80371#011validation-rmse:11.97592#011train-mse:96.11330#011validation-mse:143.42274\u001b[0m\n",
      "\u001b[34m[129]#011train-rmse:9.79083#011validation-rmse:11.97064#011train-mse:95.86089#011validation-mse:143.29643\u001b[0m\n",
      "\u001b[34m[130]#011train-rmse:9.78562#011validation-rmse:11.96816#011train-mse:95.75880#011validation-mse:143.23697\u001b[0m\n",
      "\u001b[34m[131]#011train-rmse:9.75163#011validation-rmse:11.94101#011train-mse:95.09466#011validation-mse:142.58791\u001b[0m\n",
      "\u001b[34m[132]#011train-rmse:9.73909#011validation-rmse:11.93304#011train-mse:94.85020#011validation-mse:142.39766\u001b[0m\n",
      "\u001b[34m[133]#011train-rmse:9.73484#011validation-rmse:11.92950#011train-mse:94.76759#011validation-mse:142.31299\u001b[0m\n",
      "\u001b[34m[134]#011train-rmse:9.72731#011validation-rmse:11.92725#011train-mse:94.62112#011validation-mse:142.25941\u001b[0m\n",
      "\u001b[34m[135]#011train-rmse:9.63609#011validation-rmse:11.89940#011train-mse:92.85488#011validation-mse:141.59589\u001b[0m\n",
      "\u001b[34m[136]#011train-rmse:9.62907#011validation-rmse:11.89739#011train-mse:92.71960#011validation-mse:141.54793\u001b[0m\n",
      "\u001b[34m[137]#011train-rmse:9.62350#011validation-rmse:11.89176#011train-mse:92.61223#011validation-mse:141.41414\u001b[0m\n",
      "\u001b[34m[138]#011train-rmse:9.59456#011validation-rmse:11.88720#011train-mse:92.05608#011validation-mse:141.30568\u001b[0m\n",
      "\u001b[34m[139]#011train-rmse:9.58715#011validation-rmse:11.87952#011train-mse:91.91389#011validation-mse:141.12306\u001b[0m\n",
      "\u001b[34m[140]#011train-rmse:9.58281#011validation-rmse:11.87666#011train-mse:91.83083#011validation-mse:141.05547\u001b[0m\n",
      "\u001b[34m[141]#011train-rmse:9.57344#011validation-rmse:11.87098#011train-mse:91.65125#011validation-mse:140.92023\u001b[0m\n",
      "\u001b[34m[142]#011train-rmse:9.51585#011validation-rmse:11.86684#011train-mse:90.55184#011validation-mse:140.82217\u001b[0m\n",
      "\u001b[34m[143]#011train-rmse:9.42672#011validation-rmse:11.79856#011train-mse:88.86349#011validation-mse:139.20625\u001b[0m\n",
      "\u001b[34m[144]#011train-rmse:9.42244#011validation-rmse:11.79653#011train-mse:88.78281#011validation-mse:139.15836\u001b[0m\n",
      "\u001b[34m[145]#011train-rmse:9.41414#011validation-rmse:11.79433#011train-mse:88.62656#011validation-mse:139.10632\u001b[0m\n",
      "\u001b[34m[146]#011train-rmse:9.39915#011validation-rmse:11.79022#011train-mse:88.34445#011validation-mse:139.00931\u001b[0m\n",
      "\u001b[34m[147]#011train-rmse:9.39311#011validation-rmse:11.78660#011train-mse:88.23094#011validation-mse:138.92415\u001b[0m\n",
      "\u001b[34m[148]#011train-rmse:9.38598#011validation-rmse:11.78349#011train-mse:88.09714#011validation-mse:138.85091\u001b[0m\n",
      "\u001b[34m[149]#011train-rmse:9.38190#011validation-rmse:11.78165#011train-mse:88.02068#011validation-mse:138.80745\u001b[0m\n",
      "\u001b[34m[150]#011train-rmse:9.37757#011validation-rmse:11.77958#011train-mse:87.93933#011validation-mse:138.75865\u001b[0m\n",
      "\u001b[34m[151]#011train-rmse:9.37416#011validation-rmse:11.77712#011train-mse:87.87548#011validation-mse:138.70062\u001b[0m\n",
      "\u001b[34m[152]#011train-rmse:9.36788#011validation-rmse:11.77487#011train-mse:87.75764#011validation-mse:138.64784\u001b[0m\n",
      "\u001b[34m[153]#011train-rmse:9.35518#011validation-rmse:11.76606#011train-mse:87.51975#011validation-mse:138.44032\u001b[0m\n",
      "\u001b[34m[154]#011train-rmse:9.29384#011validation-rmse:11.73002#011train-mse:86.37595#011validation-mse:137.59343\u001b[0m\n",
      "\u001b[34m[155]#011train-rmse:9.25051#011validation-rmse:11.72841#011train-mse:85.57230#011validation-mse:137.55579\u001b[0m\n",
      "\u001b[34m[156]#011train-rmse:9.15142#011validation-rmse:11.66895#011train-mse:83.74894#011validation-mse:136.16452\u001b[0m\n",
      "\u001b[34m[157]#011train-rmse:9.14829#011validation-rmse:11.66668#011train-mse:83.69173#011validation-mse:136.11160\u001b[0m\n",
      "\u001b[34m[158]#011train-rmse:9.14189#011validation-rmse:11.66464#011train-mse:83.57465#011validation-mse:136.06415\u001b[0m\n",
      "\u001b[34m[159]#011train-rmse:9.07307#011validation-rmse:11.61280#011train-mse:82.32116#011validation-mse:134.85731\u001b[0m\n",
      "\u001b[34m[160]#011train-rmse:9.06800#011validation-rmse:11.61138#011train-mse:82.22922#011validation-mse:134.82440\u001b[0m\n",
      "\u001b[34m[161]#011train-rmse:9.02501#011validation-rmse:11.60834#011train-mse:81.45131#011validation-mse:134.75380\u001b[0m\n",
      "\u001b[34m[162]#011train-rmse:9.02230#011validation-rmse:11.60713#011train-mse:81.40234#011validation-mse:134.72563\u001b[0m\n",
      "\u001b[34m[163]#011train-rmse:9.00644#011validation-rmse:11.59734#011train-mse:81.11653#011validation-mse:134.49852\u001b[0m\n",
      "\u001b[34m[164]#011train-rmse:8.99948#011validation-rmse:11.59482#011train-mse:80.99111#011validation-mse:134.43994\u001b[0m\n",
      "\u001b[34m[165]#011train-rmse:8.97486#011validation-rmse:11.57294#011train-mse:80.54862#011validation-mse:133.93301\u001b[0m\n",
      "\u001b[34m[166]#011train-rmse:8.97163#011validation-rmse:11.57112#011train-mse:80.49062#011validation-mse:133.89099\u001b[0m\n",
      "\u001b[34m[167]#011train-rmse:8.96821#011validation-rmse:11.56888#011train-mse:80.42918#011validation-mse:133.83907\u001b[0m\n",
      "\u001b[34m[168]#011train-rmse:8.95765#011validation-rmse:11.56410#011train-mse:80.24007#011validation-mse:133.72875\u001b[0m\n",
      "\u001b[34m[169]#011train-rmse:8.95463#011validation-rmse:11.56324#011train-mse:80.18571#011validation-mse:133.70866\u001b[0m\n",
      "\u001b[34m[170]#011train-rmse:8.95137#011validation-rmse:11.56069#011train-mse:80.12755#011validation-mse:133.64972\u001b[0m\n",
      "\u001b[34m[171]#011train-rmse:8.90148#011validation-rmse:11.55881#011train-mse:79.23694#011validation-mse:133.60619\u001b[0m\n",
      "\u001b[34m[172]#011train-rmse:8.85399#011validation-rmse:11.54221#011train-mse:78.39381#011validation-mse:133.22267\u001b[0m\n",
      "\u001b[34m[173]#011train-rmse:8.84446#011validation-rmse:11.54147#011train-mse:78.22482#011validation-mse:133.20566\u001b[0m\n",
      "\u001b[34m[174]#011train-rmse:8.82348#011validation-rmse:11.53982#011train-mse:77.85421#011validation-mse:133.16766\u001b[0m\n",
      "\u001b[34m[175]#011train-rmse:8.80693#011validation-rmse:11.52817#011train-mse:77.56240#011validation-mse:132.89887\u001b[0m\n",
      "\u001b[34m[176]#011train-rmse:8.80429#011validation-rmse:11.52688#011train-mse:77.51608#011validation-mse:132.86908\u001b[0m\n",
      "\u001b[34m[177]#011train-rmse:8.80184#011validation-rmse:11.52563#011train-mse:77.47294#011validation-mse:132.84039\u001b[0m\n",
      "\u001b[34m[178]#011train-rmse:8.79880#011validation-rmse:11.52332#011train-mse:77.41934#011validation-mse:132.78709\u001b[0m\n",
      "\u001b[34m[179]#011train-rmse:8.79475#011validation-rmse:11.52106#011train-mse:77.34815#011validation-mse:132.73494\u001b[0m\n",
      "\u001b[34m[180]#011train-rmse:8.73017#011validation-rmse:11.46746#011train-mse:76.21639#011validation-mse:131.50279\u001b[0m\n",
      "\u001b[34m[181]#011train-rmse:8.71349#011validation-rmse:11.46631#011train-mse:75.92531#011validation-mse:131.47633\u001b[0m\n",
      "\u001b[34m[182]#011train-rmse:8.70778#011validation-rmse:11.46445#011train-mse:75.82598#011validation-mse:131.43385\u001b[0m\n",
      "\u001b[34m[183]#011train-rmse:8.70507#011validation-rmse:11.46322#011train-mse:75.77862#011validation-mse:131.40564\u001b[0m\n",
      "\u001b[34m[184]#011train-rmse:8.67755#011validation-rmse:11.44046#011train-mse:75.30046#011validation-mse:130.88415\u001b[0m\n",
      "\u001b[34m[185]#011train-rmse:8.63582#011validation-rmse:11.43858#011train-mse:74.57790#011validation-mse:130.84113\u001b[0m\n",
      "\u001b[34m[186]#011train-rmse:8.62807#011validation-rmse:11.43466#011train-mse:74.44399#011validation-mse:130.75166\u001b[0m\n",
      "\u001b[34m[187]#011train-rmse:8.62516#011validation-rmse:11.43364#011train-mse:74.39374#011validation-mse:130.72813\u001b[0m\n",
      "\u001b[34m[188]#011train-rmse:8.58880#011validation-rmse:11.43037#011train-mse:73.76784#011validation-mse:130.65359\u001b[0m\n",
      "\u001b[34m[189]#011train-rmse:8.58384#011validation-rmse:11.42645#011train-mse:73.68287#011validation-mse:130.56393\u001b[0m\n",
      "\u001b[34m[190]#011train-rmse:8.56852#011validation-rmse:11.41541#011train-mse:73.41997#011validation-mse:130.31166\u001b[0m\n",
      "\u001b[34m[191]#011train-rmse:8.52354#011validation-rmse:11.38460#011train-mse:72.65115#011validation-mse:129.60941\u001b[0m\n",
      "\u001b[34m[192]#011train-rmse:8.50294#011validation-rmse:11.38023#011train-mse:72.30045#011validation-mse:129.50975\u001b[0m\n",
      "\u001b[34m[193]#011train-rmse:8.50055#011validation-rmse:11.37917#011train-mse:72.25972#011validation-mse:129.48576\u001b[0m\n",
      "\u001b[34m[194]#011train-rmse:8.49188#011validation-rmse:11.38066#011train-mse:72.11247#011validation-mse:129.51970\u001b[0m\n",
      "\u001b[34m[195]#011train-rmse:8.48959#011validation-rmse:11.37975#011train-mse:72.07360#011validation-mse:129.49889\u001b[0m\n",
      "\u001b[34m[196]#011train-rmse:8.46277#011validation-rmse:11.37522#011train-mse:71.61900#011validation-mse:129.39581\u001b[0m\n",
      "\u001b[34m[197]#011train-rmse:8.42269#011validation-rmse:11.37435#011train-mse:70.94211#011validation-mse:129.37582\u001b[0m\n",
      "\u001b[34m[198]#011train-rmse:8.35560#011validation-rmse:11.34758#011train-mse:69.81648#011validation-mse:128.76773\u001b[0m\n",
      "\u001b[34m[199]#011train-rmse:8.34355#011validation-rmse:11.34646#011train-mse:69.61523#011validation-mse:128.74242\u001b[0m\n",
      "\u001b[34m[200]#011train-rmse:8.32171#011validation-rmse:11.33403#011train-mse:69.25132#011validation-mse:128.46028\u001b[0m\n",
      "\u001b[34m[201]#011train-rmse:8.31904#011validation-rmse:11.33280#011train-mse:69.20691#011validation-mse:128.43260\u001b[0m\n",
      "\u001b[34m[202]#011train-rmse:8.31520#011validation-rmse:11.33165#011train-mse:69.14300#011validation-mse:128.40649\u001b[0m\n",
      "\u001b[34m[203]#011train-rmse:8.31267#011validation-rmse:11.33060#011train-mse:69.10091#011validation-mse:128.38260\u001b[0m\n",
      "\u001b[34m[204]#011train-rmse:8.28091#011validation-rmse:11.32623#011train-mse:68.57385#011validation-mse:128.28351\u001b[0m\n",
      "\u001b[34m[205]#011train-rmse:8.26453#011validation-rmse:11.31433#011train-mse:68.30294#011validation-mse:128.01430\u001b[0m\n",
      "\u001b[34m[206]#011train-rmse:8.26369#011validation-rmse:11.31323#011train-mse:68.28891#011validation-mse:127.98932\u001b[0m\n",
      "\u001b[34m[207]#011train-rmse:8.26043#011validation-rmse:11.31244#011train-mse:68.23511#011validation-mse:127.97142\u001b[0m\n",
      "\u001b[34m[208]#011train-rmse:8.22871#011validation-rmse:11.28927#011train-mse:67.71210#011validation-mse:127.44794\u001b[0m\n",
      "\u001b[34m[209]#011train-rmse:8.20208#011validation-rmse:11.28757#011train-mse:67.27447#011validation-mse:127.40929\u001b[0m\n",
      "\u001b[34m[210]#011train-rmse:8.19986#011validation-rmse:11.28643#011train-mse:67.23808#011validation-mse:127.38361\u001b[0m\n",
      "\u001b[34m[211]#011train-rmse:8.19803#011validation-rmse:11.28609#011train-mse:67.20803#011validation-mse:127.37598\u001b[0m\n",
      "\u001b[34m[212]#011train-rmse:8.18622#011validation-rmse:11.27253#011train-mse:67.01463#011validation-mse:127.07022\u001b[0m\n",
      "\u001b[34m[213]#011train-rmse:8.14968#011validation-rmse:11.26028#011train-mse:66.41763#011validation-mse:126.79415\u001b[0m\n",
      "\u001b[34m[214]#011train-rmse:8.13795#011validation-rmse:11.26070#011train-mse:66.22659#011validation-mse:126.80362\u001b[0m\n",
      "\u001b[34m[215]#011train-rmse:8.09594#011validation-rmse:11.22335#011train-mse:65.54460#011validation-mse:125.96390\u001b[0m\n",
      "\u001b[34m[216]#011train-rmse:8.08587#011validation-rmse:11.21339#011train-mse:65.38162#011validation-mse:125.74040\u001b[0m\n",
      "\u001b[34m[217]#011train-rmse:8.06456#011validation-rmse:11.21123#011train-mse:65.03748#011validation-mse:125.69179\u001b[0m\n",
      "\u001b[34m[218]#011train-rmse:8.05828#011validation-rmse:11.21325#011train-mse:64.93635#011validation-mse:125.73723\u001b[0m\n",
      "\u001b[34m[219]#011train-rmse:8.05006#011validation-rmse:11.20835#011train-mse:64.80396#011validation-mse:125.62734\u001b[0m\n",
      "\u001b[34m[220]#011train-rmse:8.04665#011validation-rmse:11.20679#011train-mse:64.74909#011validation-mse:125.59231\u001b[0m\n",
      "\u001b[34m[221]#011train-rmse:8.04263#011validation-rmse:11.20545#011train-mse:64.68433#011validation-mse:125.56234\u001b[0m\n",
      "\u001b[34m[222]#011train-rmse:8.03183#011validation-rmse:11.19896#011train-mse:64.51062#011validation-mse:125.41703\u001b[0m\n",
      "\u001b[34m[223]#011train-rmse:8.02826#011validation-rmse:11.19776#011train-mse:64.45331#011validation-mse:125.39011\u001b[0m\n",
      "\u001b[34m[224]#011train-rmse:8.02585#011validation-rmse:11.19614#011train-mse:64.41464#011validation-mse:125.35387\u001b[0m\n",
      "\u001b[34m[225]#011train-rmse:8.02304#011validation-rmse:11.19526#011train-mse:64.36966#011validation-mse:125.33408\u001b[0m\n",
      "\u001b[34m[226]#011train-rmse:8.01583#011validation-rmse:11.19173#011train-mse:64.25401#011validation-mse:125.25504\u001b[0m\n",
      "\u001b[34m[227]#011train-rmse:7.97900#011validation-rmse:11.16512#011train-mse:63.66479#011validation-mse:124.66018\u001b[0m\n",
      "\u001b[34m[228]#011train-rmse:7.97750#011validation-rmse:11.16367#011train-mse:63.64095#011validation-mse:124.62762\u001b[0m\n",
      "\u001b[34m[229]#011train-rmse:7.97366#011validation-rmse:11.16222#011train-mse:63.57964#011validation-mse:124.59531\u001b[0m\n",
      "\u001b[34m[230]#011train-rmse:7.96516#011validation-rmse:11.15375#011train-mse:63.44435#011validation-mse:124.40622\u001b[0m\n",
      "\u001b[34m[231]#011train-rmse:7.96150#011validation-rmse:11.15246#011train-mse:63.38589#011validation-mse:124.37756\u001b[0m\n",
      "\u001b[34m[232]#011train-rmse:7.95917#011validation-rmse:11.15179#011train-mse:63.34874#011validation-mse:124.36264\u001b[0m\n",
      "\u001b[34m[233]#011train-rmse:7.95714#011validation-rmse:11.15099#011train-mse:63.31646#011validation-mse:124.34470\u001b[0m\n",
      "\u001b[34m[234]#011train-rmse:7.93539#011validation-rmse:11.15014#011train-mse:62.97072#011validation-mse:124.32591\u001b[0m\n",
      "\u001b[34m[235]#011train-rmse:7.92999#011validation-rmse:11.14848#011train-mse:62.88508#011validation-mse:124.28879\u001b[0m\n",
      "\u001b[34m[236]#011train-rmse:7.92812#011validation-rmse:11.14744#011train-mse:62.85551#011validation-mse:124.26549\u001b[0m\n",
      "\u001b[34m[237]#011train-rmse:7.92661#011validation-rmse:11.14701#011train-mse:62.83153#011validation-mse:124.25607\u001b[0m\n",
      "\u001b[34m[238]#011train-rmse:7.92445#011validation-rmse:11.14513#011train-mse:62.79721#011validation-mse:124.21400\u001b[0m\n",
      "\u001b[34m[239]#011train-rmse:7.92288#011validation-rmse:11.14431#011train-mse:62.77241#011validation-mse:124.19585\u001b[0m\n",
      "\u001b[34m[240]#011train-rmse:7.92108#011validation-rmse:11.14348#011train-mse:62.74383#011validation-mse:124.17728\u001b[0m\n",
      "\u001b[34m[241]#011train-rmse:7.88329#011validation-rmse:11.11075#011train-mse:62.14672#011validation-mse:123.44887\u001b[0m\n",
      "\u001b[34m[242]#011train-rmse:7.88133#011validation-rmse:11.11026#011train-mse:62.11572#011validation-mse:123.43797\u001b[0m\n",
      "\u001b[34m[243]#011train-rmse:7.87970#011validation-rmse:11.10961#011train-mse:62.08999#011validation-mse:123.42369\u001b[0m\n",
      "\u001b[34m[244]#011train-rmse:7.87791#011validation-rmse:11.10922#011train-mse:62.06174#011validation-mse:123.41493\u001b[0m\n",
      "\u001b[34m[245]#011train-rmse:7.87062#011validation-rmse:11.10380#011train-mse:61.94707#011validation-mse:123.29473\u001b[0m\n",
      "\u001b[34m[246]#011train-rmse:7.86799#011validation-rmse:11.10276#011train-mse:61.90563#011validation-mse:123.27162\u001b[0m\n",
      "\u001b[34m[247]#011train-rmse:7.85086#011validation-rmse:11.09878#011train-mse:61.63626#011validation-mse:123.18317\u001b[0m\n",
      "\u001b[34m[248]#011train-rmse:7.84714#011validation-rmse:11.09798#011train-mse:61.57798#011validation-mse:123.16530\u001b[0m\n",
      "\u001b[34m[249]#011train-rmse:7.84394#011validation-rmse:11.09507#011train-mse:61.52790#011validation-mse:123.10081\u001b[0m\n",
      "\u001b[34m[250]#011train-rmse:7.84200#011validation-rmse:11.09353#011train-mse:61.49744#011validation-mse:123.06658\u001b[0m\n",
      "\u001b[34m[251]#011train-rmse:7.83638#011validation-rmse:11.08825#011train-mse:61.40918#011validation-mse:122.94948\u001b[0m\n",
      "\u001b[34m[252]#011train-rmse:7.83507#011validation-rmse:11.08705#011train-mse:61.38866#011validation-mse:122.92288\u001b[0m\n",
      "\u001b[34m[253]#011train-rmse:7.82237#011validation-rmse:11.08885#011train-mse:61.18987#011validation-mse:122.96295\u001b[0m\n",
      "\u001b[34m[254]#011train-rmse:7.80923#011validation-rmse:11.08072#011train-mse:60.98446#011validation-mse:122.78265\u001b[0m\n",
      "\u001b[34m[255]#011train-rmse:7.78747#011validation-rmse:11.07263#011train-mse:60.64507#011validation-mse:122.60342\u001b[0m\n",
      "\u001b[34m[256]#011train-rmse:7.78302#011validation-rmse:11.06879#011train-mse:60.57581#011validation-mse:122.51822\u001b[0m\n",
      "\u001b[34m[257]#011train-rmse:7.77232#011validation-rmse:11.06611#011train-mse:60.40938#011validation-mse:122.45896\u001b[0m\n",
      "\u001b[34m[258]#011train-rmse:7.76926#011validation-rmse:11.06633#011train-mse:60.36180#011validation-mse:122.46393\u001b[0m\n",
      "\u001b[34m[259]#011train-rmse:7.76687#011validation-rmse:11.06560#011train-mse:60.32468#011validation-mse:122.44772\u001b[0m\n",
      "\u001b[34m[260]#011train-rmse:7.74715#011validation-rmse:11.06321#011train-mse:60.01879#011validation-mse:122.39476\u001b[0m\n",
      "\u001b[34m[261]#011train-rmse:7.73442#011validation-rmse:11.05520#011train-mse:59.82157#011validation-mse:122.21754\u001b[0m\n",
      "\u001b[34m[262]#011train-rmse:7.72322#011validation-rmse:11.04902#011train-mse:59.64851#011validation-mse:122.08106\u001b[0m\n",
      "\u001b[34m[263]#011train-rmse:7.72120#011validation-rmse:11.04836#011train-mse:59.61737#011validation-mse:122.06647\u001b[0m\n",
      "\u001b[34m[264]#011train-rmse:7.70686#011validation-rmse:11.04800#011train-mse:59.39608#011validation-mse:122.05849\u001b[0m\n",
      "\u001b[34m[265]#011train-rmse:7.70427#011validation-rmse:11.04731#011train-mse:59.35622#011validation-mse:122.04341\u001b[0m\n",
      "\u001b[34m[266]#011train-rmse:7.68629#011validation-rmse:11.04828#011train-mse:59.07941#011validation-mse:122.06480\u001b[0m\n",
      "\u001b[34m[267]#011train-rmse:7.68450#011validation-rmse:11.04792#011train-mse:59.05196#011validation-mse:122.05670\u001b[0m\n",
      "\u001b[34m[268]#011train-rmse:7.68226#011validation-rmse:11.04725#011train-mse:59.01752#011validation-mse:122.04195\u001b[0m\n",
      "\u001b[34m[269]#011train-rmse:7.67924#011validation-rmse:11.04557#011train-mse:58.97105#011validation-mse:122.00468\u001b[0m\n",
      "\u001b[34m[270]#011train-rmse:7.67755#011validation-rmse:11.04455#011train-mse:58.94505#011validation-mse:121.98219\u001b[0m\n",
      "\u001b[34m[271]#011train-rmse:7.67587#011validation-rmse:11.04292#011train-mse:58.91937#011validation-mse:121.94614\u001b[0m\n",
      "\u001b[34m[272]#011train-rmse:7.67412#011validation-rmse:11.04262#011train-mse:58.89242#011validation-mse:121.93964\u001b[0m\n",
      "\u001b[34m[273]#011train-rmse:7.67315#011validation-rmse:11.04237#011train-mse:58.87758#011validation-mse:121.93398\u001b[0m\n",
      "\u001b[34m[274]#011train-rmse:7.66825#011validation-rmse:11.03462#011train-mse:58.80230#011validation-mse:121.76301\u001b[0m\n",
      "\u001b[34m[275]#011train-rmse:7.66700#011validation-rmse:11.03425#011train-mse:58.78328#011validation-mse:121.75488\u001b[0m\n",
      "\u001b[34m[276]#011train-rmse:7.66372#011validation-rmse:11.03254#011train-mse:58.73298#011validation-mse:121.71724\u001b[0m\n",
      "\u001b[34m[277]#011train-rmse:7.65964#011validation-rmse:11.02619#011train-mse:58.67036#011validation-mse:121.57706\u001b[0m\n",
      "\u001b[34m[278]#011train-rmse:7.65579#011validation-rmse:11.02329#011train-mse:58.61149#011validation-mse:121.51318\u001b[0m\n",
      "\u001b[34m[279]#011train-rmse:7.65362#011validation-rmse:11.02302#011train-mse:58.57832#011validation-mse:121.50706\u001b[0m\n",
      "\u001b[34m[280]#011train-rmse:7.65095#011validation-rmse:11.02246#011train-mse:58.53733#011validation-mse:121.49476\u001b[0m\n",
      "\u001b[34m[281]#011train-rmse:7.64912#011validation-rmse:11.02215#011train-mse:58.50941#011validation-mse:121.48778\u001b[0m\n",
      "\u001b[34m[282]#011train-rmse:7.63333#011validation-rmse:11.02080#011train-mse:58.26822#011validation-mse:121.45815\u001b[0m\n",
      "\u001b[34m[283]#011train-rmse:7.63124#011validation-rmse:11.01974#011train-mse:58.23623#011validation-mse:121.43476\u001b[0m\n",
      "\u001b[34m[284]#011train-rmse:7.62940#011validation-rmse:11.01951#011train-mse:58.20805#011validation-mse:121.42986\u001b[0m\n",
      "\u001b[34m[285]#011train-rmse:7.62639#011validation-rmse:11.01912#011train-mse:58.16226#011validation-mse:121.42121\u001b[0m\n",
      "\u001b[34m[286]#011train-rmse:7.62524#011validation-rmse:11.01861#011train-mse:58.14470#011validation-mse:121.40994\u001b[0m\n",
      "\u001b[34m[287]#011train-rmse:7.62215#011validation-rmse:11.01772#011train-mse:58.09753#011validation-mse:121.39021\u001b[0m\n",
      "\u001b[34m[288]#011train-rmse:7.58749#011validation-rmse:11.01251#011train-mse:57.57038#011validation-mse:121.27563\u001b[0m\n",
      "\u001b[34m[289]#011train-rmse:7.58661#011validation-rmse:11.01220#011train-mse:57.55702#011validation-mse:121.26884\u001b[0m\n",
      "\u001b[34m[290]#011train-rmse:7.58126#011validation-rmse:11.00913#011train-mse:57.47590#011validation-mse:121.20115\u001b[0m\n",
      "\u001b[34m[291]#011train-rmse:7.57928#011validation-rmse:11.00886#011train-mse:57.44581#011validation-mse:121.19518\u001b[0m\n",
      "\u001b[34m[292]#011train-rmse:7.57728#011validation-rmse:11.00847#011train-mse:57.41555#011validation-mse:121.18660\u001b[0m\n",
      "\u001b[34m[293]#011train-rmse:7.57579#011validation-rmse:11.00771#011train-mse:57.39295#011validation-mse:121.16991\u001b[0m\n",
      "\u001b[34m[294]#011train-rmse:7.55070#011validation-rmse:11.00692#011train-mse:57.01334#011validation-mse:121.15244\u001b[0m\n",
      "\u001b[34m[295]#011train-rmse:7.54720#011validation-rmse:11.00613#011train-mse:56.96065#011validation-mse:121.13515\u001b[0m\n",
      "\u001b[34m[296]#011train-rmse:7.54148#011validation-rmse:11.00509#011train-mse:56.87427#011validation-mse:121.11211\u001b[0m\n",
      "\u001b[34m[297]#011train-rmse:7.53720#011validation-rmse:11.00339#011train-mse:56.80960#011validation-mse:121.07456\u001b[0m\n",
      "\u001b[34m[298]#011train-rmse:7.52996#011validation-rmse:11.00238#011train-mse:56.70060#011validation-mse:121.05250\u001b[0m\n",
      "\u001b[34m[299]#011train-rmse:7.52291#011validation-rmse:10.99727#011train-mse:56.59451#011validation-mse:120.94011\u001b[0m\n",
      "\u001b[34m[300]#011train-rmse:7.52041#011validation-rmse:10.99667#011train-mse:56.55696#011validation-mse:120.92692\u001b[0m\n",
      "\u001b[34m[301]#011train-rmse:7.51873#011validation-rmse:10.99413#011train-mse:56.53162#011validation-mse:120.87116\u001b[0m\n",
      "\u001b[34m[302]#011train-rmse:7.51737#011validation-rmse:10.99358#011train-mse:56.51118#011validation-mse:120.85894\u001b[0m\n",
      "\u001b[34m[303]#011train-rmse:7.51470#011validation-rmse:10.99275#011train-mse:56.47107#011validation-mse:120.84077\u001b[0m\n",
      "\u001b[34m[304]#011train-rmse:7.51299#011validation-rmse:10.99208#011train-mse:56.44534#011validation-mse:120.82609\u001b[0m\n",
      "\u001b[34m[305]#011train-rmse:7.49148#011validation-rmse:10.98622#011train-mse:56.12259#011validation-mse:120.69720\u001b[0m\n",
      "\u001b[34m[306]#011train-rmse:7.48971#011validation-rmse:10.98533#011train-mse:56.09609#011validation-mse:120.67768\u001b[0m\n",
      "\u001b[34m[307]#011train-rmse:7.48212#011validation-rmse:10.98255#011train-mse:55.98243#011validation-mse:120.61646\u001b[0m\n",
      "\u001b[34m[308]#011train-rmse:7.47954#011validation-rmse:10.98037#011train-mse:55.94392#011validation-mse:120.56868\u001b[0m\n",
      "\u001b[34m[309]#011train-rmse:7.47820#011validation-rmse:10.97976#011train-mse:55.92380#011validation-mse:120.55530\u001b[0m\n",
      "\u001b[34m[310]#011train-rmse:7.47596#011validation-rmse:10.97940#011train-mse:55.89025#011validation-mse:120.54742\u001b[0m\n",
      "\u001b[34m[311]#011train-rmse:7.47360#011validation-rmse:10.97798#011train-mse:55.85502#011validation-mse:120.51618\u001b[0m\n",
      "\u001b[34m[312]#011train-rmse:7.46762#011validation-rmse:10.97448#011train-mse:55.76570#011validation-mse:120.43947\u001b[0m\n",
      "\u001b[34m[313]#011train-rmse:7.46260#011validation-rmse:10.97399#011train-mse:55.69085#011validation-mse:120.42857\u001b[0m\n",
      "\u001b[34m[314]#011train-rmse:7.43987#011validation-rmse:10.97146#011train-mse:55.35206#011validation-mse:120.37300\u001b[0m\n",
      "\u001b[34m[315]#011train-rmse:7.43884#011validation-rmse:10.97057#011train-mse:55.33663#011validation-mse:120.35360\u001b[0m\n",
      "\u001b[34m[316]#011train-rmse:7.43637#011validation-rmse:10.97006#011train-mse:55.29998#011validation-mse:120.34243\u001b[0m\n",
      "\u001b[34m[317]#011train-rmse:7.43359#011validation-rmse:10.96900#011train-mse:55.25868#011validation-mse:120.31911\u001b[0m\n",
      "\u001b[34m[318]#011train-rmse:7.42595#011validation-rmse:10.96752#011train-mse:55.14513#011validation-mse:120.28666\u001b[0m\n",
      "\u001b[34m[319]#011train-rmse:7.42397#011validation-rmse:10.96640#011train-mse:55.11577#011validation-mse:120.26199\u001b[0m\n",
      "\u001b[34m[320]#011train-rmse:7.41969#011validation-rmse:10.96424#011train-mse:55.05214#011validation-mse:120.21478\u001b[0m\n",
      "\u001b[34m[321]#011train-rmse:7.41545#011validation-rmse:10.96261#011train-mse:54.98937#011validation-mse:120.17910\u001b[0m\n",
      "\u001b[34m[322]#011train-rmse:7.41421#011validation-rmse:10.96210#011train-mse:54.97090#011validation-mse:120.16795\u001b[0m\n",
      "\u001b[34m[323]#011train-rmse:7.39164#011validation-rmse:10.96206#011train-mse:54.63670#011validation-mse:120.16695\u001b[0m\n",
      "\u001b[34m[324]#011train-rmse:7.39098#011validation-rmse:10.96127#011train-mse:54.62691#011validation-mse:120.14963\u001b[0m\n",
      "\u001b[34m[325]#011train-rmse:7.38698#011validation-rmse:10.95935#011train-mse:54.56784#011validation-mse:120.10750\u001b[0m\n",
      "\u001b[34m[326]#011train-rmse:7.38449#011validation-rmse:10.95877#011train-mse:54.53104#011validation-mse:120.09480\u001b[0m\n",
      "\u001b[34m[327]#011train-rmse:7.38021#011validation-rmse:10.95651#011train-mse:54.46777#011validation-mse:120.04525\u001b[0m\n",
      "\u001b[34m[328]#011train-rmse:7.37795#011validation-rmse:10.95524#011train-mse:54.43453#011validation-mse:120.01730\u001b[0m\n",
      "\u001b[34m[329]#011train-rmse:7.35834#011validation-rmse:10.94511#011train-mse:54.14541#011validation-mse:119.79547\u001b[0m\n",
      "\u001b[34m[330]#011train-rmse:7.34681#011validation-rmse:10.94387#011train-mse:53.97598#011validation-mse:119.76846\u001b[0m\n",
      "\u001b[34m[331]#011train-rmse:7.34194#011validation-rmse:10.94311#011train-mse:53.90449#011validation-mse:119.75177\u001b[0m\n",
      "\u001b[34m[332]#011train-rmse:7.34105#011validation-rmse:10.94300#011train-mse:53.89129#011validation-mse:119.74928\u001b[0m\n",
      "\u001b[34m[333]#011train-rmse:7.33763#011validation-rmse:10.94122#011train-mse:53.84118#011validation-mse:119.71045\u001b[0m\n",
      "\u001b[34m[334]#011train-rmse:7.32114#011validation-rmse:10.93414#011train-mse:53.59948#011validation-mse:119.55549\u001b[0m\n",
      "\u001b[34m[335]#011train-rmse:7.31965#011validation-rmse:10.93364#011train-mse:53.57764#011validation-mse:119.54450\u001b[0m\n",
      "\u001b[34m[336]#011train-rmse:7.31600#011validation-rmse:10.93295#011train-mse:53.52417#011validation-mse:119.52955\u001b[0m\n",
      "\u001b[34m[337]#011train-rmse:7.30155#011validation-rmse:10.92074#011train-mse:53.31295#011validation-mse:119.26273\u001b[0m\n",
      "\u001b[34m[338]#011train-rmse:7.29707#011validation-rmse:10.92076#011train-mse:53.24761#011validation-mse:119.26320\u001b[0m\n",
      "\u001b[34m[339]#011train-rmse:7.29595#011validation-rmse:10.92030#011train-mse:53.23125#011validation-mse:119.25317\u001b[0m\n",
      "\u001b[34m[340]#011train-rmse:7.29514#011validation-rmse:10.91984#011train-mse:53.21941#011validation-mse:119.24301\u001b[0m\n",
      "\u001b[34m[341]#011train-rmse:7.29432#011validation-rmse:10.91936#011train-mse:53.20741#011validation-mse:119.23258\u001b[0m\n",
      "\u001b[34m[342]#011train-rmse:7.28885#011validation-rmse:10.91505#011train-mse:53.12762#011validation-mse:119.13847\u001b[0m\n",
      "\u001b[34m[343]#011train-rmse:7.28736#011validation-rmse:10.91456#011train-mse:53.10596#011validation-mse:119.12780\u001b[0m\n",
      "\u001b[34m[344]#011train-rmse:7.28355#011validation-rmse:10.91337#011train-mse:53.05039#011validation-mse:119.10186\u001b[0m\n",
      "\u001b[34m[345]#011train-rmse:7.28225#011validation-rmse:10.91293#011train-mse:53.03146#011validation-mse:119.09232\u001b[0m\n",
      "\u001b[34m[346]#011train-rmse:7.27878#011validation-rmse:10.91061#011train-mse:52.98096#011validation-mse:119.04157\u001b[0m\n",
      "\u001b[34m[347]#011train-rmse:7.26324#011validation-rmse:10.90995#011train-mse:52.75496#011validation-mse:119.02717\u001b[0m\n",
      "\u001b[34m[348]#011train-rmse:7.26203#011validation-rmse:10.90977#011train-mse:52.73740#011validation-mse:119.02312\u001b[0m\n",
      "\u001b[34m[349]#011train-rmse:7.26002#011validation-rmse:10.90907#011train-mse:52.70821#011validation-mse:119.00804\u001b[0m\n",
      "\u001b[34m[350]#011train-rmse:7.25890#011validation-rmse:10.90868#011train-mse:52.69193#011validation-mse:118.99960\u001b[0m\n",
      "\u001b[34m[351]#011train-rmse:7.25814#011validation-rmse:10.90737#011train-mse:52.68106#011validation-mse:118.97079\u001b[0m\n",
      "\u001b[34m[352]#011train-rmse:7.25658#011validation-rmse:10.90670#011train-mse:52.65837#011validation-mse:118.95622\u001b[0m\n",
      "\u001b[34m[353]#011train-rmse:7.25469#011validation-rmse:10.90609#011train-mse:52.63095#011validation-mse:118.94282\u001b[0m\n",
      "\u001b[34m[354]#011train-rmse:7.25280#011validation-rmse:10.90574#011train-mse:52.60344#011validation-mse:118.93528\u001b[0m\n",
      "\u001b[34m[355]#011train-rmse:7.24928#011validation-rmse:10.90532#011train-mse:52.55238#011validation-mse:118.92618\u001b[0m\n",
      "\u001b[34m[356]#011train-rmse:7.24314#011validation-rmse:10.90064#011train-mse:52.46346#011validation-mse:118.82418\u001b[0m\n",
      "\u001b[34m[357]#011train-rmse:7.23198#011validation-rmse:10.91586#011train-mse:52.30186#011validation-mse:119.15602\u001b[0m\n",
      "\u001b[34m[358]#011train-rmse:7.23110#011validation-rmse:10.91353#011train-mse:52.28917#011validation-mse:119.10542\u001b[0m\n",
      "\u001b[34m[359]#011train-rmse:7.23012#011validation-rmse:10.91325#011train-mse:52.27494#011validation-mse:119.09924\u001b[0m\n",
      "\u001b[34m[360]#011train-rmse:7.23006#011validation-rmse:10.91196#011train-mse:52.27420#011validation-mse:119.07104\u001b[0m\n",
      "\u001b[34m[361]#011train-rmse:7.22772#011validation-rmse:10.91112#011train-mse:52.24030#011validation-mse:119.05278\u001b[0m\n",
      "\u001b[34m[362]#011train-rmse:7.22668#011validation-rmse:10.91047#011train-mse:52.22530#011validation-mse:119.03855\u001b[0m\n",
      "\u001b[34m[363]#011train-rmse:7.21717#011validation-rmse:10.90715#011train-mse:52.08796#011validation-mse:118.96623\u001b[0m\n",
      "\u001b[34m[364]#011train-rmse:7.20470#011validation-rmse:10.90053#011train-mse:51.90807#011validation-mse:118.82193\u001b[0m\n",
      "\u001b[34m[365]#011train-rmse:7.20336#011validation-rmse:10.90016#011train-mse:51.88870#011validation-mse:118.81374\u001b[0m\n",
      "\u001b[34m[366]#011train-rmse:7.19641#011validation-rmse:10.89566#011train-mse:51.78861#011validation-mse:118.71577\u001b[0m\n",
      "\u001b[34m[367]#011train-rmse:7.18467#011validation-rmse:10.89319#011train-mse:51.61984#011validation-mse:118.66187\u001b[0m\n",
      "\u001b[34m[368]#011train-rmse:7.18076#011validation-rmse:10.89114#011train-mse:51.56364#011validation-mse:118.61698\u001b[0m\n",
      "\u001b[34m[369]#011train-rmse:7.17512#011validation-rmse:10.88800#011train-mse:51.48264#011validation-mse:118.54881\u001b[0m\n",
      "\u001b[34m[370]#011train-rmse:7.17354#011validation-rmse:10.88748#011train-mse:51.45997#011validation-mse:118.53736\u001b[0m\n",
      "\u001b[34m[371]#011train-rmse:7.17259#011validation-rmse:10.88734#011train-mse:51.44641#011validation-mse:118.53441\u001b[0m\n",
      "\u001b[34m[372]#011train-rmse:7.16948#011validation-rmse:10.88596#011train-mse:51.40177#011validation-mse:118.50446\u001b[0m\n",
      "\u001b[34m[373]#011train-rmse:7.16383#011validation-rmse:10.88208#011train-mse:51.32071#011validation-mse:118.41997\u001b[0m\n",
      "\u001b[34m[374]#011train-rmse:7.16221#011validation-rmse:10.88123#011train-mse:51.29763#011validation-mse:118.40138\u001b[0m\n",
      "\u001b[34m[375]#011train-rmse:7.16058#011validation-rmse:10.88002#011train-mse:51.27423#011validation-mse:118.37515\u001b[0m\n",
      "\u001b[34m[376]#011train-rmse:7.15916#011validation-rmse:10.87969#011train-mse:51.25394#011validation-mse:118.36778\u001b[0m\n",
      "\u001b[34m[377]#011train-rmse:7.14698#011validation-rmse:10.87956#011train-mse:51.07968#011validation-mse:118.36491\u001b[0m\n",
      "\u001b[34m[378]#011train-rmse:7.14602#011validation-rmse:10.87924#011train-mse:51.06600#011validation-mse:118.35804\u001b[0m\n",
      "\u001b[34m[379]#011train-rmse:7.14438#011validation-rmse:10.87881#011train-mse:51.04246#011validation-mse:118.34869\u001b[0m\n",
      "\u001b[34m[380]#011train-rmse:7.14330#011validation-rmse:10.87859#011train-mse:51.02709#011validation-mse:118.34392\u001b[0m\n",
      "\u001b[34m[381]#011train-rmse:7.14229#011validation-rmse:10.87870#011train-mse:51.01269#011validation-mse:118.34633\u001b[0m\n",
      "\u001b[34m[382]#011train-rmse:7.14088#011validation-rmse:10.87715#011train-mse:50.99254#011validation-mse:118.31264\u001b[0m\n",
      "\u001b[34m[383]#011train-rmse:7.13903#011validation-rmse:10.87586#011train-mse:50.96606#011validation-mse:118.28458\u001b[0m\n",
      "\u001b[34m[384]#011train-rmse:7.13775#011validation-rmse:10.87556#011train-mse:50.94777#011validation-mse:118.27793\u001b[0m\n",
      "\u001b[34m[385]#011train-rmse:7.13623#011validation-rmse:10.87509#011train-mse:50.92606#011validation-mse:118.26783\u001b[0m\n",
      "\u001b[34m[386]#011train-rmse:7.13500#011validation-rmse:10.87508#011train-mse:50.90861#011validation-mse:118.26759\u001b[0m\n",
      "\u001b[34m[387]#011train-rmse:7.12447#011validation-rmse:10.86799#011train-mse:50.75838#011validation-mse:118.11340\u001b[0m\n",
      "\u001b[34m[388]#011train-rmse:7.12154#011validation-rmse:10.86472#011train-mse:50.71671#011validation-mse:118.04237\u001b[0m\n",
      "\u001b[34m[389]#011train-rmse:7.11785#011validation-rmse:10.86308#011train-mse:50.66416#011validation-mse:118.00685\u001b[0m\n",
      "\u001b[34m[390]#011train-rmse:7.11813#011validation-rmse:10.86299#011train-mse:50.66811#011validation-mse:118.00486\u001b[0m\n",
      "\u001b[34m[391]#011train-rmse:7.11253#011validation-rmse:10.85963#011train-mse:50.58849#011validation-mse:117.93193\u001b[0m\n",
      "\u001b[34m[392]#011train-rmse:7.11017#011validation-rmse:10.85876#011train-mse:50.55476#011validation-mse:117.91290\u001b[0m\n",
      "\u001b[34m[393]#011train-rmse:7.10703#011validation-rmse:10.85665#011train-mse:50.51012#011validation-mse:117.86698\u001b[0m\n",
      "\u001b[34m[394]#011train-rmse:7.10505#011validation-rmse:10.85612#011train-mse:50.48201#011validation-mse:117.85552\u001b[0m\n",
      "\u001b[34m[395]#011train-rmse:7.10275#011validation-rmse:10.85508#011train-mse:50.44931#011validation-mse:117.83311\u001b[0m\n",
      "\u001b[34m[396]#011train-rmse:7.09930#011validation-rmse:10.85347#011train-mse:50.40033#011validation-mse:117.79803\u001b[0m\n",
      "\u001b[34m[397]#011train-rmse:7.09748#011validation-rmse:10.85263#011train-mse:50.37451#011validation-mse:117.77989\u001b[0m\n",
      "\u001b[34m[398]#011train-rmse:7.07465#011validation-rmse:10.85913#011train-mse:50.05097#011validation-mse:117.92104\u001b[0m\n",
      "\u001b[34m[399]#011train-rmse:7.07357#011validation-rmse:10.85899#011train-mse:50.03568#011validation-mse:117.91788\u001b[0m\n",
      "\u001b[34m[400]#011train-rmse:7.05587#011validation-rmse:10.85474#011train-mse:49.78562#011validation-mse:117.82577\u001b[0m\n",
      "\u001b[34m[401]#011train-rmse:7.05509#011validation-rmse:10.85385#011train-mse:49.77463#011validation-mse:117.80637\u001b[0m\n",
      "\u001b[34m[402]#011train-rmse:7.05259#011validation-rmse:10.85314#011train-mse:49.73938#011validation-mse:117.79089\u001b[0m\n",
      "\u001b[34m[403]#011train-rmse:7.05083#011validation-rmse:10.85281#011train-mse:49.71458#011validation-mse:117.78356\u001b[0m\n",
      "\u001b[34m[404]#011train-rmse:7.04961#011validation-rmse:10.85242#011train-mse:49.69738#011validation-mse:117.77507\u001b[0m\n",
      "\u001b[34m[405]#011train-rmse:7.03669#011validation-rmse:10.85264#011train-mse:49.51538#011validation-mse:117.78011\u001b[0m\n",
      "\u001b[34m[406]#011train-rmse:7.03251#011validation-rmse:10.85243#011train-mse:49.45653#011validation-mse:117.77555\u001b[0m\n",
      "\u001b[34m[407]#011train-rmse:7.03118#011validation-rmse:10.84955#011train-mse:49.43790#011validation-mse:117.71285\u001b[0m\n",
      "\u001b[34m[408]#011train-rmse:7.02820#011validation-rmse:10.84831#011train-mse:49.39592#011validation-mse:117.68619\u001b[0m\n",
      "\u001b[34m[409]#011train-rmse:7.02268#011validation-rmse:10.84602#011train-mse:49.31825#011validation-mse:117.63640\u001b[0m\n",
      "\u001b[34m[410]#011train-rmse:7.02138#011validation-rmse:10.84580#011train-mse:49.30011#011validation-mse:117.63163\u001b[0m\n",
      "\u001b[34m[411]#011train-rmse:7.02019#011validation-rmse:10.84539#011train-mse:49.28337#011validation-mse:117.62270\u001b[0m\n",
      "\u001b[34m[412]#011train-rmse:7.01733#011validation-rmse:10.84459#011train-mse:49.24323#011validation-mse:117.60535\u001b[0m\n",
      "\u001b[34m[413]#011train-rmse:7.01314#011validation-rmse:10.84345#011train-mse:49.18440#011validation-mse:117.58062\u001b[0m\n",
      "\u001b[34m[414]#011train-rmse:7.00971#011validation-rmse:10.84250#011train-mse:49.13624#011validation-mse:117.55986\u001b[0m\n",
      "\u001b[34m[415]#011train-rmse:7.00853#011validation-rmse:10.84226#011train-mse:49.11979#011validation-mse:117.55467\u001b[0m\n",
      "\u001b[34m[416]#011train-rmse:7.00214#011validation-rmse:10.83678#011train-mse:49.03033#011validation-mse:117.43600\u001b[0m\n",
      "\u001b[34m[417]#011train-rmse:7.00096#011validation-rmse:10.83628#011train-mse:49.01372#011validation-mse:117.42522\u001b[0m\n",
      "\u001b[34m[418]#011train-rmse:6.99881#011validation-rmse:10.83559#011train-mse:48.98363#011validation-mse:117.41016\u001b[0m\n",
      "\u001b[34m[419]#011train-rmse:6.99014#011validation-rmse:10.82946#011train-mse:48.86242#011validation-mse:117.27756\u001b[0m\n",
      "\u001b[34m[420]#011train-rmse:6.98895#011validation-rmse:10.82939#011train-mse:48.84568#011validation-mse:117.27591\u001b[0m\n",
      "\u001b[34m[421]#011train-rmse:6.98496#011validation-rmse:10.82661#011train-mse:48.78989#011validation-mse:117.21574\u001b[0m\n",
      "\u001b[34m[422]#011train-rmse:6.98359#011validation-rmse:10.82576#011train-mse:48.77093#011validation-mse:117.19739\u001b[0m\n",
      "\u001b[34m[423]#011train-rmse:6.98233#011validation-rmse:10.82543#011train-mse:48.75333#011validation-mse:117.19008\u001b[0m\n",
      "\u001b[34m[424]#011train-rmse:6.98000#011validation-rmse:10.82453#011train-mse:48.72068#011validation-mse:117.17061\u001b[0m\n",
      "\u001b[34m[425]#011train-rmse:6.97927#011validation-rmse:10.82455#011train-mse:48.71056#011validation-mse:117.17106\u001b[0m\n",
      "\u001b[34m[426]#011train-rmse:6.97312#011validation-rmse:10.82239#011train-mse:48.62473#011validation-mse:117.12424\u001b[0m\n",
      "\u001b[34m[427]#011train-rmse:6.97071#011validation-rmse:10.82094#011train-mse:48.59120#011validation-mse:117.09294\u001b[0m\n",
      "\u001b[34m[428]#011train-rmse:6.96994#011validation-rmse:10.82096#011train-mse:48.58044#011validation-mse:117.09337\u001b[0m\n",
      "\u001b[34m[429]#011train-rmse:6.96907#011validation-rmse:10.81855#011train-mse:48.56820#011validation-mse:117.04123\u001b[0m\n",
      "\u001b[34m[430]#011train-rmse:6.96321#011validation-rmse:10.82418#011train-mse:48.48654#011validation-mse:117.16292\u001b[0m\n",
      "\u001b[34m[431]#011train-rmse:6.96245#011validation-rmse:10.82403#011train-mse:48.47607#011validation-mse:117.15973\u001b[0m\n",
      "\u001b[34m[432]#011train-rmse:6.95943#011validation-rmse:10.82364#011train-mse:48.43402#011validation-mse:117.15142\u001b[0m\n",
      "\u001b[34m[433]#011train-rmse:6.95597#011validation-rmse:10.81912#011train-mse:48.38581#011validation-mse:117.05357\u001b[0m\n",
      "\u001b[34m[434]#011train-rmse:6.95510#011validation-rmse:10.81912#011train-mse:48.37382#011validation-mse:117.05351\u001b[0m\n",
      "\u001b[34m[435]#011train-rmse:6.94646#011validation-rmse:10.81571#011train-mse:48.25364#011validation-mse:116.97996\u001b[0m\n",
      "\u001b[34m[436]#011train-rmse:6.94534#011validation-rmse:10.81550#011train-mse:48.23800#011validation-mse:116.97516\u001b[0m\n",
      "\u001b[34m[437]#011train-rmse:6.94304#011validation-rmse:10.81418#011train-mse:48.20618#011validation-mse:116.94659\u001b[0m\n",
      "\u001b[34m[438]#011train-rmse:6.94147#011validation-rmse:10.81385#011train-mse:48.18435#011validation-mse:116.93948\u001b[0m\n",
      "\u001b[34m[439]#011train-rmse:6.93893#011validation-rmse:10.81286#011train-mse:48.14898#011validation-mse:116.91810\u001b[0m\n",
      "\u001b[34m[440]#011train-rmse:6.93741#011validation-rmse:10.81286#011train-mse:48.12804#011validation-mse:116.91798\u001b[0m\n",
      "\u001b[34m[441]#011train-rmse:6.93530#011validation-rmse:10.81188#011train-mse:48.09866#011validation-mse:116.89702\u001b[0m\n",
      "\u001b[34m[442]#011train-rmse:6.93434#011validation-rmse:10.81099#011train-mse:48.08539#011validation-mse:116.87779\u001b[0m\n",
      "\u001b[34m[443]#011train-rmse:6.92635#011validation-rmse:10.81021#011train-mse:47.97456#011validation-mse:116.86085\u001b[0m\n",
      "\u001b[34m[444]#011train-rmse:6.92568#011validation-rmse:10.81013#011train-mse:47.96539#011validation-mse:116.85914\u001b[0m\n",
      "\u001b[34m[445]#011train-rmse:6.92294#011validation-rmse:10.80885#011train-mse:47.92740#011validation-mse:116.83156\u001b[0m\n",
      "\u001b[34m[446]#011train-rmse:6.92013#011validation-rmse:10.80801#011train-mse:47.88843#011validation-mse:116.81325\u001b[0m\n",
      "\u001b[34m[447]#011train-rmse:6.91930#011validation-rmse:10.80780#011train-mse:47.87695#011validation-mse:116.80881\u001b[0m\n",
      "\u001b[34m[448]#011train-rmse:6.91793#011validation-rmse:10.80722#011train-mse:47.85797#011validation-mse:116.79615\u001b[0m\n",
      "\u001b[34m[449]#011train-rmse:6.91669#011validation-rmse:10.80703#011train-mse:47.84085#011validation-mse:116.79208\u001b[0m\n",
      "\u001b[34m[450]#011train-rmse:6.91415#011validation-rmse:10.80605#011train-mse:47.80570#011validation-mse:116.77090\u001b[0m\n",
      "\u001b[34m[451]#011train-rmse:6.91250#011validation-rmse:10.80541#011train-mse:47.78292#011validation-mse:116.75708\u001b[0m\n",
      "\u001b[34m[452]#011train-rmse:6.91147#011validation-rmse:10.80548#011train-mse:47.76874#011validation-mse:116.75852\u001b[0m\n",
      "\u001b[34m[453]#011train-rmse:6.90209#011validation-rmse:10.80188#011train-mse:47.63917#011validation-mse:116.68066\u001b[0m\n",
      "\u001b[34m[454]#011train-rmse:6.89687#011validation-rmse:10.80139#011train-mse:47.56723#011validation-mse:116.67020\u001b[0m\n",
      "\u001b[34m[455]#011train-rmse:6.89540#011validation-rmse:10.80195#011train-mse:47.54686#011validation-mse:116.68236\u001b[0m\n",
      "\u001b[34m[456]#011train-rmse:6.88838#011validation-rmse:10.80062#011train-mse:47.45002#011validation-mse:116.65354\u001b[0m\n",
      "\u001b[34m[457]#011train-rmse:6.88759#011validation-rmse:10.80016#011train-mse:47.43922#011validation-mse:116.64369\u001b[0m\n",
      "\u001b[34m[458]#011train-rmse:6.88631#011validation-rmse:10.79978#011train-mse:47.42154#011validation-mse:116.63537\u001b[0m\n",
      "\u001b[34m[459]#011train-rmse:6.88310#011validation-rmse:10.79822#011train-mse:47.37731#011validation-mse:116.60175\u001b[0m\n",
      "\u001b[34m[460]#011train-rmse:6.86116#011validation-rmse:10.79692#011train-mse:47.07574#011validation-mse:116.57381\u001b[0m\n",
      "\u001b[34m[461]#011train-rmse:6.85947#011validation-rmse:10.79657#011train-mse:47.05259#011validation-mse:116.56622\u001b[0m\n",
      "\u001b[34m[462]#011train-rmse:6.85360#011validation-rmse:10.79573#011train-mse:46.97213#011validation-mse:116.54790\u001b[0m\n",
      "\u001b[34m[463]#011train-rmse:6.85185#011validation-rmse:10.79454#011train-mse:46.94819#011validation-mse:116.52222\u001b[0m\n",
      "\u001b[34m[464]#011train-rmse:6.84679#011validation-rmse:10.79102#011train-mse:46.87891#011validation-mse:116.44620\u001b[0m\n",
      "\u001b[34m[465]#011train-rmse:6.84601#011validation-rmse:10.79099#011train-mse:46.86814#011validation-mse:116.44567\u001b[0m\n",
      "\u001b[34m[466]#011train-rmse:6.84450#011validation-rmse:10.79089#011train-mse:46.84744#011validation-mse:116.44340\u001b[0m\n",
      "\u001b[34m[467]#011train-rmse:6.84370#011validation-rmse:10.79098#011train-mse:46.83660#011validation-mse:116.44546\u001b[0m\n",
      "\u001b[34m[468]#011train-rmse:6.84271#011validation-rmse:10.79091#011train-mse:46.82299#011validation-mse:116.44376\u001b[0m\n",
      "\u001b[34m[469]#011train-rmse:6.83412#011validation-rmse:10.78839#011train-mse:46.70546#011validation-mse:116.38955\u001b[0m\n",
      "\u001b[34m[470]#011train-rmse:6.83273#011validation-rmse:10.78813#011train-mse:46.68647#011validation-mse:116.38399\u001b[0m\n",
      "\u001b[34m[471]#011train-rmse:6.83157#011validation-rmse:10.78807#011train-mse:46.67075#011validation-mse:116.38281\u001b[0m\n",
      "\u001b[34m[472]#011train-rmse:6.83050#011validation-rmse:10.78407#011train-mse:46.65606#011validation-mse:116.29649\u001b[0m\n",
      "\u001b[34m[473]#011train-rmse:6.82332#011validation-rmse:10.78138#011train-mse:46.55805#011validation-mse:116.23855\u001b[0m\n",
      "\u001b[34m[474]#011train-rmse:6.82283#011validation-rmse:10.78139#011train-mse:46.55133#011validation-mse:116.23866\u001b[0m\n",
      "\u001b[34m[475]#011train-rmse:6.81437#011validation-rmse:10.78001#011train-mse:46.43601#011validation-mse:116.20875\u001b[0m\n",
      "\u001b[34m[476]#011train-rmse:6.81434#011validation-rmse:10.78034#011train-mse:46.43557#011validation-mse:116.21603\u001b[0m\n",
      "\u001b[34m[477]#011train-rmse:6.81315#011validation-rmse:10.77968#011train-mse:46.41931#011validation-mse:116.20171\u001b[0m\n",
      "\u001b[34m[478]#011train-rmse:6.81105#011validation-rmse:10.77884#011train-mse:46.39067#011validation-mse:116.18362\u001b[0m\n",
      "\u001b[34m[479]#011train-rmse:6.80957#011validation-rmse:10.77780#011train-mse:46.37063#011validation-mse:116.16124\u001b[0m\n",
      "\u001b[34m[480]#011train-rmse:6.80535#011validation-rmse:10.78312#011train-mse:46.31306#011validation-mse:116.27585\u001b[0m\n",
      "\u001b[34m[481]#011train-rmse:6.80089#011validation-rmse:10.77936#011train-mse:46.25241#011validation-mse:116.19469\u001b[0m\n",
      "\u001b[34m[482]#011train-rmse:6.79870#011validation-rmse:10.77852#011train-mse:46.22268#011validation-mse:116.17673\u001b[0m\n",
      "\u001b[34m[483]#011train-rmse:6.79680#011validation-rmse:10.77811#011train-mse:46.19685#011validation-mse:116.16792\u001b[0m\n",
      "\u001b[34m[484]#011train-rmse:6.79604#011validation-rmse:10.77765#011train-mse:46.18642#011validation-mse:116.15788\u001b[0m\n",
      "\u001b[34m[485]#011train-rmse:6.79516#011validation-rmse:10.77738#011train-mse:46.17449#011validation-mse:116.15211\u001b[0m\n",
      "\u001b[34m[486]#011train-rmse:6.79035#011validation-rmse:10.77494#011train-mse:46.10906#011validation-mse:116.09952\u001b[0m\n",
      "\u001b[34m[487]#011train-rmse:6.78821#011validation-rmse:10.77401#011train-mse:46.08009#011validation-mse:116.07954\u001b[0m\n",
      "\u001b[34m[488]#011train-rmse:6.78721#011validation-rmse:10.77391#011train-mse:46.06647#011validation-mse:116.07740\u001b[0m\n",
      "\u001b[34m[489]#011train-rmse:6.78528#011validation-rmse:10.77288#011train-mse:46.04028#011validation-mse:116.05508\u001b[0m\n",
      "\u001b[34m[490]#011train-rmse:6.78385#011validation-rmse:10.77282#011train-mse:46.02090#011validation-mse:116.05385\u001b[0m\n",
      "\u001b[34m[491]#011train-rmse:6.78300#011validation-rmse:10.77284#011train-mse:46.00932#011validation-mse:116.05437\u001b[0m\n",
      "\u001b[34m[492]#011train-rmse:6.78198#011validation-rmse:10.77289#011train-mse:45.99547#011validation-mse:116.05534\u001b[0m\n",
      "\u001b[34m[493]#011train-rmse:6.77965#011validation-rmse:10.77257#011train-mse:45.96385#011validation-mse:116.04849\u001b[0m\n",
      "\u001b[34m[494]#011train-rmse:6.77846#011validation-rmse:10.77239#011train-mse:45.94787#011validation-mse:116.04475\u001b[0m\n",
      "\u001b[34m[495]#011train-rmse:6.77671#011validation-rmse:10.77187#011train-mse:45.92407#011validation-mse:116.03339\u001b[0m\n",
      "\u001b[34m[496]#011train-rmse:6.77714#011validation-rmse:10.76999#011train-mse:45.92986#011validation-mse:115.99290\u001b[0m\n",
      "\u001b[34m[497]#011train-rmse:6.77643#011validation-rmse:10.76905#011train-mse:45.92027#011validation-mse:115.97253\u001b[0m\n",
      "\u001b[34m[498]#011train-rmse:6.77553#011validation-rmse:10.76893#011train-mse:45.90807#011validation-mse:115.97004\u001b[0m\n",
      "\u001b[34m[499]#011train-rmse:6.77204#011validation-rmse:10.76615#011train-mse:45.86074#011validation-mse:115.91008\u001b[0m\n",
      "\u001b[34m[500]#011train-rmse:6.76187#011validation-rmse:10.75864#011train-mse:45.72313#011validation-mse:115.74844\u001b[0m\n",
      "\u001b[34m[501]#011train-rmse:6.76063#011validation-rmse:10.75870#011train-mse:45.70643#011validation-mse:115.74979\u001b[0m\n",
      "\u001b[34m[502]#011train-rmse:6.75993#011validation-rmse:10.75866#011train-mse:45.69694#011validation-mse:115.74882\u001b[0m\n",
      "\u001b[34m[503]#011train-rmse:6.74786#011validation-rmse:10.75919#011train-mse:45.53389#011validation-mse:115.76030\u001b[0m\n",
      "\u001b[34m[504]#011train-rmse:6.74348#011validation-rmse:10.75498#011train-mse:45.47471#011validation-mse:115.66989\u001b[0m\n",
      "\u001b[34m[505]#011train-rmse:6.74264#011validation-rmse:10.75369#011train-mse:45.46354#011validation-mse:115.64203\u001b[0m\n",
      "\u001b[34m[506]#011train-rmse:6.73572#011validation-rmse:10.75334#011train-mse:45.37019#011validation-mse:115.63446\u001b[0m\n",
      "\u001b[34m[507]#011train-rmse:6.73115#011validation-rmse:10.75117#011train-mse:45.30870#011validation-mse:115.58774\u001b[0m\n",
      "\u001b[34m[508]#011train-rmse:6.73064#011validation-rmse:10.75130#011train-mse:45.30175#011validation-mse:115.59077\u001b[0m\n",
      "\u001b[34m[509]#011train-rmse:6.72349#011validation-rmse:10.75501#011train-mse:45.20559#011validation-mse:115.67052\u001b[0m\n",
      "\u001b[34m[510]#011train-rmse:6.71610#011validation-rmse:10.75494#011train-mse:45.10623#011validation-mse:115.66898\u001b[0m\n",
      "\u001b[34m[511]#011train-rmse:6.70837#011validation-rmse:10.75278#011train-mse:45.00253#011validation-mse:115.62238\u001b[0m\n",
      "\u001b[34m[512]#011train-rmse:6.70629#011validation-rmse:10.75178#011train-mse:44.97460#011validation-mse:115.60101\u001b[0m\n",
      "\u001b[34m[513]#011train-rmse:6.70383#011validation-rmse:10.75091#011train-mse:44.94166#011validation-mse:115.58216\u001b[0m\n",
      "\u001b[34m[514]#011train-rmse:6.70186#011validation-rmse:10.75036#011train-mse:44.91515#011validation-mse:115.57055\u001b[0m\n",
      "\u001b[34m[515]#011train-rmse:6.70076#011validation-rmse:10.75022#011train-mse:44.90054#011validation-mse:115.56733\u001b[0m\n",
      "\u001b[34m[516]#011train-rmse:6.69945#011validation-rmse:10.74989#011train-mse:44.88285#011validation-mse:115.56037\u001b[0m\n",
      "\u001b[34m[517]#011train-rmse:6.69819#011validation-rmse:10.74960#011train-mse:44.86609#011validation-mse:115.55415\u001b[0m\n",
      "\u001b[34m[518]#011train-rmse:6.69401#011validation-rmse:10.74788#011train-mse:44.81009#011validation-mse:115.51697\u001b[0m\n",
      "\u001b[34m[519]#011train-rmse:6.69310#011validation-rmse:10.74765#011train-mse:44.79780#011validation-mse:115.51209\u001b[0m\n",
      "\u001b[34m[520]#011train-rmse:6.68688#011validation-rmse:10.74481#011train-mse:44.71467#011validation-mse:115.45107\u001b[0m\n",
      "\u001b[34m[521]#011train-rmse:6.68563#011validation-rmse:10.74457#011train-mse:44.69790#011validation-mse:115.44589\u001b[0m\n",
      "\u001b[34m[522]#011train-rmse:6.68182#011validation-rmse:10.74040#011train-mse:44.64701#011validation-mse:115.35638\u001b[0m\n",
      "\u001b[34m[523]#011train-rmse:6.68016#011validation-rmse:10.74000#011train-mse:44.62479#011validation-mse:115.34783\u001b[0m\n",
      "\u001b[34m[524]#011train-rmse:6.68051#011validation-rmse:10.73964#011train-mse:44.62951#011validation-mse:115.34008\u001b[0m\n",
      "\u001b[34m[525]#011train-rmse:6.67982#011validation-rmse:10.73933#011train-mse:44.62022#011validation-mse:115.33347\u001b[0m\n",
      "\u001b[34m[526]#011train-rmse:6.67870#011validation-rmse:10.73756#011train-mse:44.60537#011validation-mse:115.29540\u001b[0m\n",
      "\u001b[34m[527]#011train-rmse:6.67720#011validation-rmse:10.73749#011train-mse:44.58524#011validation-mse:115.29391\u001b[0m\n",
      "\u001b[34m[528]#011train-rmse:6.67656#011validation-rmse:10.73692#011train-mse:44.57669#011validation-mse:115.28168\u001b[0m\n",
      "\u001b[34m[529]#011train-rmse:6.67607#011validation-rmse:10.73687#011train-mse:44.57014#011validation-mse:115.28063\u001b[0m\n",
      "\u001b[34m[530]#011train-rmse:6.67514#011validation-rmse:10.73647#011train-mse:44.55767#011validation-mse:115.27202\u001b[0m\n",
      "\u001b[34m[531]#011train-rmse:6.67427#011validation-rmse:10.73573#011train-mse:44.54619#011validation-mse:115.25610\u001b[0m\n",
      "\u001b[34m[532]#011train-rmse:6.67290#011validation-rmse:10.73528#011train-mse:44.52782#011validation-mse:115.24641\u001b[0m\n",
      "\u001b[34m[533]#011train-rmse:6.66313#011validation-rmse:10.72980#011train-mse:44.39753#011validation-mse:115.12878\u001b[0m\n",
      "\u001b[34m[534]#011train-rmse:6.66248#011validation-rmse:10.72969#011train-mse:44.38882#011validation-mse:115.12656\u001b[0m\n",
      "\u001b[34m[535]#011train-rmse:6.65432#011validation-rmse:10.72299#011train-mse:44.28021#011validation-mse:114.98275\u001b[0m\n",
      "\u001b[34m[536]#011train-rmse:6.65328#011validation-rmse:10.72116#011train-mse:44.26634#011validation-mse:114.94349\u001b[0m\n",
      "\u001b[34m[537]#011train-rmse:6.65247#011validation-rmse:10.72110#011train-mse:44.25572#011validation-mse:114.94227\u001b[0m\n",
      "\u001b[34m[538]#011train-rmse:6.65141#011validation-rmse:10.72069#011train-mse:44.24150#011validation-mse:114.93346\u001b[0m\n",
      "\u001b[34m[539]#011train-rmse:6.65022#011validation-rmse:10.72046#011train-mse:44.22572#011validation-mse:114.92853\u001b[0m\n",
      "\u001b[34m[540]#011train-rmse:6.64827#011validation-rmse:10.71961#011train-mse:44.19972#011validation-mse:114.91019\u001b[0m\n",
      "\u001b[34m[541]#011train-rmse:6.64693#011validation-rmse:10.71949#011train-mse:44.18183#011validation-mse:114.90755\u001b[0m\n",
      "\u001b[34m[542]#011train-rmse:6.64487#011validation-rmse:10.71844#011train-mse:44.15459#011validation-mse:114.88512\u001b[0m\n",
      "\u001b[34m[543]#011train-rmse:6.64365#011validation-rmse:10.71823#011train-mse:44.13840#011validation-mse:114.88051\u001b[0m\n",
      "\u001b[34m[544]#011train-rmse:6.63704#011validation-rmse:10.71496#011train-mse:44.05054#011validation-mse:114.81059\u001b[0m\n",
      "\u001b[34m[545]#011train-rmse:6.63750#011validation-rmse:10.71445#011train-mse:44.05667#011validation-mse:114.79974\u001b[0m\n",
      "\u001b[34m[546]#011train-rmse:6.63794#011validation-rmse:10.71440#011train-mse:44.06246#011validation-mse:114.79857\u001b[0m\n",
      "\u001b[34m[547]#011train-rmse:6.63550#011validation-rmse:10.71373#011train-mse:44.03014#011validation-mse:114.78425\u001b[0m\n",
      "\u001b[34m[548]#011train-rmse:6.63400#011validation-rmse:10.71306#011train-mse:44.01024#011validation-mse:114.77002\u001b[0m\n",
      "\u001b[34m[549]#011train-rmse:6.63229#011validation-rmse:10.71255#011train-mse:43.98748#011validation-mse:114.75901\u001b[0m\n",
      "\u001b[34m[550]#011train-rmse:6.61714#011validation-rmse:10.71234#011train-mse:43.78679#011validation-mse:114.75455\u001b[0m\n",
      "\u001b[34m[551]#011train-rmse:6.61641#011validation-rmse:10.71233#011train-mse:43.77721#011validation-mse:114.75439\u001b[0m\n",
      "\u001b[34m[552]#011train-rmse:6.61585#011validation-rmse:10.71242#011train-mse:43.76976#011validation-mse:114.75610\u001b[0m\n",
      "\u001b[34m[553]#011train-rmse:6.61701#011validation-rmse:10.71113#011train-mse:43.78503#011validation-mse:114.72857\u001b[0m\n",
      "\u001b[34m[554]#011train-rmse:6.61076#011validation-rmse:10.71085#011train-mse:43.70249#011validation-mse:114.72254\u001b[0m\n",
      "\u001b[34m[555]#011train-rmse:6.60959#011validation-rmse:10.71081#011train-mse:43.68693#011validation-mse:114.72166\u001b[0m\n",
      "\u001b[34m[556]#011train-rmse:6.60770#011validation-rmse:10.71001#011train-mse:43.66186#011validation-mse:114.70472\u001b[0m\n",
      "\u001b[34m[557]#011train-rmse:6.60284#011validation-rmse:10.70684#011train-mse:43.59770#011validation-mse:114.63673\u001b[0m\n",
      "\u001b[34m[558]#011train-rmse:6.60319#011validation-rmse:10.70667#011train-mse:43.60233#011validation-mse:114.63309\u001b[0m\n",
      "\u001b[34m[559]#011train-rmse:6.59052#011validation-rmse:10.70644#011train-mse:43.43523#011validation-mse:114.62810\u001b[0m\n",
      "\u001b[34m[560]#011train-rmse:6.58827#011validation-rmse:10.70609#011train-mse:43.40563#011validation-mse:114.62057\u001b[0m\n",
      "\u001b[34m[561]#011train-rmse:6.58385#011validation-rmse:10.70428#011train-mse:43.34736#011validation-mse:114.58186\u001b[0m\n",
      "\u001b[34m[562]#011train-rmse:6.58407#011validation-rmse:10.70383#011train-mse:43.35025#011validation-mse:114.57225\u001b[0m\n",
      "\u001b[34m[563]#011train-rmse:6.58260#011validation-rmse:10.70372#011train-mse:43.33097#011validation-mse:114.56985\u001b[0m\n",
      "\u001b[34m[564]#011train-rmse:6.58163#011validation-rmse:10.70231#011train-mse:43.31811#011validation-mse:114.53970\u001b[0m\n",
      "\u001b[34m[565]#011train-rmse:6.58098#011validation-rmse:10.70219#011train-mse:43.30959#011validation-mse:114.53726\u001b[0m\n",
      "\u001b[34m[566]#011train-rmse:6.58021#011validation-rmse:10.70209#011train-mse:43.29949#011validation-mse:114.53510\u001b[0m\n",
      "\u001b[34m[567]#011train-rmse:6.57765#011validation-rmse:10.70141#011train-mse:43.26577#011validation-mse:114.52039\u001b[0m\n",
      "\u001b[34m[568]#011train-rmse:6.57134#011validation-rmse:10.70562#011train-mse:43.18275#011validation-mse:114.61048\u001b[0m\n",
      "\u001b[34m[569]#011train-rmse:6.57021#011validation-rmse:10.70557#011train-mse:43.16793#011validation-mse:114.60957\u001b[0m\n",
      "\u001b[34m[570]#011train-rmse:6.56880#011validation-rmse:10.70545#011train-mse:43.14942#011validation-mse:114.60694\u001b[0m\n",
      "\u001b[34m[571]#011train-rmse:6.56583#011validation-rmse:10.70411#011train-mse:43.11039#011validation-mse:114.57813\u001b[0m\n",
      "\u001b[34m[572]#011train-rmse:6.56422#011validation-rmse:10.70369#011train-mse:43.08924#011validation-mse:114.56924\u001b[0m\n",
      "\u001b[34m[573]#011train-rmse:6.56308#011validation-rmse:10.70387#011train-mse:43.07432#011validation-mse:114.57310\u001b[0m\n",
      "\u001b[34m[574]#011train-rmse:6.56128#011validation-rmse:10.70212#011train-mse:43.05067#011validation-mse:114.53553\u001b[0m\n",
      "\u001b[34m[575]#011train-rmse:6.55456#011validation-rmse:10.71336#011train-mse:42.96249#011validation-mse:114.77623\u001b[0m\n",
      "\u001b[34m[576]#011train-rmse:6.55319#011validation-rmse:10.71286#011train-mse:42.94461#011validation-mse:114.76550\u001b[0m\n",
      "\u001b[34m[577]#011train-rmse:6.55391#011validation-rmse:10.71230#011train-mse:42.95396#011validation-mse:114.75355\u001b[0m\n",
      "\u001b[34m[578]#011train-rmse:6.53918#011validation-rmse:10.72992#011train-mse:42.76116#011validation-mse:115.13131\u001b[0m\n",
      "\u001b[34m[579]#011train-rmse:6.52973#011validation-rmse:10.72967#011train-mse:42.63768#011validation-mse:115.12588\u001b[0m\n",
      "\u001b[34m[580]#011train-rmse:6.52592#011validation-rmse:10.72860#011train-mse:42.58786#011validation-mse:115.10295\u001b[0m\n",
      "\u001b[34m[581]#011train-rmse:6.52440#011validation-rmse:10.72621#011train-mse:42.56809#011validation-mse:115.05170\u001b[0m\n",
      "\u001b[34m[582]#011train-rmse:6.52313#011validation-rmse:10.72577#011train-mse:42.55140#011validation-mse:115.04234\u001b[0m\n",
      "\u001b[34m[583]#011train-rmse:6.52237#011validation-rmse:10.72579#011train-mse:42.54159#011validation-mse:115.04289\u001b[0m\n",
      "\u001b[34m[584]#011train-rmse:6.50838#011validation-rmse:10.72426#011train-mse:42.35934#011validation-mse:115.01000\u001b[0m\n",
      "\u001b[34m[585]#011train-rmse:6.50588#011validation-rmse:10.72364#011train-mse:42.32674#011validation-mse:114.99683\u001b[0m\n",
      "\u001b[34m[586]#011train-rmse:6.48949#011validation-rmse:10.72305#011train-mse:42.11375#011validation-mse:114.98415\u001b[0m\n",
      "\u001b[34m[587]#011train-rmse:6.48674#011validation-rmse:10.72211#011train-mse:42.07803#011validation-mse:114.96387\u001b[0m\n",
      "\u001b[34m[588]#011train-rmse:6.48609#011validation-rmse:10.72205#011train-mse:42.06960#011validation-mse:114.96251\u001b[0m\n",
      "\u001b[34m[589]#011train-rmse:6.48512#011validation-rmse:10.72190#011train-mse:42.05702#011validation-mse:114.95937\u001b[0m\n",
      "\u001b[34m[590]#011train-rmse:6.48320#011validation-rmse:10.72114#011train-mse:42.03218#011validation-mse:114.94293\u001b[0m\n",
      "\u001b[34m[591]#011train-rmse:6.48243#011validation-rmse:10.72115#011train-mse:42.02216#011validation-mse:114.94327\u001b[0m\n",
      "\u001b[34m[592]#011train-rmse:6.47867#011validation-rmse:10.72141#011train-mse:41.97338#011validation-mse:114.94881\u001b[0m\n",
      "\u001b[34m[593]#011train-rmse:6.46702#011validation-rmse:10.72098#011train-mse:41.82268#011validation-mse:114.93944\u001b[0m\n",
      "\u001b[34m[594]#011train-rmse:6.46615#011validation-rmse:10.72127#011train-mse:41.81130#011validation-mse:114.94579\u001b[0m\n",
      "\u001b[34m[595]#011train-rmse:6.46522#011validation-rmse:10.72083#011train-mse:41.79926#011validation-mse:114.93643\u001b[0m\n",
      "\u001b[34m[596]#011train-rmse:6.46414#011validation-rmse:10.72081#011train-mse:41.78531#011validation-mse:114.93590\u001b[0m\n",
      "\u001b[34m[597]#011train-rmse:6.45797#011validation-rmse:10.71807#011train-mse:41.70563#011validation-mse:114.87732\u001b[0m\n",
      "\u001b[34m[598]#011train-rmse:6.45514#011validation-rmse:10.71788#011train-mse:41.66906#011validation-mse:114.87322\u001b[0m\n",
      "\u001b[34m[599]#011train-rmse:6.44945#011validation-rmse:10.71522#011train-mse:41.59558#011validation-mse:114.81614\u001b[0m\n",
      "\u001b[34m[600]#011train-rmse:6.44903#011validation-rmse:10.71505#011train-mse:41.59018#011validation-mse:114.81255\u001b[0m\n",
      "\u001b[34m[601]#011train-rmse:6.44852#011validation-rmse:10.71504#011train-mse:41.58369#011validation-mse:114.81233\u001b[0m\n",
      "\u001b[34m[602]#011train-rmse:6.44777#011validation-rmse:10.71488#011train-mse:41.57398#011validation-mse:114.80894\u001b[0m\n",
      "\u001b[34m[603]#011train-rmse:6.44709#011validation-rmse:10.71490#011train-mse:41.56516#011validation-mse:114.80925\u001b[0m\n",
      "\u001b[34m[604]#011train-rmse:6.44476#011validation-rmse:10.71392#011train-mse:41.53515#011validation-mse:114.78835\u001b[0m\n",
      "\u001b[34m[605]#011train-rmse:6.44316#011validation-rmse:10.71329#011train-mse:41.51447#011validation-mse:114.77487\u001b[0m\n",
      "\u001b[34m[606]#011train-rmse:6.44226#011validation-rmse:10.71311#011train-mse:41.50300#011validation-mse:114.77102\u001b[0m\n",
      "\u001b[34m[607]#011train-rmse:6.44154#011validation-rmse:10.71291#011train-mse:41.49365#011validation-mse:114.76665\u001b[0m\n",
      "\u001b[34m[608]#011train-rmse:6.44048#011validation-rmse:10.71313#011train-mse:41.48005#011validation-mse:114.77125\u001b[0m\n",
      "\u001b[34m[609]#011train-rmse:6.43076#011validation-rmse:10.73150#011train-mse:41.35487#011validation-mse:115.16532\u001b[0m\n",
      "\u001b[34m[610]#011train-rmse:6.43028#011validation-rmse:10.73150#011train-mse:41.34869#011validation-mse:115.16526\u001b[0m\n",
      "\u001b[34m[611]#011train-rmse:6.42611#011validation-rmse:10.72922#011train-mse:41.29511#011validation-mse:115.11646\u001b[0m\n",
      "\u001b[34m[612]#011train-rmse:6.42526#011validation-rmse:10.72890#011train-mse:41.28425#011validation-mse:115.10948\u001b[0m\n",
      "\u001b[34m[613]#011train-rmse:6.42270#011validation-rmse:10.72850#011train-mse:41.25128#011validation-mse:115.10098\u001b[0m\n",
      "\u001b[34m[614]#011train-rmse:6.42096#011validation-rmse:10.72799#011train-mse:41.22902#011validation-mse:115.09010\u001b[0m\n",
      "\u001b[34m[615]#011train-rmse:6.41151#011validation-rmse:10.72724#011train-mse:41.10768#011validation-mse:115.07401\u001b[0m\n",
      "\u001b[34m[616]#011train-rmse:6.41021#011validation-rmse:10.72725#011train-mse:41.09108#011validation-mse:115.07420\u001b[0m\n",
      "\u001b[34m[617]#011train-rmse:6.40835#011validation-rmse:10.72657#011train-mse:41.06723#011validation-mse:115.05946\u001b[0m\n",
      "\u001b[34m[618]#011train-rmse:6.40590#011validation-rmse:10.72599#011train-mse:41.03583#011validation-mse:115.04722\u001b[0m\n",
      "\u001b[34m[619]#011train-rmse:6.40447#011validation-rmse:10.72565#011train-mse:41.01747#011validation-mse:115.03976\u001b[0m\n",
      "\u001b[34m[620]#011train-rmse:6.40299#011validation-rmse:10.72290#011train-mse:40.99842#011validation-mse:114.98077\u001b[0m\n",
      "\u001b[34m[621]#011train-rmse:6.40186#011validation-rmse:10.72284#011train-mse:40.98400#011validation-mse:114.97963\u001b[0m\n",
      "\u001b[34m[622]#011train-rmse:6.39166#011validation-rmse:10.71694#011train-mse:40.85356#011validation-mse:114.85307\u001b[0m\n",
      "\u001b[34m[623]#011train-rmse:6.39019#011validation-rmse:10.71644#011train-mse:40.83474#011validation-mse:114.84232\u001b[0m\n",
      "\u001b[34m[624]#011train-rmse:6.38344#011validation-rmse:10.71703#011train-mse:40.74854#011validation-mse:114.85510\u001b[0m\n",
      "\u001b[34m[625]#011train-rmse:6.37632#011validation-rmse:10.71578#011train-mse:40.65774#011validation-mse:114.82828\u001b[0m\n",
      "\u001b[34m[626]#011train-rmse:6.37614#011validation-rmse:10.71503#011train-mse:40.65536#011validation-mse:114.81202\u001b[0m\n",
      "\u001b[34m[627]#011train-rmse:6.37432#011validation-rmse:10.71511#011train-mse:40.63209#011validation-mse:114.81377\u001b[0m\n",
      "\u001b[34m[628]#011train-rmse:6.37390#011validation-rmse:10.71514#011train-mse:40.62679#011validation-mse:114.81441\u001b[0m\n",
      "\u001b[34m[629]#011train-rmse:6.37301#011validation-rmse:10.71532#011train-mse:40.61548#011validation-mse:114.81845\u001b[0m\n",
      "\u001b[34m[630]#011train-rmse:6.37206#011validation-rmse:10.71504#011train-mse:40.60337#011validation-mse:114.81233\u001b[0m\n",
      "\u001b[34m[631]#011train-rmse:6.37101#011validation-rmse:10.71341#011train-mse:40.59004#011validation-mse:114.77741\u001b[0m\n",
      "\u001b[34m[632]#011train-rmse:6.36959#011validation-rmse:10.71301#011train-mse:40.57188#011validation-mse:114.76872\u001b[0m\n",
      "\u001b[34m[633]#011train-rmse:6.36353#011validation-rmse:10.71259#011train-mse:40.49477#011validation-mse:114.75975\u001b[0m\n",
      "\u001b[34m[634]#011train-rmse:6.35675#011validation-rmse:10.73077#011train-mse:40.40852#011validation-mse:115.14958\u001b[0m\n",
      "\u001b[34m[635]#011train-rmse:6.35624#011validation-rmse:10.73079#011train-mse:40.40203#011validation-mse:115.15012\u001b[0m\n",
      "\u001b[34m[636]#011train-rmse:6.35516#011validation-rmse:10.73082#011train-mse:40.38828#011validation-mse:115.15074\u001b[0m\n",
      "\u001b[34m[637]#011train-rmse:6.35394#011validation-rmse:10.73026#011train-mse:40.37276#011validation-mse:115.13853\u001b[0m\n",
      "\u001b[34m[638]#011train-rmse:6.35316#011validation-rmse:10.73011#011train-mse:40.36291#011validation-mse:115.13535\u001b[0m\n",
      "\u001b[34m[639]#011train-rmse:6.35227#011validation-rmse:10.73016#011train-mse:40.35151#011validation-mse:115.13644\u001b[0m\n",
      "\u001b[34m[640]#011train-rmse:6.35118#011validation-rmse:10.73007#011train-mse:40.33769#011validation-mse:115.13460\u001b[0m\n",
      "\u001b[34m[641]#011train-rmse:6.35068#011validation-rmse:10.73004#011train-mse:40.33133#011validation-mse:115.13397\u001b[0m\n",
      "\u001b[34m[642]#011train-rmse:6.34990#011validation-rmse:10.72998#011train-mse:40.32146#011validation-mse:115.13271\u001b[0m\n",
      "\u001b[34m[643]#011train-rmse:6.33841#011validation-rmse:10.72879#011train-mse:40.17558#011validation-mse:115.10692\u001b[0m\n",
      "\u001b[34m[644]#011train-rmse:6.33762#011validation-rmse:10.72868#011train-mse:40.16561#011validation-mse:115.10480\u001b[0m\n",
      "\u001b[34m[645]#011train-rmse:6.33608#011validation-rmse:10.72790#011train-mse:40.14614#011validation-mse:115.08817\u001b[0m\n",
      "\u001b[34m[646]#011train-rmse:6.33427#011validation-rmse:10.72685#011train-mse:40.12323#011validation-mse:115.06542\u001b[0m\n",
      "\u001b[34m[647]#011train-rmse:6.33275#011validation-rmse:10.72697#011train-mse:40.10392#011validation-mse:115.06804\u001b[0m\n",
      "\u001b[34m[648]#011train-rmse:6.32895#011validation-rmse:10.72573#011train-mse:40.05575#011validation-mse:115.04145\u001b[0m\n",
      "\u001b[34m[649]#011train-rmse:6.32787#011validation-rmse:10.72548#011train-mse:40.04214#011validation-mse:115.03610\u001b[0m\n",
      "\u001b[34m[650]#011train-rmse:6.32516#011validation-rmse:10.72431#011train-mse:40.00793#011validation-mse:115.01103\u001b[0m\n",
      "\u001b[34m[651]#011train-rmse:6.32512#011validation-rmse:10.72265#011train-mse:40.00734#011validation-mse:114.97555\u001b[0m\n",
      "\u001b[34m[652]#011train-rmse:6.32237#011validation-rmse:10.72177#011train-mse:39.97258#011validation-mse:114.95670\u001b[0m\n",
      "\u001b[34m[653]#011train-rmse:6.32180#011validation-rmse:10.72167#011train-mse:39.96540#011validation-mse:114.95448\u001b[0m\n",
      "\u001b[34m[654]#011train-rmse:6.31550#011validation-rmse:10.71797#011train-mse:39.88582#011validation-mse:114.87520\u001b[0m\n",
      "\u001b[34m[655]#011train-rmse:6.31451#011validation-rmse:10.71789#011train-mse:39.87324#011validation-mse:114.87349\u001b[0m\n",
      "\u001b[34m[656]#011train-rmse:6.31316#011validation-rmse:10.71746#011train-mse:39.85621#011validation-mse:114.86411\u001b[0m\n",
      "\u001b[34m[657]#011train-rmse:6.31190#011validation-rmse:10.71654#011train-mse:39.84031#011validation-mse:114.84459\u001b[0m\n",
      "\u001b[34m[658]#011train-rmse:6.31073#011validation-rmse:10.71606#011train-mse:39.82558#011validation-mse:114.83436\u001b[0m\n",
      "\u001b[34m[659]#011train-rmse:6.30979#011validation-rmse:10.71581#011train-mse:39.81364#011validation-mse:114.82894\u001b[0m\n",
      "\u001b[34m[660]#011train-rmse:6.30843#011validation-rmse:10.71563#011train-mse:39.79647#011validation-mse:114.82494\u001b[0m\n",
      "\u001b[34m[661]#011train-rmse:6.30552#011validation-rmse:10.71557#011train-mse:39.75975#011validation-mse:114.82378\u001b[0m\n",
      "\u001b[34m[662]#011train-rmse:6.30457#011validation-rmse:10.71540#011train-mse:39.74776#011validation-mse:114.82015\u001b[0m\n",
      "\u001b[34m[663]#011train-rmse:6.30121#011validation-rmse:10.71528#011train-mse:39.70543#011validation-mse:114.81747\u001b[0m\n",
      "\u001b[34m[664]#011train-rmse:6.30062#011validation-rmse:10.71547#011train-mse:39.69804#011validation-mse:114.82162\u001b[0m\n",
      "\u001b[34m[665]#011train-rmse:6.29959#011validation-rmse:10.71582#011train-mse:39.68509#011validation-mse:114.82896\u001b[0m\n",
      "\u001b[34m[666]#011train-rmse:6.29961#011validation-rmse:10.71569#011train-mse:39.68529#011validation-mse:114.82629\u001b[0m\n",
      "\u001b[34m[667]#011train-rmse:6.29103#011validation-rmse:10.71507#011train-mse:39.57726#011validation-mse:114.81297\u001b[0m\n",
      "\u001b[34m[668]#011train-rmse:6.28479#011validation-rmse:10.71398#011train-mse:39.49879#011validation-mse:114.78962\u001b[0m\n",
      "\u001b[34m[669]#011train-rmse:6.28430#011validation-rmse:10.71379#011train-mse:39.49265#011validation-mse:114.78547\u001b[0m\n",
      "\u001b[34m[670]#011train-rmse:6.28185#011validation-rmse:10.71274#011train-mse:39.46187#011validation-mse:114.76308\u001b[0m\n",
      "\u001b[34m[671]#011train-rmse:6.28021#011validation-rmse:10.71245#011train-mse:39.44122#011validation-mse:114.75666\u001b[0m\n",
      "\u001b[34m[672]#011train-rmse:6.27889#011validation-rmse:10.71194#011train-mse:39.42472#011validation-mse:114.74590\u001b[0m\n",
      "\u001b[34m[673]#011train-rmse:6.27656#011validation-rmse:10.71195#011train-mse:39.39542#011validation-mse:114.74617\u001b[0m\n",
      "\u001b[34m[674]#011train-rmse:6.27668#011validation-rmse:10.71200#011train-mse:39.39693#011validation-mse:114.74709\u001b[0m\n",
      "\u001b[34m[675]#011train-rmse:6.27472#011validation-rmse:10.71124#011train-mse:39.37241#011validation-mse:114.73090\u001b[0m\n",
      "\u001b[34m[676]#011train-rmse:6.27405#011validation-rmse:10.71105#011train-mse:39.36393#011validation-mse:114.72687\u001b[0m\n",
      "\u001b[34m[677]#011train-rmse:6.27286#011validation-rmse:10.71063#011train-mse:39.34903#011validation-mse:114.71778\u001b[0m\n",
      "\u001b[34m[678]#011train-rmse:6.27160#011validation-rmse:10.71047#011train-mse:39.33320#011validation-mse:114.71442\u001b[0m\n",
      "\u001b[34m[679]#011train-rmse:6.26731#011validation-rmse:10.70995#011train-mse:39.27945#011validation-mse:114.70319\u001b[0m\n",
      "\u001b[34m[680]#011train-rmse:6.26597#011validation-rmse:10.70939#011train-mse:39.26263#011validation-mse:114.69128\u001b[0m\n",
      "\u001b[34m[681]#011train-rmse:6.26347#011validation-rmse:10.70968#011train-mse:39.23127#011validation-mse:114.69746\u001b[0m\n",
      "\u001b[34m[682]#011train-rmse:6.25896#011validation-rmse:10.70656#011train-mse:39.17479#011validation-mse:114.63075\u001b[0m\n",
      "\u001b[34m[683]#011train-rmse:6.25492#011validation-rmse:10.70381#011train-mse:39.12421#011validation-mse:114.57180\u001b[0m\n",
      "\u001b[34m[684]#011train-rmse:6.25389#011validation-rmse:10.70343#011train-mse:39.11133#011validation-mse:114.56372\u001b[0m\n",
      "\u001b[34m[685]#011train-rmse:6.24888#011validation-rmse:10.71307#011train-mse:39.04871#011validation-mse:114.77012\u001b[0m\n",
      "\u001b[34m[686]#011train-rmse:6.24646#011validation-rmse:10.71291#011train-mse:39.01846#011validation-mse:114.76671\u001b[0m\n",
      "\u001b[34m[687]#011train-rmse:6.24561#011validation-rmse:10.71288#011train-mse:39.00790#011validation-mse:114.76587\u001b[0m\n",
      "\u001b[34m[688]#011train-rmse:6.24450#011validation-rmse:10.71280#011train-mse:38.99399#011validation-mse:114.76416\u001b[0m\n",
      "\u001b[34m[689]#011train-rmse:6.24244#011validation-rmse:10.71255#011train-mse:38.96830#011validation-mse:114.75880\u001b[0m\n",
      "\u001b[34m[690]#011train-rmse:6.24147#011validation-rmse:10.71242#011train-mse:38.95611#011validation-mse:114.75597\u001b[0m\n",
      "\u001b[34m[691]#011train-rmse:6.24104#011validation-rmse:10.71148#011train-mse:38.95084#011validation-mse:114.73599\u001b[0m\n",
      "\u001b[34m[692]#011train-rmse:6.23338#011validation-rmse:10.71158#011train-mse:38.85519#011validation-mse:114.73814\u001b[0m\n",
      "\u001b[34m[693]#011train-rmse:6.23166#011validation-rmse:10.71147#011train-mse:38.83387#011validation-mse:114.73584\u001b[0m\n",
      "\u001b[34m[694]#011train-rmse:6.22942#011validation-rmse:10.71832#011train-mse:38.80582#011validation-mse:114.88251\u001b[0m\n",
      "\u001b[34m[695]#011train-rmse:6.22834#011validation-rmse:10.71794#011train-mse:38.79236#011validation-mse:114.87449\u001b[0m\n",
      "\u001b[34m[696]#011train-rmse:6.22709#011validation-rmse:10.71769#011train-mse:38.77679#011validation-mse:114.86907\u001b[0m\n",
      "\u001b[34m[697]#011train-rmse:6.22005#011validation-rmse:10.72222#011train-mse:38.68928#011validation-mse:114.96614\u001b[0m\n",
      "\u001b[34m[698]#011train-rmse:6.21628#011validation-rmse:10.72750#011train-mse:38.64232#011validation-mse:115.07956\u001b[0m\n",
      "\u001b[34m[699]#011train-rmse:6.20960#011validation-rmse:10.72646#011train-mse:38.55938#011validation-mse:115.05718\u001b[0m\n",
      "\u001b[34m[700]#011train-rmse:6.20890#011validation-rmse:10.72638#011train-mse:38.55071#011validation-mse:115.05544\u001b[0m\n",
      "\u001b[34m[701]#011train-rmse:6.20810#011validation-rmse:10.72635#011train-mse:38.54076#011validation-mse:115.05470\u001b[0m\n",
      "\u001b[34m[702]#011train-rmse:6.20277#011validation-rmse:10.72362#011train-mse:38.47463#011validation-mse:114.99622\u001b[0m\n",
      "\u001b[34m[703]#011train-rmse:6.19959#011validation-rmse:10.72202#011train-mse:38.43511#011validation-mse:114.96190\u001b[0m\n",
      "\u001b[34m[704]#011train-rmse:6.18600#011validation-rmse:10.71126#011train-mse:38.26673#011validation-mse:114.73130\u001b[0m\n",
      "\u001b[34m[705]#011train-rmse:6.18516#011validation-rmse:10.71125#011train-mse:38.25637#011validation-mse:114.73117\u001b[0m\n",
      "\u001b[34m[706]#011train-rmse:6.18367#011validation-rmse:10.71124#011train-mse:38.23797#011validation-mse:114.73092\u001b[0m\n",
      "\u001b[34m[707]#011train-rmse:6.18132#011validation-rmse:10.71040#011train-mse:38.20889#011validation-mse:114.71287\u001b[0m\n",
      "\u001b[34m[708]#011train-rmse:6.18053#011validation-rmse:10.71006#011train-mse:38.19911#011validation-mse:114.70552\u001b[0m\n",
      "\u001b[34m[709]#011train-rmse:6.17867#011validation-rmse:10.71000#011train-mse:38.17621#011validation-mse:114.70419\u001b[0m\n",
      "\u001b[34m[710]#011train-rmse:6.17853#011validation-rmse:10.70947#011train-mse:38.17450#011validation-mse:114.69286\u001b[0m\n",
      "\u001b[34m[711]#011train-rmse:6.17756#011validation-rmse:10.70921#011train-mse:38.16245#011validation-mse:114.68739\u001b[0m\n",
      "\u001b[34m[712]#011train-rmse:6.17672#011validation-rmse:10.70913#011train-mse:38.15211#011validation-mse:114.68561\u001b[0m\n",
      "\u001b[34m[713]#011train-rmse:6.17562#011validation-rmse:10.70869#011train-mse:38.13855#011validation-mse:114.67631\u001b[0m\n",
      "\u001b[34m[714]#011train-rmse:6.17550#011validation-rmse:10.70854#011train-mse:38.13701#011validation-mse:114.67304\u001b[0m\n",
      "\u001b[34m[715]#011train-rmse:6.16962#011validation-rmse:10.70604#011train-mse:38.06441#011validation-mse:114.61938\u001b[0m\n",
      "\u001b[34m[716]#011train-rmse:6.16846#011validation-rmse:10.70579#011train-mse:38.05011#011validation-mse:114.61412\u001b[0m\n",
      "\u001b[34m[717]#011train-rmse:6.16761#011validation-rmse:10.70560#011train-mse:38.03962#011validation-mse:114.61011\u001b[0m\n",
      "\u001b[34m[718]#011train-rmse:6.15994#011validation-rmse:10.70553#011train-mse:37.94506#011validation-mse:114.60852\u001b[0m\n",
      "\u001b[34m[719]#011train-rmse:6.15878#011validation-rmse:10.70547#011train-mse:37.93084#011validation-mse:114.60740\u001b[0m\n",
      "\u001b[34m[720]#011train-rmse:6.15339#011validation-rmse:10.70290#011train-mse:37.86447#011validation-mse:114.55231\u001b[0m\n",
      "\u001b[34m[721]#011train-rmse:6.14946#011validation-rmse:10.70188#011train-mse:37.81612#011validation-mse:114.53046\u001b[0m\n",
      "\u001b[34m[722]#011train-rmse:6.14843#011validation-rmse:10.70102#011train-mse:37.80338#011validation-mse:114.51206\u001b[0m\n",
      "\u001b[34m[723]#011train-rmse:6.14757#011validation-rmse:10.70087#011train-mse:37.79273#011validation-mse:114.50892\u001b[0m\n",
      "\u001b[34m[724]#011train-rmse:6.13886#011validation-rmse:10.70243#011train-mse:37.68576#011validation-mse:114.54227\u001b[0m\n",
      "\u001b[34m[725]#011train-rmse:6.13836#011validation-rmse:10.70249#011train-mse:37.67970#011validation-mse:114.54353\u001b[0m\n",
      "\u001b[34m[726]#011train-rmse:6.13740#011validation-rmse:10.70203#011train-mse:37.66782#011validation-mse:114.53380\u001b[0m\n",
      "\u001b[34m[727]#011train-rmse:6.13537#011validation-rmse:10.70061#011train-mse:37.64290#011validation-mse:114.50329\u001b[0m\n",
      "\u001b[34m[728]#011train-rmse:6.13447#011validation-rmse:10.69943#011train-mse:37.63188#011validation-mse:114.47808\u001b[0m\n",
      "\u001b[34m[729]#011train-rmse:6.13368#011validation-rmse:10.69923#011train-mse:37.62224#011validation-mse:114.47387\u001b[0m\n",
      "\u001b[34m[730]#011train-rmse:6.13328#011validation-rmse:10.69923#011train-mse:37.61730#011validation-mse:114.47369\u001b[0m\n",
      "\u001b[34m[731]#011train-rmse:6.13176#011validation-rmse:10.69874#011train-mse:37.59871#011validation-mse:114.46321\u001b[0m\n",
      "\u001b[34m[732]#011train-rmse:6.12906#011validation-rmse:10.69674#011train-mse:37.56554#011validation-mse:114.42049\u001b[0m\n",
      "\u001b[34m[733]#011train-rmse:6.12711#011validation-rmse:10.69591#011train-mse:37.54167#011validation-mse:114.40259\u001b[0m\n",
      "\u001b[34m[734]#011train-rmse:6.12145#011validation-rmse:10.69535#011train-mse:37.47232#011validation-mse:114.39066\u001b[0m\n",
      "\u001b[34m[735]#011train-rmse:6.12056#011validation-rmse:10.69531#011train-mse:37.46149#011validation-mse:114.38990\u001b[0m\n",
      "\u001b[34m[736]#011train-rmse:6.11906#011validation-rmse:10.69475#011train-mse:37.44309#011validation-mse:114.37779\u001b[0m\n",
      "\u001b[34m[737]#011train-rmse:6.11835#011validation-rmse:10.69474#011train-mse:37.43440#011validation-mse:114.37761\u001b[0m\n",
      "\u001b[34m[738]#011train-rmse:6.11788#011validation-rmse:10.69484#011train-mse:37.42865#011validation-mse:114.37979\u001b[0m\n",
      "\u001b[34m[739]#011train-rmse:6.11727#011validation-rmse:10.69379#011train-mse:37.42122#011validation-mse:114.35741\u001b[0m\n",
      "\u001b[34m[740]#011train-rmse:6.11357#011validation-rmse:10.69038#011train-mse:37.37594#011validation-mse:114.28454\u001b[0m\n",
      "\u001b[34m[741]#011train-rmse:6.11284#011validation-rmse:10.69032#011train-mse:37.36707#011validation-mse:114.28319\u001b[0m\n",
      "\u001b[34m[742]#011train-rmse:6.10682#011validation-rmse:10.68698#011train-mse:37.29345#011validation-mse:114.21173\u001b[0m\n",
      "\u001b[34m[743]#011train-rmse:6.10043#011validation-rmse:10.68344#011train-mse:37.21544#011validation-mse:114.13628\u001b[0m\n",
      "\u001b[34m[744]#011train-rmse:6.09944#011validation-rmse:10.68326#011train-mse:37.20340#011validation-mse:114.13224\u001b[0m\n",
      "\u001b[34m[745]#011train-rmse:6.09897#011validation-rmse:10.68328#011train-mse:37.19764#011validation-mse:114.13268\u001b[0m\n",
      "\u001b[34m[746]#011train-rmse:6.09744#011validation-rmse:10.68314#011train-mse:37.17899#011validation-mse:114.12973\u001b[0m\n",
      "\u001b[34m[747]#011train-rmse:6.09683#011validation-rmse:10.68304#011train-mse:37.17150#011validation-mse:114.12760\u001b[0m\n",
      "\u001b[34m[748]#011train-rmse:6.09305#011validation-rmse:10.68303#011train-mse:37.12539#011validation-mse:114.12726\u001b[0m\n",
      "\u001b[34m[749]#011train-rmse:6.09214#011validation-rmse:10.68305#011train-mse:37.11444#011validation-mse:114.12794\u001b[0m\n",
      "\u001b[34m[750]#011train-rmse:6.08811#011validation-rmse:10.68290#011train-mse:37.06532#011validation-mse:114.12472\u001b[0m\n",
      "\u001b[34m[751]#011train-rmse:6.08736#011validation-rmse:10.68271#011train-mse:37.05610#011validation-mse:114.12073\u001b[0m\n",
      "\u001b[34m[752]#011train-rmse:6.08498#011validation-rmse:10.68225#011train-mse:37.02719#011validation-mse:114.11070\u001b[0m\n",
      "\u001b[34m[753]#011train-rmse:6.08009#011validation-rmse:10.68153#011train-mse:36.96777#011validation-mse:114.09531\u001b[0m\n",
      "\u001b[34m[754]#011train-rmse:6.07955#011validation-rmse:10.68110#011train-mse:36.96119#011validation-mse:114.08620\u001b[0m\n",
      "\u001b[34m[755]#011train-rmse:6.07822#011validation-rmse:10.68051#011train-mse:36.94500#011validation-mse:114.07348\u001b[0m\n",
      "\u001b[34m[756]#011train-rmse:6.07743#011validation-rmse:10.68055#011train-mse:36.93536#011validation-mse:114.07440\u001b[0m\n",
      "\u001b[34m[757]#011train-rmse:6.07334#011validation-rmse:10.67944#011train-mse:36.88562#011validation-mse:114.05087\u001b[0m\n",
      "\u001b[34m[758]#011train-rmse:6.07231#011validation-rmse:10.67901#011train-mse:36.87317#011validation-mse:114.04154\u001b[0m\n",
      "\u001b[34m[759]#011train-rmse:6.07150#011validation-rmse:10.67891#011train-mse:36.86331#011validation-mse:114.03945\u001b[0m\n",
      "\u001b[34m[760]#011train-rmse:6.06855#011validation-rmse:10.67852#011train-mse:36.82752#011validation-mse:114.03102\u001b[0m\n",
      "\u001b[34m[761]#011train-rmse:6.06693#011validation-rmse:10.67757#011train-mse:36.80783#011validation-mse:114.01092\u001b[0m\n",
      "\u001b[34m[762]#011train-rmse:6.06639#011validation-rmse:10.67746#011train-mse:36.80123#011validation-mse:114.00836\u001b[0m\n",
      "\u001b[34m[763]#011train-rmse:6.06572#011validation-rmse:10.67696#011train-mse:36.79322#011validation-mse:113.99773\u001b[0m\n",
      "\u001b[34m[764]#011train-rmse:6.06491#011validation-rmse:10.67664#011train-mse:36.78335#011validation-mse:113.99098\u001b[0m\n",
      "\u001b[34m[765]#011train-rmse:6.06408#011validation-rmse:10.67678#011train-mse:36.77327#011validation-mse:113.99381\u001b[0m\n",
      "\u001b[34m[766]#011train-rmse:6.06299#011validation-rmse:10.67652#011train-mse:36.76006#011validation-mse:113.98846\u001b[0m\n",
      "\u001b[34m[767]#011train-rmse:6.06204#011validation-rmse:10.67643#011train-mse:36.74858#011validation-mse:113.98638\u001b[0m\n",
      "\u001b[34m[768]#011train-rmse:6.06010#011validation-rmse:10.67544#011train-mse:36.72509#011validation-mse:113.96516\u001b[0m\n",
      "\u001b[34m[769]#011train-rmse:6.05945#011validation-rmse:10.67541#011train-mse:36.71719#011validation-mse:113.96468\u001b[0m\n",
      "\u001b[34m[770]#011train-rmse:6.05861#011validation-rmse:10.67510#011train-mse:36.70703#011validation-mse:113.95796\u001b[0m\n",
      "\u001b[34m[771]#011train-rmse:6.05649#011validation-rmse:10.67506#011train-mse:36.68130#011validation-mse:113.95713\u001b[0m\n",
      "\u001b[34m[772]#011train-rmse:6.05589#011validation-rmse:10.67503#011train-mse:36.67404#011validation-mse:113.95646\u001b[0m\n",
      "\u001b[34m[773]#011train-rmse:6.04890#011validation-rmse:10.67381#011train-mse:36.58933#011validation-mse:113.93045\u001b[0m\n",
      "\u001b[34m[774]#011train-rmse:6.03998#011validation-rmse:10.66806#011train-mse:36.48151#011validation-mse:113.80773\u001b[0m\n",
      "\u001b[34m[775]#011train-rmse:6.03810#011validation-rmse:10.66784#011train-mse:36.45886#011validation-mse:113.80309\u001b[0m\n",
      "\u001b[34m[776]#011train-rmse:6.03752#011validation-rmse:10.66774#011train-mse:36.45177#011validation-mse:113.80090\u001b[0m\n",
      "\u001b[34m[777]#011train-rmse:6.03672#011validation-rmse:10.66768#011train-mse:36.44218#011validation-mse:113.79966\u001b[0m\n",
      "\u001b[34m[778]#011train-rmse:6.03613#011validation-rmse:10.66754#011train-mse:36.43498#011validation-mse:113.79652\u001b[0m\n",
      "\u001b[34m[779]#011train-rmse:6.02961#011validation-rmse:10.66663#011train-mse:36.35634#011validation-mse:113.77721\u001b[0m\n",
      "\u001b[34m[780]#011train-rmse:6.02864#011validation-rmse:10.66650#011train-mse:36.34478#011validation-mse:113.77454\u001b[0m\n",
      "\u001b[34m[781]#011train-rmse:6.02814#011validation-rmse:10.66640#011train-mse:36.33863#011validation-mse:113.77235\u001b[0m\n",
      "\u001b[34m[782]#011train-rmse:6.02716#011validation-rmse:10.66624#011train-mse:36.32682#011validation-mse:113.76904\u001b[0m\n",
      "\u001b[34m[783]#011train-rmse:6.02611#011validation-rmse:10.66622#011train-mse:36.31427#011validation-mse:113.76843\u001b[0m\n",
      "\u001b[34m[784]#011train-rmse:6.02489#011validation-rmse:10.66561#011train-mse:36.29951#011validation-mse:113.75547\u001b[0m\n",
      "\u001b[34m[785]#011train-rmse:6.02189#011validation-rmse:10.66486#011train-mse:36.26342#011validation-mse:113.73949\u001b[0m\n",
      "\u001b[34m[786]#011train-rmse:6.02092#011validation-rmse:10.66462#011train-mse:36.25168#011validation-mse:113.73425\u001b[0m\n",
      "\u001b[34m[787]#011train-rmse:6.02058#011validation-rmse:10.66458#011train-mse:36.24756#011validation-mse:113.73355\u001b[0m\n",
      "\u001b[34m[788]#011train-rmse:6.01975#011validation-rmse:10.66471#011train-mse:36.23763#011validation-mse:113.73632\u001b[0m\n",
      "\u001b[34m[789]#011train-rmse:6.01895#011validation-rmse:10.66436#011train-mse:36.22800#011validation-mse:113.72875\u001b[0m\n",
      "\u001b[34m[790]#011train-rmse:6.01537#011validation-rmse:10.66112#011train-mse:36.18493#011validation-mse:113.65965\u001b[0m\n",
      "\u001b[34m[791]#011train-rmse:6.01201#011validation-rmse:10.66486#011train-mse:36.14446#011validation-mse:113.73945\u001b[0m\n",
      "\u001b[34m[792]#011train-rmse:6.01054#011validation-rmse:10.66404#011train-mse:36.12676#011validation-mse:113.72192\u001b[0m\n",
      "\u001b[34m[793]#011train-rmse:6.00718#011validation-rmse:10.66287#011train-mse:36.08641#011validation-mse:113.69700\u001b[0m\n",
      "\u001b[34m[794]#011train-rmse:6.00602#011validation-rmse:10.66252#011train-mse:36.07238#011validation-mse:113.68949\u001b[0m\n",
      "\u001b[34m[795]#011train-rmse:6.00547#011validation-rmse:10.66242#011train-mse:36.06591#011validation-mse:113.68748\u001b[0m\n",
      "\u001b[34m[796]#011train-rmse:6.00245#011validation-rmse:10.65969#011train-mse:36.02961#011validation-mse:113.62920\u001b[0m\n",
      "\u001b[34m[797]#011train-rmse:6.00003#011validation-rmse:10.65665#011train-mse:36.00062#011validation-mse:113.56438\u001b[0m\n",
      "\u001b[34m[798]#011train-rmse:5.99953#011validation-rmse:10.65655#011train-mse:35.99459#011validation-mse:113.56222\u001b[0m\n",
      "\u001b[34m[799]#011train-rmse:5.99743#011validation-rmse:10.65569#011train-mse:35.96932#011validation-mse:113.54414\u001b[0m\n",
      "\u001b[34m[800]#011train-rmse:5.99663#011validation-rmse:10.65551#011train-mse:35.95976#011validation-mse:113.54020\u001b[0m\n",
      "\u001b[34m[801]#011train-rmse:5.99626#011validation-rmse:10.65532#011train-mse:35.95527#011validation-mse:113.53615\u001b[0m\n",
      "\u001b[34m[802]#011train-rmse:5.99549#011validation-rmse:10.65515#011train-mse:35.94611#011validation-mse:113.53256\u001b[0m\n",
      "\u001b[34m[803]#011train-rmse:5.99488#011validation-rmse:10.65516#011train-mse:35.93873#011validation-mse:113.53262\u001b[0m\n",
      "\u001b[34m[804]#011train-rmse:5.99416#011validation-rmse:10.65537#011train-mse:35.93016#011validation-mse:113.53719\u001b[0m\n",
      "\u001b[34m[805]#011train-rmse:5.99363#011validation-rmse:10.65544#011train-mse:35.92383#011validation-mse:113.53867\u001b[0m\n",
      "\u001b[34m[806]#011train-rmse:5.99294#011validation-rmse:10.65529#011train-mse:35.91555#011validation-mse:113.53545\u001b[0m\n",
      "\u001b[34m[807]#011train-rmse:5.98855#011validation-rmse:10.67290#011train-mse:35.86283#011validation-mse:113.91112\u001b[0m\n",
      "\u001b[34m[808]#011train-rmse:5.98693#011validation-rmse:10.67271#011train-mse:35.84347#011validation-mse:113.90697\u001b[0m\n",
      "\u001b[34m[809]#011train-rmse:5.98597#011validation-rmse:10.67245#011train-mse:35.83195#011validation-mse:113.90153\u001b[0m\n",
      "\u001b[34m[810]#011train-rmse:5.98415#011validation-rmse:10.67187#011train-mse:35.81020#011validation-mse:113.88917\u001b[0m\n",
      "\u001b[34m[811]#011train-rmse:5.98302#011validation-rmse:10.67131#011train-mse:35.79671#011validation-mse:113.87713\u001b[0m\n",
      "\u001b[34m[812]#011train-rmse:5.98188#011validation-rmse:10.67145#011train-mse:35.78312#011validation-mse:113.88012\u001b[0m\n",
      "\u001b[34m[813]#011train-rmse:5.98151#011validation-rmse:10.67114#011train-mse:35.77863#011validation-mse:113.87350\u001b[0m\n",
      "\u001b[34m[814]#011train-rmse:5.98044#011validation-rmse:10.67086#011train-mse:35.76589#011validation-mse:113.86755\u001b[0m\n",
      "\u001b[34m[815]#011train-rmse:5.97865#011validation-rmse:10.67019#011train-mse:35.74447#011validation-mse:113.85326\u001b[0m\n",
      "\u001b[34m[816]#011train-rmse:5.97872#011validation-rmse:10.66983#011train-mse:35.74534#011validation-mse:113.84554\u001b[0m\n",
      "\u001b[34m[817]#011train-rmse:5.97549#011validation-rmse:10.66948#011train-mse:35.70670#011validation-mse:113.83802\u001b[0m\n",
      "\u001b[34m[818]#011train-rmse:5.97073#011validation-rmse:10.66693#011train-mse:35.64984#011validation-mse:113.78356\u001b[0m\n",
      "\u001b[34m[819]#011train-rmse:5.97032#011validation-rmse:10.66684#011train-mse:35.64486#011validation-mse:113.78154\u001b[0m\n",
      "\u001b[34m[820]#011train-rmse:5.96909#011validation-rmse:10.66677#011train-mse:35.63027#011validation-mse:113.78025\u001b[0m\n",
      "\u001b[34m[821]#011train-rmse:5.96820#011validation-rmse:10.66664#011train-mse:35.61962#011validation-mse:113.77734\u001b[0m\n",
      "\u001b[34m[822]#011train-rmse:5.96772#011validation-rmse:10.66661#011train-mse:35.61390#011validation-mse:113.77673\u001b[0m\n",
      "\u001b[34m[823]#011train-rmse:5.96414#011validation-rmse:10.66457#011train-mse:35.57119#011validation-mse:113.73331\u001b[0m\n",
      "\u001b[34m[824]#011train-rmse:5.95532#011validation-rmse:10.67127#011train-mse:35.46597#011validation-mse:113.87623\u001b[0m\n",
      "\u001b[34m[825]#011train-rmse:5.95258#011validation-rmse:10.67115#011train-mse:35.43339#011validation-mse:113.87361\u001b[0m\n",
      "\u001b[34m[826]#011train-rmse:5.95140#011validation-rmse:10.67070#011train-mse:35.41940#011validation-mse:113.86398\u001b[0m\n",
      "\u001b[34m[827]#011train-rmse:5.95020#011validation-rmse:10.66946#011train-mse:35.40518#011validation-mse:113.83754\u001b[0m\n",
      "\u001b[34m[828]#011train-rmse:5.94944#011validation-rmse:10.66944#011train-mse:35.39601#011validation-mse:113.83719\u001b[0m\n",
      "\u001b[34m[829]#011train-rmse:5.94743#011validation-rmse:10.66941#011train-mse:35.37209#011validation-mse:113.83649\u001b[0m\n",
      "\u001b[34m[830]#011train-rmse:5.94662#011validation-rmse:10.66931#011train-mse:35.36248#011validation-mse:113.83452\u001b[0m\n",
      "\u001b[34m[831]#011train-rmse:5.94572#011validation-rmse:10.66907#011train-mse:35.35178#011validation-mse:113.82925\u001b[0m\n",
      "\u001b[34m[832]#011train-rmse:5.94468#011validation-rmse:10.66847#011train-mse:35.33948#011validation-mse:113.81655\u001b[0m\n",
      "\u001b[34m[833]#011train-rmse:5.94161#011validation-rmse:10.66747#011train-mse:35.30297#011validation-mse:113.79526\u001b[0m\n",
      "\u001b[34m[834]#011train-rmse:5.93958#011validation-rmse:10.66661#011train-mse:35.27877#011validation-mse:113.77688\u001b[0m\n",
      "\u001b[34m[835]#011train-rmse:5.93861#011validation-rmse:10.66625#011train-mse:35.26726#011validation-mse:113.76922\u001b[0m\n",
      "\u001b[34m[836]#011train-rmse:5.93644#011validation-rmse:10.66542#011train-mse:35.24150#011validation-mse:113.75150\u001b[0m\n",
      "\u001b[34m[837]#011train-rmse:5.93638#011validation-rmse:10.66487#011train-mse:35.24080#011validation-mse:113.73959\u001b[0m\n",
      "\u001b[34m[838]#011train-rmse:5.93342#011validation-rmse:10.66469#011train-mse:35.20571#011validation-mse:113.73594\u001b[0m\n",
      "\u001b[34m[839]#011train-rmse:5.93194#011validation-rmse:10.66433#011train-mse:35.18807#011validation-mse:113.72817\u001b[0m\n",
      "\u001b[34m[840]#011train-rmse:5.93134#011validation-rmse:10.66416#011train-mse:35.18097#011validation-mse:113.72459\u001b[0m\n",
      "\u001b[34m[841]#011train-rmse:5.92927#011validation-rmse:10.66367#011train-mse:35.15644#011validation-mse:113.71406\u001b[0m\n",
      "\u001b[34m[842]#011train-rmse:5.92834#011validation-rmse:10.66365#011train-mse:35.14543#011validation-mse:113.71361\u001b[0m\n",
      "\u001b[34m[843]#011train-rmse:5.92752#011validation-rmse:10.66361#011train-mse:35.13575#011validation-mse:113.71283\u001b[0m\n",
      "\u001b[34m[844]#011train-rmse:5.92697#011validation-rmse:10.66373#011train-mse:35.12915#011validation-mse:113.71531\u001b[0m\n",
      "\u001b[34m[845]#011train-rmse:5.92328#011validation-rmse:10.66249#011train-mse:35.08534#011validation-mse:113.68890\u001b[0m\n",
      "\u001b[34m[846]#011train-rmse:5.92275#011validation-rmse:10.66240#011train-mse:35.07916#011validation-mse:113.68712\u001b[0m\n",
      "\u001b[34m[847]#011train-rmse:5.92190#011validation-rmse:10.66235#011train-mse:35.06905#011validation-mse:113.68607\u001b[0m\n",
      "\u001b[34m[848]#011train-rmse:5.92122#011validation-rmse:10.66215#011train-mse:35.06101#011validation-mse:113.68184\u001b[0m\n",
      "\u001b[34m[849]#011train-rmse:5.91556#011validation-rmse:10.66038#011train-mse:34.99403#011validation-mse:113.64401\u001b[0m\n",
      "\u001b[34m[850]#011train-rmse:5.91495#011validation-rmse:10.66040#011train-mse:34.98673#011validation-mse:113.64437\u001b[0m\n",
      "\u001b[34m[851]#011train-rmse:5.91427#011validation-rmse:10.66039#011train-mse:34.97877#011validation-mse:113.64426\u001b[0m\n",
      "\u001b[34m[852]#011train-rmse:5.91295#011validation-rmse:10.66020#011train-mse:34.96316#011validation-mse:113.64013\u001b[0m\n",
      "\u001b[34m[853]#011train-rmse:5.91145#011validation-rmse:10.65963#011train-mse:34.94542#011validation-mse:113.62812\u001b[0m\n",
      "\u001b[34m[854]#011train-rmse:5.91034#011validation-rmse:10.65934#011train-mse:34.93227#011validation-mse:113.62180\u001b[0m\n",
      "\u001b[34m[855]#011train-rmse:5.90973#011validation-rmse:10.65929#011train-mse:34.92507#011validation-mse:113.62079\u001b[0m\n",
      "\u001b[34m[856]#011train-rmse:5.90977#011validation-rmse:10.65765#011train-mse:34.92558#011validation-mse:113.58566\u001b[0m\n",
      "\u001b[34m[857]#011train-rmse:5.90794#011validation-rmse:10.65710#011train-mse:34.90396#011validation-mse:113.57395\u001b[0m\n",
      "\u001b[34m[858]#011train-rmse:5.90726#011validation-rmse:10.65706#011train-mse:34.89596#011validation-mse:113.57318\u001b[0m\n",
      "\u001b[34m[859]#011train-rmse:5.90677#011validation-rmse:10.65703#011train-mse:34.89009#011validation-mse:113.57264\u001b[0m\n",
      "\u001b[34m[860]#011train-rmse:5.90538#011validation-rmse:10.65650#011train-mse:34.87367#011validation-mse:113.56133\u001b[0m\n",
      "\u001b[34m[861]#011train-rmse:5.90372#011validation-rmse:10.65607#011train-mse:34.85404#011validation-mse:113.55212\u001b[0m\n",
      "\u001b[34m[862]#011train-rmse:5.90270#011validation-rmse:10.65583#011train-mse:34.84204#011validation-mse:113.54690\u001b[0m\n",
      "\u001b[34m[863]#011train-rmse:5.90216#011validation-rmse:10.65593#011train-mse:34.83570#011validation-mse:113.54918\u001b[0m\n",
      "\u001b[34m[864]#011train-rmse:5.90074#011validation-rmse:10.65553#011train-mse:34.81894#011validation-mse:113.54055\u001b[0m\n",
      "\u001b[34m[865]#011train-rmse:5.89974#011validation-rmse:10.65527#011train-mse:34.80714#011validation-mse:113.53490\u001b[0m\n",
      "\u001b[34m[866]#011train-rmse:5.89869#011validation-rmse:10.65522#011train-mse:34.79474#011validation-mse:113.53384\u001b[0m\n",
      "\u001b[34m[867]#011train-rmse:5.89759#011validation-rmse:10.65506#011train-mse:34.78174#011validation-mse:113.53048\u001b[0m\n",
      "\u001b[34m[868]#011train-rmse:5.89798#011validation-rmse:10.65506#011train-mse:34.78637#011validation-mse:113.53038\u001b[0m\n",
      "\u001b[34m[869]#011train-rmse:5.89633#011validation-rmse:10.65388#011train-mse:34.76684#011validation-mse:113.50535\u001b[0m\n",
      "\u001b[34m[870]#011train-rmse:5.89602#011validation-rmse:10.65408#011train-mse:34.76321#011validation-mse:113.50977\u001b[0m\n",
      "\u001b[34m[871]#011train-rmse:5.89451#011validation-rmse:10.65419#011train-mse:34.74540#011validation-mse:113.51192\u001b[0m\n",
      "\u001b[34m[872]#011train-rmse:5.89371#011validation-rmse:10.65416#011train-mse:34.73595#011validation-mse:113.51138\u001b[0m\n",
      "\u001b[34m[873]#011train-rmse:5.89263#011validation-rmse:10.65406#011train-mse:34.72324#011validation-mse:113.50916\u001b[0m\n",
      "\u001b[34m[874]#011train-rmse:5.89218#011validation-rmse:10.65402#011train-mse:34.71801#011validation-mse:113.50844\u001b[0m\n",
      "\u001b[34m[875]#011train-rmse:5.89144#011validation-rmse:10.65405#011train-mse:34.70925#011validation-mse:113.50894\u001b[0m\n",
      "\u001b[34m[876]#011train-rmse:5.88995#011validation-rmse:10.65103#011train-mse:34.69172#011validation-mse:113.44470\u001b[0m\n",
      "\u001b[34m[877]#011train-rmse:5.88901#011validation-rmse:10.65097#011train-mse:34.68068#011validation-mse:113.44325\u001b[0m\n",
      "\u001b[34m[878]#011train-rmse:5.88838#011validation-rmse:10.65081#011train-mse:34.67319#011validation-mse:113.43987\u001b[0m\n",
      "\u001b[34m[879]#011train-rmse:5.88608#011validation-rmse:10.65044#011train-mse:34.64617#011validation-mse:113.43209\u001b[0m\n",
      "\u001b[34m[880]#011train-rmse:5.88475#011validation-rmse:10.64993#011train-mse:34.63049#011validation-mse:113.42121\u001b[0m\n",
      "\u001b[34m[881]#011train-rmse:5.88303#011validation-rmse:10.64924#011train-mse:34.61025#011validation-mse:113.40656\u001b[0m\n",
      "\u001b[34m[882]#011train-rmse:5.88225#011validation-rmse:10.64906#011train-mse:34.60103#011validation-mse:113.40266\u001b[0m\n",
      "\u001b[34m[883]#011train-rmse:5.88104#011validation-rmse:10.64877#011train-mse:34.58686#011validation-mse:113.39656\u001b[0m\n",
      "\u001b[34m[884]#011train-rmse:5.87832#011validation-rmse:10.64831#011train-mse:34.55489#011validation-mse:113.38670\u001b[0m\n",
      "\u001b[34m[885]#011train-rmse:5.87697#011validation-rmse:10.64818#011train-mse:34.53896#011validation-mse:113.38391\u001b[0m\n",
      "\u001b[34m[886]#011train-rmse:5.87648#011validation-rmse:10.64812#011train-mse:34.53327#011validation-mse:113.38281\u001b[0m\n",
      "\u001b[34m[887]#011train-rmse:5.87550#011validation-rmse:10.64691#011train-mse:34.52173#011validation-mse:113.35694\u001b[0m\n",
      "\u001b[34m[888]#011train-rmse:5.87387#011validation-rmse:10.64584#011train-mse:34.50257#011validation-mse:113.33419\u001b[0m\n",
      "\u001b[34m[889]#011train-rmse:5.87270#011validation-rmse:10.64500#011train-mse:34.48882#011validation-mse:113.31619\u001b[0m\n",
      "\u001b[34m[890]#011train-rmse:5.87168#011validation-rmse:10.64438#011train-mse:34.47686#011validation-mse:113.30322\u001b[0m\n",
      "\u001b[34m[891]#011train-rmse:5.86949#011validation-rmse:10.64207#011train-mse:34.45105#011validation-mse:113.25396\u001b[0m\n",
      "\u001b[34m[892]#011train-rmse:5.86907#011validation-rmse:10.64201#011train-mse:34.44621#011validation-mse:113.25262\u001b[0m\n",
      "\u001b[34m[893]#011train-rmse:5.86745#011validation-rmse:10.64161#011train-mse:34.42723#011validation-mse:113.24410\u001b[0m\n",
      "\u001b[34m[894]#011train-rmse:5.86608#011validation-rmse:10.64042#011train-mse:34.41105#011validation-mse:113.21865\u001b[0m\n",
      "\u001b[34m[895]#011train-rmse:5.86480#011validation-rmse:10.64015#011train-mse:34.39606#011validation-mse:113.21301\u001b[0m\n",
      "\u001b[34m[896]#011train-rmse:5.86311#011validation-rmse:10.63976#011train-mse:34.37627#011validation-mse:113.20463\u001b[0m\n",
      "\u001b[34m[897]#011train-rmse:5.86151#011validation-rmse:10.63954#011train-mse:34.35747#011validation-mse:113.20004\u001b[0m\n",
      "\u001b[34m[898]#011train-rmse:5.86073#011validation-rmse:10.63933#011train-mse:34.34835#011validation-mse:113.19558\u001b[0m\n",
      "\u001b[34m[899]#011train-rmse:5.85923#011validation-rmse:10.63917#011train-mse:34.33071#011validation-mse:113.19216\u001b[0m\n",
      "\u001b[34m[900]#011train-rmse:5.85860#011validation-rmse:10.63886#011train-mse:34.32336#011validation-mse:113.18555\u001b[0m\n",
      "\u001b[34m[901]#011train-rmse:5.85337#011validation-rmse:10.63701#011train-mse:34.26211#011validation-mse:113.14616\u001b[0m\n",
      "\u001b[34m[902]#011train-rmse:5.85336#011validation-rmse:10.63715#011train-mse:34.26201#011validation-mse:113.14919\u001b[0m\n",
      "\u001b[34m[903]#011train-rmse:5.85282#011validation-rmse:10.63708#011train-mse:34.25564#011validation-mse:113.14769\u001b[0m\n",
      "\u001b[34m[904]#011train-rmse:5.85040#011validation-rmse:10.63639#011train-mse:34.22732#011validation-mse:113.13296\u001b[0m\n",
      "\u001b[34m[905]#011train-rmse:5.84925#011validation-rmse:10.63613#011train-mse:34.21393#011validation-mse:113.12753\u001b[0m\n",
      "\u001b[34m[906]#011train-rmse:5.84842#011validation-rmse:10.63599#011train-mse:34.20417#011validation-mse:113.12455\u001b[0m\n",
      "\u001b[34m[907]#011train-rmse:5.84511#011validation-rmse:10.63389#011train-mse:34.16552#011validation-mse:113.07973\u001b[0m\n",
      "\u001b[34m[908]#011train-rmse:5.84185#011validation-rmse:10.63324#011train-mse:34.12739#011validation-mse:113.06609\u001b[0m\n",
      "\u001b[34m[909]#011train-rmse:5.84119#011validation-rmse:10.63283#011train-mse:34.11963#011validation-mse:113.05719\u001b[0m\n",
      "\u001b[34m[910]#011train-rmse:5.84046#011validation-rmse:10.63277#011train-mse:34.11111#011validation-mse:113.05588\u001b[0m\n",
      "\u001b[34m[911]#011train-rmse:5.83971#011validation-rmse:10.63283#011train-mse:34.10242#011validation-mse:113.05721\u001b[0m\n",
      "\u001b[34m[912]#011train-rmse:5.83848#011validation-rmse:10.63299#011train-mse:34.08805#011validation-mse:113.06052\u001b[0m\n",
      "\u001b[34m[913]#011train-rmse:5.83792#011validation-rmse:10.63294#011train-mse:34.08152#011validation-mse:113.05967\u001b[0m\n",
      "\u001b[34m[914]#011train-rmse:5.83518#011validation-rmse:10.63307#011train-mse:34.04952#011validation-mse:113.06246\u001b[0m\n",
      "\u001b[34m[915]#011train-rmse:5.83310#011validation-rmse:10.63181#011train-mse:34.02521#011validation-mse:113.03573\u001b[0m\n",
      "\u001b[34m[916]#011train-rmse:5.83235#011validation-rmse:10.63151#011train-mse:34.01653#011validation-mse:113.02938\u001b[0m\n",
      "\u001b[34m[917]#011train-rmse:5.83173#011validation-rmse:10.63132#011train-mse:34.00923#011validation-mse:113.02531\u001b[0m\n",
      "\u001b[34m[918]#011train-rmse:5.83097#011validation-rmse:10.63126#011train-mse:34.00044#011validation-mse:113.02393\u001b[0m\n",
      "\u001b[34m[919]#011train-rmse:5.81954#011validation-rmse:10.63043#011train-mse:33.86721#011validation-mse:113.00628\u001b[0m\n",
      "\u001b[34m[920]#011train-rmse:5.81888#011validation-rmse:10.63000#011train-mse:33.85953#011validation-mse:112.99712\u001b[0m\n",
      "\u001b[34m[921]#011train-rmse:5.81767#011validation-rmse:10.62970#011train-mse:33.84547#011validation-mse:112.99081\u001b[0m\n",
      "\u001b[34m[922]#011train-rmse:5.81663#011validation-rmse:10.62965#011train-mse:33.83339#011validation-mse:112.98965\u001b[0m\n",
      "\u001b[34m[923]#011train-rmse:5.81550#011validation-rmse:10.62968#011train-mse:33.82025#011validation-mse:112.99032\u001b[0m\n",
      "\u001b[34m[924]#011train-rmse:5.81016#011validation-rmse:10.62964#011train-mse:33.75816#011validation-mse:112.98941\u001b[0m\n",
      "\u001b[34m[925]#011train-rmse:5.80944#011validation-rmse:10.62982#011train-mse:33.74977#011validation-mse:112.99328\u001b[0m\n",
      "\u001b[34m[926]#011train-rmse:5.80684#011validation-rmse:10.62833#011train-mse:33.71957#011validation-mse:112.96164\u001b[0m\n",
      "\u001b[34m[927]#011train-rmse:5.80597#011validation-rmse:10.62819#011train-mse:33.70951#011validation-mse:112.95873\u001b[0m\n",
      "\u001b[34m[928]#011train-rmse:5.80508#011validation-rmse:10.62814#011train-mse:33.69921#011validation-mse:112.95752\u001b[0m\n",
      "\u001b[34m[929]#011train-rmse:5.80398#011validation-rmse:10.62773#011train-mse:33.68634#011validation-mse:112.94882\u001b[0m\n",
      "\u001b[34m[930]#011train-rmse:5.80392#011validation-rmse:10.62744#011train-mse:33.68574#011validation-mse:112.94274\u001b[0m\n",
      "\u001b[34m[931]#011train-rmse:5.80343#011validation-rmse:10.62731#011train-mse:33.67999#011validation-mse:112.93984\u001b[0m\n",
      "\u001b[34m[932]#011train-rmse:5.80041#011validation-rmse:10.62723#011train-mse:33.64492#011validation-mse:112.93827\u001b[0m\n",
      "\u001b[34m[933]#011train-rmse:5.80012#011validation-rmse:10.62738#011train-mse:33.64151#011validation-mse:112.94138\u001b[0m\n",
      "\u001b[34m[934]#011train-rmse:5.79936#011validation-rmse:10.62725#011train-mse:33.63277#011validation-mse:112.93861\u001b[0m\n",
      "\u001b[34m[935]#011train-rmse:5.79837#011validation-rmse:10.62726#011train-mse:33.62131#011validation-mse:112.93887\u001b[0m\n",
      "\u001b[34m[936]#011train-rmse:5.79704#011validation-rmse:10.62655#011train-mse:33.60582#011validation-mse:112.92384\u001b[0m\n",
      "\u001b[34m[937]#011train-rmse:5.79630#011validation-rmse:10.62637#011train-mse:33.59729#011validation-mse:112.92005\u001b[0m\n",
      "\u001b[34m[938]#011train-rmse:5.79560#011validation-rmse:10.62634#011train-mse:33.58915#011validation-mse:112.91943\u001b[0m\n",
      "\u001b[34m[939]#011train-rmse:5.79469#011validation-rmse:10.62609#011train-mse:33.57862#011validation-mse:112.91409\u001b[0m\n",
      "\u001b[34m[940]#011train-rmse:5.79340#011validation-rmse:10.62590#011train-mse:33.56372#011validation-mse:112.91013\u001b[0m\n",
      "\u001b[34m[941]#011train-rmse:5.79248#011validation-rmse:10.62562#011train-mse:33.55304#011validation-mse:112.90403\u001b[0m\n",
      "\u001b[34m[942]#011train-rmse:5.79076#011validation-rmse:10.62533#011train-mse:33.53308#011validation-mse:112.89797\u001b[0m\n",
      "\u001b[34m[943]#011train-rmse:5.79019#011validation-rmse:10.62520#011train-mse:33.52654#011validation-mse:112.89515\u001b[0m\n",
      "\u001b[34m[944]#011train-rmse:5.78955#011validation-rmse:10.62497#011train-mse:33.51917#011validation-mse:112.89043\u001b[0m\n",
      "\u001b[34m[945]#011train-rmse:5.78881#011validation-rmse:10.62473#011train-mse:33.51053#011validation-mse:112.88525\u001b[0m\n",
      "\u001b[34m[946]#011train-rmse:5.78839#011validation-rmse:10.62470#011train-mse:33.50565#011validation-mse:112.88456\u001b[0m\n",
      "\u001b[34m[947]#011train-rmse:5.78663#011validation-rmse:10.62423#011train-mse:33.48534#011validation-mse:112.87437\u001b[0m\n",
      "\u001b[34m[948]#011train-rmse:5.78572#011validation-rmse:10.62391#011train-mse:33.47476#011validation-mse:112.86774\u001b[0m\n",
      "\u001b[34m[949]#011train-rmse:5.78322#011validation-rmse:10.62443#011train-mse:33.44587#011validation-mse:112.87875\u001b[0m\n",
      "\u001b[34m[950]#011train-rmse:5.78215#011validation-rmse:10.62438#011train-mse:33.43349#011validation-mse:112.87762\u001b[0m\n",
      "\u001b[34m[951]#011train-rmse:5.78101#011validation-rmse:10.62402#011train-mse:33.42025#011validation-mse:112.87007\u001b[0m\n",
      "\u001b[34m[952]#011train-rmse:5.78019#011validation-rmse:10.62370#011train-mse:33.41085#011validation-mse:112.86327\u001b[0m\n",
      "\u001b[34m[953]#011train-rmse:5.77929#011validation-rmse:10.62373#011train-mse:33.40040#011validation-mse:112.86392\u001b[0m\n",
      "\u001b[34m[954]#011train-rmse:5.77832#011validation-rmse:10.62370#011train-mse:33.38917#011validation-mse:112.86314\u001b[0m\n",
      "\u001b[34m[955]#011train-rmse:5.77731#011validation-rmse:10.62337#011train-mse:33.37743#011validation-mse:112.85619\u001b[0m\n",
      "\u001b[34m[956]#011train-rmse:5.77681#011validation-rmse:10.62319#011train-mse:33.37168#011validation-mse:112.85231\u001b[0m\n",
      "\u001b[34m[957]#011train-rmse:5.77104#011validation-rmse:10.62137#011train-mse:33.30514#011validation-mse:112.81360\u001b[0m\n",
      "\u001b[34m[958]#011train-rmse:5.77032#011validation-rmse:10.62055#011train-mse:33.29684#011validation-mse:112.79621\u001b[0m\n",
      "\u001b[34m[959]#011train-rmse:5.76956#011validation-rmse:10.62034#011train-mse:33.28801#011validation-mse:112.79181\u001b[0m\n",
      "\u001b[34m[960]#011train-rmse:5.76815#011validation-rmse:10.61985#011train-mse:33.27178#011validation-mse:112.78136\u001b[0m\n",
      "\u001b[34m[961]#011train-rmse:5.76724#011validation-rmse:10.62000#011train-mse:33.26129#011validation-mse:112.78478\u001b[0m\n",
      "\u001b[34m[962]#011train-rmse:5.76633#011validation-rmse:10.61988#011train-mse:33.25081#011validation-mse:112.78198\u001b[0m\n",
      "\u001b[34m[963]#011train-rmse:5.76577#011validation-rmse:10.61935#011train-mse:33.24435#011validation-mse:112.77071\u001b[0m\n",
      "\u001b[34m[964]#011train-rmse:5.76488#011validation-rmse:10.61877#011train-mse:33.23407#011validation-mse:112.75856\u001b[0m\n",
      "\u001b[34m[965]#011train-rmse:5.76352#011validation-rmse:10.61832#011train-mse:33.21836#011validation-mse:112.74889\u001b[0m\n",
      "\u001b[34m[966]#011train-rmse:5.76191#011validation-rmse:10.61786#011train-mse:33.19978#011validation-mse:112.73927\u001b[0m\n",
      "\u001b[34m[967]#011train-rmse:5.76127#011validation-rmse:10.61774#011train-mse:33.19242#011validation-mse:112.73673\u001b[0m\n",
      "\u001b[34m[968]#011train-rmse:5.76038#011validation-rmse:10.61754#011train-mse:33.18211#011validation-mse:112.73235\u001b[0m\n",
      "\u001b[34m[969]#011train-rmse:5.75955#011validation-rmse:10.61719#011train-mse:33.17263#011validation-mse:112.72497\u001b[0m\n",
      "\u001b[34m[970]#011train-rmse:5.75867#011validation-rmse:10.61460#011train-mse:33.16251#011validation-mse:112.66996\u001b[0m\n",
      "\u001b[34m[971]#011train-rmse:5.75554#011validation-rmse:10.61389#011train-mse:33.12643#011validation-mse:112.65498\u001b[0m\n",
      "\u001b[34m[972]#011train-rmse:5.75502#011validation-rmse:10.61398#011train-mse:33.12048#011validation-mse:112.65672\u001b[0m\n",
      "\u001b[34m[973]#011train-rmse:5.75467#011validation-rmse:10.61393#011train-mse:33.11644#011validation-mse:112.65591\u001b[0m\n",
      "\u001b[34m[974]#011train-rmse:5.75470#011validation-rmse:10.61377#011train-mse:33.11672#011validation-mse:112.65234\u001b[0m\n",
      "\u001b[34m[975]#011train-rmse:5.75495#011validation-rmse:10.61365#011train-mse:33.11961#011validation-mse:112.64992\u001b[0m\n",
      "\u001b[34m[976]#011train-rmse:5.75388#011validation-rmse:10.61521#011train-mse:33.10728#011validation-mse:112.68292\u001b[0m\n",
      "\u001b[34m[977]#011train-rmse:5.74975#011validation-rmse:10.61110#011train-mse:33.05979#011validation-mse:112.59579\u001b[0m\n",
      "\u001b[34m[978]#011train-rmse:5.74908#011validation-rmse:10.61100#011train-mse:33.05210#011validation-mse:112.59347\u001b[0m\n",
      "\u001b[34m[979]#011train-rmse:5.74849#011validation-rmse:10.61096#011train-mse:33.04536#011validation-mse:112.59274\u001b[0m\n",
      "\u001b[34m[980]#011train-rmse:5.74818#011validation-rmse:10.61096#011train-mse:33.04177#011validation-mse:112.59271\u001b[0m\n",
      "\u001b[34m[981]#011train-rmse:5.74723#011validation-rmse:10.61045#011train-mse:33.03086#011validation-mse:112.58179\u001b[0m\n",
      "\u001b[34m[982]#011train-rmse:5.74640#011validation-rmse:10.61017#011train-mse:33.02134#011validation-mse:112.57591\u001b[0m\n",
      "\u001b[34m[983]#011train-rmse:5.74010#011validation-rmse:10.61003#011train-mse:32.94890#011validation-mse:112.57302\u001b[0m\n",
      "\u001b[34m[984]#011train-rmse:5.73925#011validation-rmse:10.60990#011train-mse:32.93921#011validation-mse:112.57008\u001b[0m\n",
      "\u001b[34m[985]#011train-rmse:5.73809#011validation-rmse:10.60963#011train-mse:32.92585#011validation-mse:112.56439\u001b[0m\n",
      "\u001b[34m[986]#011train-rmse:5.73736#011validation-rmse:10.60936#011train-mse:32.91750#011validation-mse:112.55870\u001b[0m\n",
      "\u001b[34m[987]#011train-rmse:5.73562#011validation-rmse:10.60724#011train-mse:32.89759#011validation-mse:112.51372\u001b[0m\n",
      "\u001b[34m[988]#011train-rmse:5.73517#011validation-rmse:10.60718#011train-mse:32.89234#011validation-mse:112.51250\u001b[0m\n",
      "\u001b[34m[989]#011train-rmse:5.73452#011validation-rmse:10.60716#011train-mse:32.88492#011validation-mse:112.51199\u001b[0m\n",
      "\u001b[34m[990]#011train-rmse:5.73392#011validation-rmse:10.60693#011train-mse:32.87802#011validation-mse:112.50725\u001b[0m\n",
      "\u001b[34m[991]#011train-rmse:5.73343#011validation-rmse:10.60695#011train-mse:32.87241#011validation-mse:112.50761\u001b[0m\n",
      "\u001b[34m[992]#011train-rmse:5.73142#011validation-rmse:10.60780#011train-mse:32.84938#011validation-mse:112.52569\u001b[0m\n",
      "\u001b[34m[993]#011train-rmse:5.73070#011validation-rmse:10.60764#011train-mse:32.84109#011validation-mse:112.52232\u001b[0m\n",
      "\u001b[34m[994]#011train-rmse:5.72985#011validation-rmse:10.60750#011train-mse:32.83144#011validation-mse:112.51944\u001b[0m\n",
      "\u001b[34m[995]#011train-rmse:5.72911#011validation-rmse:10.60718#011train-mse:32.82290#011validation-mse:112.51262\u001b[0m\n",
      "\u001b[34m[996]#011train-rmse:5.72772#011validation-rmse:10.60703#011train-mse:32.80690#011validation-mse:112.50935\u001b[0m\n",
      "\u001b[34m[997]#011train-rmse:5.72715#011validation-rmse:10.60706#011train-mse:32.80037#011validation-mse:112.50984\u001b[0m\n",
      "\u001b[34m[998]#011train-rmse:5.72395#011validation-rmse:10.60554#011train-mse:32.76381#011validation-mse:112.47765\u001b[0m\n",
      "\u001b[34m[999]#011train-rmse:5.72351#011validation-rmse:10.60547#011train-mse:32.75869#011validation-mse:112.47624\u001b[0m\n",
      "\u001b[34m[1000]#011train-rmse:5.72257#011validation-rmse:10.60535#011train-mse:32.74801#011validation-mse:112.47373\u001b[0m\n",
      "\u001b[34m[1001]#011train-rmse:5.72187#011validation-rmse:10.60529#011train-mse:32.73994#011validation-mse:112.47249\u001b[0m\n",
      "\u001b[34m[1002]#011train-rmse:5.72118#011validation-rmse:10.60525#011train-mse:32.73209#011validation-mse:112.47160\u001b[0m\n",
      "\u001b[34m[1003]#011train-rmse:5.71713#011validation-rmse:10.60407#011train-mse:32.68572#011validation-mse:112.44656\u001b[0m\n",
      "\u001b[34m[1004]#011train-rmse:5.71565#011validation-rmse:10.60332#011train-mse:32.66882#011validation-mse:112.43076\u001b[0m\n",
      "\u001b[34m[1005]#011train-rmse:5.71358#011validation-rmse:10.60271#011train-mse:32.64523#011validation-mse:112.41769\u001b[0m\n",
      "\u001b[34m[1006]#011train-rmse:5.71248#011validation-rmse:10.60262#011train-mse:32.63260#011validation-mse:112.41576\u001b[0m\n",
      "\u001b[34m[1007]#011train-rmse:5.71110#011validation-rmse:10.60222#011train-mse:32.61688#011validation-mse:112.40731\u001b[0m\n",
      "\u001b[34m[1008]#011train-rmse:5.71078#011validation-rmse:10.60223#011train-mse:32.61316#011validation-mse:112.40751\u001b[0m\n",
      "\u001b[34m[1009]#011train-rmse:5.70896#011validation-rmse:10.60172#011train-mse:32.59238#011validation-mse:112.39671\u001b[0m\n",
      "\u001b[34m[1010]#011train-rmse:5.70773#011validation-rmse:10.60130#011train-mse:32.57839#011validation-mse:112.38771\u001b[0m\n",
      "\u001b[34m[1011]#011train-rmse:5.70720#011validation-rmse:10.60136#011train-mse:32.57230#011validation-mse:112.38908\u001b[0m\n",
      "\u001b[34m[1012]#011train-rmse:5.70608#011validation-rmse:10.60139#011train-mse:32.55949#011validation-mse:112.38974\u001b[0m\n",
      "\u001b[34m[1013]#011train-rmse:5.70526#011validation-rmse:10.60128#011train-mse:32.55022#011validation-mse:112.38736\u001b[0m\n",
      "\u001b[34m[1014]#011train-rmse:5.70391#011validation-rmse:10.60137#011train-mse:32.53475#011validation-mse:112.38924\u001b[0m\n",
      "\u001b[34m[1015]#011train-rmse:5.70352#011validation-rmse:10.60126#011train-mse:32.53032#011validation-mse:112.38707\u001b[0m\n",
      "\u001b[34m[1016]#011train-rmse:5.70286#011validation-rmse:10.60134#011train-mse:32.52279#011validation-mse:112.38867\u001b[0m\n",
      "\u001b[34m[1017]#011train-rmse:5.70285#011validation-rmse:10.60074#011train-mse:32.52277#011validation-mse:112.37602\u001b[0m\n",
      "\u001b[34m[1018]#011train-rmse:5.70238#011validation-rmse:10.60019#011train-mse:32.51736#011validation-mse:112.36437\u001b[0m\n",
      "Training seconds: 143\n",
      "Billable seconds: 143\n",
      "2020-12-03 15:33:28,283 WARNING sagemaker: Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "from sagemaker_automl import select_inference_output\n",
    "\n",
    "# Get a data transformation model from chosen candidate\n",
    "best_candidate = automl_interactive_runner.choose_candidate(df_tuning_job_analytics, best_training_job)\n",
    "best_data_transformer_model = best_candidate.get_data_transformer_model(role=SAGEMAKER_ROLE, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "# Our first data transformation container will always return recordio-protobuf format\n",
    "best_data_transformer_model.env[\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\"] = 'application/x-recordio-protobuf'\n",
    "# Add environment variable for sparse encoding\n",
    "if best_candidate.data_transformer_step.sparse_encoding:\n",
    "    best_data_transformer_model.env[\"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\"] = '1'\n",
    "\n",
    "# Get a algo model from chosen training job of the candidate\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "best_algo_model = algo_estimator.create_model(**best_candidate.algo_step.get_inference_container_config())\n",
    "\n",
    "# Final pipeline model is composed of data transformation models and algo model and an\n",
    "# inverse label transform model if we need to transform the intermediates back to non-numerical value\n",
    "model_containers = [best_data_transformer_model, best_algo_model]\n",
    "if best_candidate.transforms_label:\n",
    "    model_containers.append(best_candidate.get_data_transformer_model(\n",
    "        transform_mode=\"inverse-label-transform\",\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        sagemaker_session=SAGEMAKER_SESSION))\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"AutoML-{}\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name),\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    models=model_containers,\n",
    "    vpc_config=AUTOML_LOCAL_RUN_CONFIG.vpc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Best Pipeline\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. You can customize the initial instance count and instance type used to deploy this model.\n",
    "2. Endpoint name can be changed to avoid conflict with existing endpoints.\n",
    "\n",
    "</div>\n",
    "\n",
    "Finally, deploy the model to SageMaker to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.deploy(initial_instance_count=1,\n",
    "                      instance_type='ml.m5.2xlarge',\n",
    "                      endpoint_name=pipeline_model.name,\n",
    "                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you could visit the sagemaker\n",
    "[endpoint console page](https://eu-central-1.console.aws.amazon.com/sagemaker/home?region=eu-central-1#/endpoints) to find the deployed endpoint (it'll take a few minutes to be in service).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <strong>To rerun this notebook, delete or change the name of your endpoint!</strong> <br>\n",
    "If you rerun this notebook, you'll run into an error on the last step because the endpoint already exists. You can either delete the endpoint from the endpoint console page or you can change the <code>endpoint_name</code> in the previous code block.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
